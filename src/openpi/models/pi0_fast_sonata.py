# è¯¥ç‰ˆæœ¬å·²çŸ¥é—®é¢˜ï¼ˆè¿™äº›é—®é¢˜ç›®å‰æš‚æ—¶ä¸ç”¨ç«‹åˆ»è§£å†³ï¼‰ï¼š
# è®­ç»ƒæ—¶æ¢¯åº¦	ä¸ä¼šå°è¯•å›ä¼ åˆ° Sonata/Projector	freezeâ€‘filter éåˆšéœ€, è¿™ä¸ªæˆ‘ä»¬åç»­å†è§£å†³ï¼Œå› ä¸ºæˆ‘ä»¬å®é™…ä¸Šè¦å…è®¸è®­ç»ƒï¼Œæ‰€ä»¥åè€Œä¸èƒ½å†»ç»“ï¼Œè¿™ä¸ªåé¢å†è¯´
# æ€§èƒ½æ½œåœ¨ç“¶é¢ˆ	CPUâ€¯â†”â€¯GPU copy / å¤šç¼–è¯‘	åç»­è¿­ä»£å¯èƒ½ä¼šå½±å“è¿™ä¸ªï¼Œæ‰€ä»¥é¦–å…ˆè§£å†³é—®é¢˜1
# 1024 token sizeï¼Œè¿™ä¸ªæš‚æ—¶ä¸èƒ½è®¾ç½®å¤ªå¤§å› ä¸ºä¼šç‚¸æ˜¾å­˜ï¼Œé¦–å…ˆä½¿ç”¨æç¤ºæ–¹å¼æ¥ç¡®å®šæ˜¯å¦ä¼šæœ‰è¿‡å¤šçš„æƒ…å†µï¼Œæ²¡æœ‰å°±ç»§ç»­è®­ç»ƒï¼Œæœ‰çš„è¯åç»­å†ç»§ç»­å¤„ç†
# æ³¨æ„ï¼Œgridä¼¼ä¹ä¸èƒ½æ˜¯è´Ÿæ•°ï¼
# per-sample pure_callback batch>1 æ—¶ CPUâ†”GPU æ¥å›å’Œ XLA â†’ host äº¤äº’ä¼šæ‹–æ…¢ï¼Œæ¢¯åº¦ç§¯ç´¯åœºæ™¯å°¤ç”š
# grid â†’ coord åç§»ï¼šå½“å‰åœ¨ _canonicalize_point_dict é‡ŒæŠŠ grid_coord å½’é›¶ï¼Œä½† è¿ç»­ xyz (coord) å¹¶æ²¡æœ‰åŒæ­¥åç§»ï¼›å¦‚æœä½ åé¢ç”¨åˆ°ç»å¯¹åæ ‡ï¼Œéœ€è¦ç¡®ä¿ä¸€è‡´æ€§ã€‚
# ä¸ºäº†é¿å…è­¦å‘Šï¼Œå®æ–½äº†JAX ç«¯ batch/offset ç”¨ int32ï¼Œhost(PyTorch) ç«¯ç»Ÿä¸€ .long()ï¼›é¿å… JAX_ENABLE_X64 ç›¸å…³è­¦å‘Šã€‚
# ã€è¿™ä¸ªä¼¼ä¹ä¿®å¤äº†ï¼Ÿã€‘â€œæ’å…¥ä½ç½®â€ä¸¥æ ¼ä¸€è‡´æ€§é—®é¢˜å­˜åœ¨ï¼šæˆ‘ä»¬æ˜¯å‰ç¼€æ‹¼æ¥ï¼›SpatialLM æ˜¯ <point_start>..ç‚¹token.. <point_end> æ’å›åˆ°æ–‡æœ¬åºåˆ—ã€‚è¯­ä¹‰ç­‰ä»·ï¼ˆæ–‡æœ¬ä¾æ—§èƒ½çœ‹åˆ°ç‚¹ tokenï¼‰ï¼Œä½†ä¸æ˜¯å®Œå…¨åŒä¸€ä½ç½®ã€‚å¦‚æœä½ è¦é€å­—èŠ‚ä¸€è‡´ï¼Œéœ€è¦è®© tokenizer/prompt ä¸­çœŸçš„åŒ…å« <point_start>/<point_end>ï¼Œå¹¶åœ¨æ‹¼æ¥æ—¶æ‰¾åˆ°è¿™ä¸¤ä¸ªä½ç½®å†åšæ’å…¥ï¼ˆæˆæœ¬è¾ƒé«˜ï¼Œä¸”å¯¹ä½ å½“å‰ Pi0â€‘FAST çš„å¤šæ¨¡æ€æ‹¼æ¥æ¥å£ä¸è‡ªç„¶ï¼‰ã€‚


import dataclasses
import inspect
import logging
import typing
import jax
import jax.numpy as jnp
import jax.nn as jnn
import numpy as np
import torch
from pathlib import Path
from typing import Any, Dict, Tuple, Optional

# ---- JAX <-> openpi å…¼å®¹ï¼šKeyArray åœ¨ JAX 0.4.14+ è¢«ç§»é™¤ ----
import jax.random as _jr
if not hasattr(_jr, "KeyArray"): _jr.KeyArray = jax.Array  # type: ignore[attr-defined]

from flax import nnx
# nnx_bridge allows bridging PyTorch modules to NNX (Flax) modules
import flax.nnx.bridge as nnx_bridge

from jax import ShapeDtypeStruct
from jax import pure_callback

from openpi.models import sonata_encoder  # This module should define the Sonata point cloud encoder
import openpi.models.gemma_fast as _gemma 
from openpi.models import pi0_fast as _pi0_fast
from openpi.models import siglip as _siglip
from openpi.models import PointBackboneType, ProjectorType
import openpi.models.model as _model  # for BaseModel and Observation
from openpi.shared import array_typing as at  # for inputs_spec override
# from openpi.shared import download     # utility for downloading resources like weights, not used for now

# optional â€“ hugâ€‘hub ä¼˜å…ˆ
try:
    from huggingface_hub import hf_hub_download
    _HF_OK = True
except ImportError:          # ç¯å¢ƒé‡Œæ²¡è£… huggingface_hub ä¼šèµ°æ—§é€»è¾‘
    _HF_OK = False
logger = logging.getLogger("openpi")

# ç”¨äºç”Ÿæˆæµ‹è¯•ç”¨æ•°æ®çš„å·¥å…·å‡½æ•°
def _canonicalize_point_dict(pd):
    pd = {k: jnp.asarray(v) for k, v in pd.items()}  # â† ç”¨ jnpï¼›ä¸åšä»»ä½•â€œæ•°æ®ä¿®å¤â€ï¼Œåªåšå½¢çŠ¶è§„èŒƒåŒ–ä¸ dtype çº¦æŸ
 

    if pd["coord"].ndim == 3:      # (B,N,3) â†’ (B*N,3)
        B, N, _ = pd["coord"].shape
        pd["coord"] = jnp.reshape(pd["coord"], (B * N, 3))
        pd["feat"]  = jnp.reshape(pd["feat"],  (B * N, -1))
        # JAX ç«¯ç»Ÿä¸€ int32ï¼›host(PyTorch) ç«¯å†å‡ä¸º int64 ä»¥æ”¯æŒ (batch << 48)
        pd["batch"]  = jnp.repeat(jnp.arange(B, dtype=jnp.int32), N)
        pd["offset"] = jnp.cumsum(jnp.full((B,), N, dtype=jnp.int32))

    if "grid_size" in pd and pd["grid_size"].ndim == 3:
        pd["grid_size"] = jnp.reshape(pd["grid_size"], (-1, 3))

    # JAX ç«¯ä¿æŒ int32ï¼ˆé¿å… x64 è­¦å‘Šï¼‰ï¼›host ç«¯å†å‡ä¸º int64
    for key in ("batch", "offset"):
         if key in pd:
            pd[key] = pd[key].astype(jnp.int32, copy=False)

    # SpatialLM çº¦å®šï¼šæ˜¾å¼æä¾› int32 ä½“ç´ åæ ‡ï¼ˆä¸åšé›¶ç‚¹å¹³ç§»/é‡å»ºï¼‰
    if "grid_coord" in pd:
        # è¿™é‡Œæœ‰ä¸ªæ½œåœ¨çš„é—®é¢˜ï¼Œè‹¥ç”¨æˆ·è‡ªå·±ç»„è£…çš„grid_coordå·²ç»è¶…è¿‡65535ï¼Œåˆ™å¯èƒ½å†æ¬¡æº¢å‡ºï¼Œä½†è¿™ä¸ªå®é™…ä¸Šä¸å¤ªå¯èƒ½ï¼Œå› æ­¤åªå†™æ³¨é‡Šï¼Œç­‰ä»¥åå¦‚æœè®­ç»ƒæœ‰é—®é¢˜å†å›æ¥çœ‹ã€‚
        if pd["grid_coord"].shape[-1] != 3:
            raise ValueError("pointcloud.grid_coord çš„æœ€åä¸€ç»´å¿…é¡»ä¸º 3ï¼ˆxyzï¼‰ã€‚")
        pd["grid_coord"] = pd["grid_coord"].astype(jnp.int32, copy=False)

    return pd

# ---------- host-side helper: find <point_start>/<point_end> & keep indices ----------
def _host_find_window_and_keep_idx(
    prompt_np: np.ndarray,
    start_id: int,
    end_id: int,
    *,
    allow_text_between: bool = False,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    åœ¨ host ä¸Šè§£æä¸€ä¸ªæ ·æœ¬çš„ tokenized_promptï¼Œè¿”å›:
      â€¢ window: np.int32[2] = [s_idx, e_idx]
      â€¢ keep_idx: np.int32[L-2] â€”â€” å»æ‰ s/e ä¸¤ä¸ªä½ç½®åï¼Œä¿ç•™çš„ L-2 ä¸ªæ–‡æœ¬ä½ç½®ç´¢å¼•
    è‹¥æœªæ‰¾åˆ°æˆ–ä¸åˆæ³•ï¼ŒæŠ›å‡ºå¼‚å¸¸ã€‚
    """
    arr = np.asarray(prompt_np).tolist()
    L = len(arr)
    s_pos = [i for i, t in enumerate(arr) if t == start_id]
    e_pos = [i for i, t in enumerate(arr) if t == end_id]
    if len(s_pos) != 1 or len(e_pos) != 1:
        raise ValueError(
            f"[point-window] expect exactly one <start>/<end>, got start={s_pos}, end={e_pos}"
        )
    s, e = s_pos[0], e_pos[0]
    if not (0 <= s < e < L):
        raise ValueError(f"[point-window] invalid order: start={s}, end={e}, L={L}")
    if not allow_text_between and e != s + 1:
        raise ValueError(
            f"[point-window] found text between <start> and <end> (start={s}, end={e}). "
            "Set allow_text_between_markers=True if this is intentional."
        )
    keep = np.array([i for i in range(L) if i != s and i != e], dtype=np.int32)
    win = np.array([s, e], dtype=np.int32)
    return win, keep

# -------- åœ¨æ—§ / æ–°ä¸¤ç±» Observation ä¹‹é—´ç»Ÿä¸€æŠ½å–ç‚¹äº‘ ----------
def _extract_point_batch(obs) -> tuple[dict[str, jnp.ndarray], jnp.ndarray] | None:
    """
    è¿”å› (pc_dict, batch_mask) æˆ– None

    æ”¯æŒä¸¤ç§æ¥æºï¼š
    1. æ—§ç‰ˆ :  obs.pointcloud_data
       - a) å·²æ˜¯ Sonata å…¼å®¹ dict      â†’ ç›´æ¥ä½¿ç”¨
       - b) [B, P, C] ndarrayï¼ˆCâ‰¥3ï¼ŒæŒ‰ [xyz + extras]ï¼‰â†’ è‡ªåŠ¨å±•å¼€æˆ dictï¼Œå¹¶éœ€æä¾› voxel_size æˆ–æ˜¾å¼ grid
    2. æ–°ç‰ˆ :  obs.point_clouds["pointcloud"]  +  obs.point_cloud_masks["pointcloud"]
    """
    # ---------- ğŸ’¡ æ–°æ¥å£ ----------
    if hasattr(obs, "point_clouds") and "pointcloud" in getattr(obs, "point_clouds"):
        # å½¢çŠ¶: [B, M, 3(grid) + point_feat_dim(feats)]
        pc_arr  = obs.point_clouds["pointcloud"]
        pc_mask = obs.point_cloud_masks["pointcloud"]     # [B]

        B, M, _ = pc_arr.shape
        # SpatialLMâ€‘Qwen çº¦å®š:
        #   0â€‘2 : ä½“ç´ ç½‘æ ¼åæ ‡ (int32)
        #   3â€‘5 : è¿ç»­ xyz (float32)
        #   6+ : å…¶ä»–è¯­ä¹‰ç‰¹å¾
        grid_int = pc_arr[..., :3].astype(jnp.int32)           # (B,M,3)
        coords   = pc_arr[..., 3:6].astype(jnp.float32)        # è¿ç»­ xyz
        feats    = pc_arr[..., 3:].astype(jnp.float32)         # xyz + è¯­ä¹‰

        # ä¸åœ¨ JAX ä¾§åšâ€œä¿®å¤â€ï¼›å±•å¹³/NaN è¿‡æ»¤ç­‰ç•™åˆ° host ä¾§ï¼ˆwrapper å†…ï¼‰åšç¡¬æ ¡éªŒ
        pc_dict = _canonicalize_point_dict(
            dict(coord=coords, grid_coord=grid_int, feat=feats)
        )

        # ç›´æ¥ä½¿ç”¨é™æ€ç»´åº¦ M ä½œä¸º pad é•¿åº¦ï¼Œé¿å… runâ€‘time int()
        # åªè¿”å›å¸§çº§æ©ç  [B]ï¼›åœ¨ embed_inputs ä¸­å†æŒ‰ token ç»´å¹¿æ’­
        return pc_dict, pc_mask

    # ---------- æ—§æ¥å£ ----------
    legacy = getattr(obs, "pointcloud_data", None)
    if legacy is None:
        return None

    # a) å·²ç»æ˜¯ dict
    if isinstance(legacy, dict) and "coord" in legacy:
        pc_dict = _canonicalize_point_dict(legacy)
        # å¼ºå¥‘çº¦ï¼šlegacy-dict å¿…é¡»å·²æ˜¯ Sonata å…¼å®¹æ ¼å¼ï¼›ä¸å¾—åœ¨æ¨¡å‹å†…â€œæ¨æ–­/ä¿®å¤â€ã€‚
        # 1) éœ€è¦æ˜¾å¼æä¾› grid_coordï¼ˆN,3ï¼‰å¹¶ä¸”ä¸º int32 éè´Ÿ
        if "grid_coord" not in pc_dict:
            raise ValueError(
                "Legacy dict ç¼ºå°‘ grid_coordã€‚ä¸¥æ ¼å¯¹é½ SpatialLMï¼šè¯·åœ¨ä¸Šæ¸¸æ˜¾å¼æä¾›éè´Ÿ int32 ä½“ç´ åæ ‡ (N,3)ã€‚"
            )
        # 2) offset/batch è‹¥ç¼ºçœå¯ç”± wrapper æŒ‰ batch é‡å»ºï¼›ä½†ä¸åšä»»ä½•å€¼åŸŸä¿®å¤
    else:
        # b) æ—§æ¥å£è‹¥åªæ˜¯ [B,P,C] åŸå§‹æ•°ç»„ï¼šä¸å†åœ¨æ¨¡å‹å†…ä½“ç´ åŒ–/é‡å»º gridï¼ˆé¿å…â€œè¶Šæƒä¿®å¤â€ï¼‰ã€‚
        raise ValueError(
            "Legacy path æ”¶åˆ° [B,P,C] æ•°ç»„ï¼Œä½†ä¸¥æ ¼æ¨¡å¼ä¸‹æ¨¡å‹ä¸å†ä»£æ›¿ä½ ä½“ç´ åŒ–/æ„é€  gridã€‚"
            "è¯·åœ¨ä¸Šæ¸¸æŠŠç‚¹äº‘è½¬æ¢ä¸º Sonata å…¼å®¹ dictï¼Œæ˜¾å¼æä¾› grid_coord(int32,éè´Ÿ)ã€coord(float32,xyz)ã€feat([xyz,...])ã€‚"
        )

    # legacy è·¯å¾„å‡è®¾æ¯å¸§å›ºå®š P ä¸ªç‚¹
    # æ—§è·¯å¾„åœ¨ä¸¥æ ¼æ¨¡å¼ä¸‹ä»…åšæœ€å°å‡è®¾ï¼šè¿”å›å¸§çº§ True æ©ç ï¼Œç”¨ wrapper å†åšæ›´å¼ºæ ¡éªŒ
    if "offset" in pc_dict:
        B = pc_dict["offset"].shape[0]
    elif "batch" in pc_dict:
        B = int(jnp.max(pc_dict["batch"])) + 1 if pc_dict["batch"].size else 0
    else:
        raise ValueError("Legacy dict éœ€åŒ…å« 'offset' æˆ– 'batch' ä»¥æ¨æ–­ batch å°ºå¯¸ã€‚")
    mask = jnp.ones((B,), dtype=bool)
    return pc_dict, mask

# Alias the Sonata class from the sonata_encoder module for convenience
Sonata = sonata_encoder.Sonata

@dataclasses.dataclass(frozen=True)
class Pi0FASTSonataConfig(_pi0_fast.Pi0FASTConfig):
    """Configuration for the Pi0FASTSonata model (Pi0FAST with Sonata point cloud encoder)."""

    # === SpatialLM å¥‘çº¦ ===
    # point_feat_dim å®šä¹‰ä¸ºä¼ å…¥ Sonata çš„ feats ç»´åº¦ï¼ˆä¸å« gridï¼‰ï¼š
    # feats = [xyz(3), extra...]ï¼Œä¾‹å¦‚ xyzrgb â‡’ point_feat_dim = 6
    # Observation.pointcloud çš„æœ€åä¸€ç»´ = 3(grid) + point_feat_dim
    point_feat_dim: int = 6
    # è®©çˆ¶ç±» Pi0FASTConfig.inputs_spec() æŒ‰åŸé€»è¾‘è‡ªåŠ¨æ³¨å…¥ç‚¹äº‘å­—æ®µ
    # ï¼ˆPi0FASTSonata æœ¬èº«ä¸ä¼šç”¨è¿™ä¸ªæšä¸¾å»æ„å»ºæ¨¡å—ï¼Œåªç”¨äº specï¼‰
    point_backbone_type: PointBackboneType = PointBackboneType.SONATA
    # projector_type å¯¹ spec æ— å½±å“ï¼Œè¿™é‡Œä¿æŒ None æˆ– LINEAR å‡å¯
    projector_type: ProjectorType | None = None

    dtype: str = "bfloat16"
    paligemma_variant: _gemma.Variant = "gemma_2b"
    # Inherits default action_dim, action_horizon, max_token_len from Pi0FASTConfig (e.g., 32, 32, 250)
    use_pretrained_point: bool = True      # è°ƒè¯•é˜¶æ®µå¯è®¾ False è·³è¿‡ä¸‹è½½
    # è‹¥ä½¿ç”¨ Sonataï¼Œåˆ™é»˜è®¤**å¿…é¡»**æä¾›ç‚¹äº‘ï¼›ç¼ºå¤±æ—¶ç›´æ¥æŠ¥é”™è€Œä¸æ˜¯é™é»˜é™çº§
    # è‹¥éœ€è¦åªç”¨å›¾åƒ+æ–‡æœ¬åšæ¶ˆèï¼Œå¯æŠŠè¯¥å¼€å…³è®¾ä¸º False
    require_pointcloud: bool = True
    # è‹¥æ— å›¾åƒåˆ™ç›´æ¥ä¸è®­ç»ƒï¼ˆè®­ç»ƒæ—¶æŠ¥é”™ç»ˆæ­¢ï¼›æ¨ç†ä¸å—å½±å“ï¼Œè¿™é‡Œä¸»è¦ç”¨äºè¿›è¡Œè°ƒè¯•ç¡®ä¿æ•°æ®é›†æ­£ç¡®ï¼‰
    require_image: bool = True
    # === åŸä½æ’å…¥ï¼ˆSpatialLM å¯¹é½ï¼‰ ===
    insert_points_in_place: bool = True
    # è¿™ä¸¤ä¸ª id å¿…é¡»ä¸ä½ çš„ tokenizer ä¸­çš„ special tokens ä¸€è‡´
    point_start_id: Optional[int] = None   # ä¾‹å¦‚ tokenizer("<|point_start|>") çš„ id
    point_end_id:   Optional[int] = None   # ä¾‹å¦‚ tokenizer("<|point_end|>")   çš„ id
    # é»˜è®¤ä¸å…è®¸ start/end ä¹‹é—´ä»æœ‰äººç±»æ–‡æœ¬ï¼›è‹¥ä½ çš„æ•°æ®ä¸­ç¡®å®å­˜åœ¨ï¼Œå¯è®¾ True
    allow_text_between_markers: bool = False

    @property
    def model_type(self) -> _model.ModelType:
        # Reuse the PI0_FAST model type (since this is an extension of Pi0-FAST architecture)
        return _model.ModelType.PI0_FAST

    def create(self, rng: jax.Array) -> "Pi0FASTSonata":
        """Instantiate a Pi0FASTSonata model with random initialization."""
        return Pi0FASTSonata(self, rngs=nnx.Rngs(rng))

    # ---- è¦†å†™ inputs_specï¼šä¸¥æ ¼å¯¹é½ SpatialLM çš„ç‚¹äº‘å¸ƒå±€ ----
    def inputs_spec(self, *, batch_size: int = 1) -> tuple[_model.Observation, _model.Actions]:
        image_spec = jax.ShapeDtypeStruct([batch_size, *_model.IMAGE_RESOLUTION, 3], jnp.float32)
        image_mask_spec = jax.ShapeDtypeStruct([batch_size], jnp.bool_)
        with at.disable_typechecking():
            observation_spec = _model.Observation(
                images={
                    "base_0_rgb": image_spec,
                    "base_1_rgb": image_spec,
                    "wrist_0_rgb": image_spec,
                },
                image_masks={
                    "base_0_rgb": image_mask_spec,
                    "base_1_rgb": image_mask_spec,
                    "wrist_0_rgb": image_mask_spec,
                },
                state=jax.ShapeDtypeStruct([batch_size, self.action_dim], jnp.float32),
                tokenized_prompt=jax.ShapeDtypeStruct([batch_size, self.max_token_len], jnp.int32),
                tokenized_prompt_mask=jax.ShapeDtypeStruct([batch_size, self.max_token_len], bool),
                token_ar_mask=jax.ShapeDtypeStruct([batch_size, self.max_token_len], jnp.int32),
                token_loss_mask=jax.ShapeDtypeStruct([batch_size, self.max_token_len], jnp.bool_),
                # ç‚¹äº‘ï¼ˆä¸ SpatialLM çš„ Sonata è¾“å…¥å¥‘çº¦å¯¹é½ï¼‰ï¼š
                #  - coord: è¿ç»­ xyzï¼ˆfloat32ï¼‰
                #  - feat : [xyz, extras...]ï¼ˆfloat32ï¼Œä¸” feat[:,:3] å¿…é¡»ä¸ coord ä¸€è‡´ï¼‰
                #  - batch: æ¯ä¸ªç‚¹å±äºå“ªä¸ªæ ·æœ¬ï¼ˆint64ï¼‰
                #  - grid_coord: éè´Ÿä½“ç´ åæ ‡ï¼ˆint32ï¼Œå¯é€‰ï¼›è‹¥ç¼ºçœå°†ç”± wrapper ç”¨ floor(coord) + é›¶ç‚¹å¹³ç§»é‡å»ºï¼‰
                pointcloud_data={
                    "coord": jax.ShapeDtypeStruct([batch_size, self.max_points, 3], jnp.float32),
                    "feat":  jax.ShapeDtypeStruct([batch_size, self.max_points, self.point_feat_dim], jnp.float32),
                    # JAX ç«¯ int32ï¼›host ç«¯å‡è‡³ int64
                    "batch": jax.ShapeDtypeStruct([batch_size, self.max_points], jnp.int32),
                    "grid_coord": jax.ShapeDtypeStruct([batch_size, self.max_points, 3], jnp.int32),
                },
            )
        action_spec = jax.ShapeDtypeStruct([batch_size, self.action_horizon, self.action_dim], jnp.float32)
        return observation_spec, action_spec
class Pi0FASTSonata(_model.BaseModel):
    """
    Pi0FASTSonata model: Extends Pi0-FAST to incorporate a Sonata point cloud encoder.
    Combines vision (SigLIP image encoder), language (PaLI-Gemma LLM), and point cloud (Sonata) encoders.
    """
    def __init__(self, config: Pi0FASTSonataConfig, rngs: nnx.Rngs):
        # Initialize base model (setup action_dim, action_horizon, etc.)
        super().__init__(config.action_dim, config.action_horizon, config.max_token_len)

        # --------------------------------------------------------------
        # è®°å½•æ˜¯å¦å¼ºåˆ¶è¦æ±‚ç‚¹äº‘
        self._require_pointcloud = bool(getattr(config, "require_pointcloud", True))
        self._require_image = bool(getattr(config, "require_image", True))
        # è®¾å®šç»Ÿä¸€ deviceï¼ˆGPU å¦‚æœå¯ç”¨ï¼Œå¦åˆ™ CPUï¼‰
        # --------------------------------------------------------------
        self.device: torch.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        
        # ------------------------------------------------------------------
        # 1) è¯­è¨€æ¨¡å‹  Gemma  ------------------------------------------------
        # ------------------------------------------------------------------
        # ------------------------------------------------------------------
        # Gemmaâ€‘fast LLM ----------------------------------------------------
        # ------------------------------------------------------------------
        pal_cfg = _gemma.get_config(config.paligemma_variant)

        # æ ¹æ® gemma_fast.Module çš„ __init__ ç­¾åè‡ªåŠ¨æ”¶é›†éœ€è¦çš„å‚æ•°
        gemma_sig = inspect.signature(_gemma.Module.__init__)
        pal_kwargs: dict[str, typing.Any] = {}
        for name in gemma_sig.parameters:
            if name == "self":          # è·³è¿‡ self
                continue
            if hasattr(pal_cfg, name):
                pal_kwargs[name] = getattr(pal_cfg, name)

        # è‹¥ get_config æ²¡è¿”å› variantï¼Œåˆ™ç”¨ä¼ å…¥çš„æšä¸¾å­—ç¬¦ä¸²è¡¥é½
        pal_kwargs.setdefault("variant", config.paligemma_variant)

        # å…¶å®ƒ dtype ç›¸å…³è¦†å†™
        pal_kwargs["embed_dtype"] = config.dtype
        pal_kwargs["cache_dtype"] = config.dtype

        llm = nnx_bridge.ToNNX(_gemma.Module(**pal_kwargs))

        # åˆå§‹åŒ–
        llm.lazy_init(rngs=rngs, method="init")

        # ------------------------------------------------------------------
        # 2) å›¾åƒç¼–ç å™¨  SigLIP  --------------------------------------------
        # ------------------------------------------------------------------
        _model_width = getattr(pal_cfg, "width", getattr(pal_cfg, "hidden_size", 1024))
        
        raw_img_kwargs = dict(
            # _siglip.Module å¯èƒ½ä¸éœ€è¦ num_classesï¼›å¦‚æœ signature é‡Œæ²¡æœ‰ä¼šè¢«è‡ªåŠ¨ä¸¢å¼ƒ
            num_classes=_model_width,
            variant="So400m/14",
            pool_type="none",
            scan=True,
            dtype_mm=config.dtype,
        )

        # ---------------------------------------------------------------------------------

        img = nnx_bridge.ToNNX(_siglip.Module(**raw_img_kwargs))

        # Initialize image encoder with a dummy image to set dimensions
        dummy_image = next(iter(config.fake_obs(batch_size=1).images.values()))
        img.lazy_init(dummy_image, train=False, rngs=rngs)

        # ------------------------------------------------------------------
        # 3) åˆ›å»ºå¹¶åŠ è½½ç‚¹äº‘ç¼–ç å™¨ (Sonata) â€” å‚æ•°å¯¹é½ SpatialLMâ€‘1.1, åé¢å¯ä»¥æ”¹æˆconfigä¼ è¾“
        # ------------------------------------------------------------------
        
        # ---------- Sonata hyperâ€‘params â€“ ä¸ ckpt ä¿æŒ 100â€¯% ä¸€è‡´ ----------
        # in_channels = feats ç»´åº¦ï¼ˆä¸å« grid çš„3åˆ—ï¼‰
        if not hasattr(config, "point_feat_dim"):
            raise ValueError(
                "Pi0FASTSonataConfig éœ€æ˜¾å¼æä¾› point_feat_dimï¼ˆ= feats ç»´åº¦ï¼Œxyz+extrasï¼Œä¸å« gridï¼‰"
            )
        # ä¸ SpatialLM å¥‘çº¦ä¸€è‡´ï¼šin_channels = feats åˆ—æ•°ï¼ˆå« xyzï¼Œä¸å« gridï¼‰
        _in_channels = int(config.point_feat_dim)  # e.g., xyzrgb -> 6
        if _in_channels < 3:
            raise ValueError(
                f"é…ç½® point_feat_dim={config.point_feat_dim} æ— æ•ˆï¼Œé¡» â‰¥ 3ï¼ˆè‡³å°‘åŒ…å«è¿ç»­ xyzï¼‰"
            )
        # è‹¥åç»­è¾“å…¥ç‚¹äº‘ç‰¹å¾ç»´ä¸é…ç½®ä¸ç¬¦ï¼Œå°†åœ¨ embed_inputs æ—©æœŸæŠ¥é”™

        # è‹¥æœªå®‰è£… flash_attnï¼Œè‡ªåŠ¨ç¦ç”¨ä»¥é¿å…æ–­è¨€å¤±è´¥
        _enable_flash = (getattr(sonata_encoder, "flash_attn", None) is not None)
        if not _enable_flash and not getattr(Pi0FASTSonata, "_warned_no_flash", False):
            logger.warning("[Sonata] flash-attn not found; falling back to non-flash path (slower, it is highly recommended to use flash-attn).")
            Pi0FASTSonata._warned_no_flash = True
        sp_cfg = dict(
            in_channels   = _in_channels,
            order         = ("z", "z-trans"),
            stride        = (2, 2, 2, 2),         # 5â€‘stage â‡’ 4 æ¬¡ä¸‹é‡‡æ ·
            enc_depths    = (3, 3, 3, 12, 3),
            enc_channels  = (48, 96, 192, 384, 512),   # â˜… æœ«ç«¯ 512
            enc_num_head  = (3, 6, 12, 24, 32),
            enc_patch_size= (1024,)*5,            # ckpt é»˜è®¤
            mlp_ratio     = 4.0,
            mask_token    = True,                   # Sonata.Embedding ä¸­ mask_token åŠŸèƒ½è¢«ç¦ç”¨ï¼Œæ­¤å‚æ•°æ— æ•ˆ
            enc_mode=True,  # å³voxel
            enable_fourier_encode = True,         # â˜… ckpt å« fourier+input_proj
            num_bins      = 1280,
            enable_flash  = _enable_flash,
        )
        point_model = Sonata(**sp_cfg)
        # è®°å½•ä¾›åç»­æ–­è¨€ï¼Projector ä½¿ç”¨
        self._point_in_channels = _in_channels  # feats ç»´åº¦ï¼ˆxyz+extrasï¼‰
        # ä¸ SpatialLM ä¸€è‡´ï¼šproj è¾“å…¥ç»´ = ç¼–ç å™¨æœ«å±‚é€šé“
        self._enc_out_dim = sp_cfg["enc_channels"][-1]

        if config.use_pretrained_point:
            # ------------------------------------------------------------------
            # ä»…ä½¿ç”¨æœ¬åœ°ç²¾ç®€åçš„ SpatialLM1.1 Sonata æƒé‡
            # æ–‡ä»¶æ”¾ç½®: <repo_root>/openpi/pretrain/SpatialLM_Sonata_encoder.pth
            # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œè¯·ä½¿ç”¨uv run scripts/sonata_weight_gen.pyæ¥è·å–sonataçš„checkpoint
            # ------------------------------------------------------------------
            # è·¯å¾„æŒ‡å‘ <repo_root>/src/pretrain/
            ckpt_path = (
                Path(__file__).resolve().parents[2]  # -> â€¦/openpi/src
                / "pretrain" / "SpatialLM_Sonata_encoder.pth"
            )
            if not ckpt_path.is_file():
                raise FileNotFoundError(
                    f"Sonata é¢„è®­ç»ƒæƒé‡æœªæ‰¾åˆ°: {ckpt_path}\n"
                    "è¯·å…ˆè¿è¡Œ scripts/sonata_weight_gen.py ç”Ÿæˆæ–‡ä»¶ï¼Œ"
                    "å¹¶æ”¾ç½®åˆ° src/pretrain/ ç›®å½•ã€‚"
                )
            logger.info("Using local Sonata weights: %s", ckpt_path)


            # åŠ è½½æƒé‡ â€”â€” PyTorch 2.6+ é»˜è®¤ weights_only=Trueï¼Œä¼šæ‹¦ä½åŒ…å«
            # numpy æ ‡é‡çš„è€å¼ state_dictï¼Œè¿™é‡Œæ˜¾å¼å…³æ‰å³å¯ã€‚
            load_kwargs = dict(map_location="cpu")
            if "weights_only" in inspect.signature(torch.load).parameters:
                load_kwargs["weights_only"] = False

            raw_obj = torch.load(ckpt_path, **load_kwargs)

            # â‘ è‹¥æ˜¯è®­ç»ƒ checkpointï¼Œå…ˆå–å‡ºçœŸæ­£æƒé‡
            if isinstance(raw_obj, dict) and "state_dict" in raw_obj:
                state_dict = raw_obj["state_dict"]
            else:
                state_dict = raw_obj

            # â‘¡å»æ‰å¤šä½™å‰ç¼€ï¼ˆå¦‚ "module." æˆ– "model.")
            cleaned = {}
            for k, v in state_dict.items():
                if k.startswith(("module.", "model.", "student.backbone.", "student.", "point_backbone.")):
                    cleaned[k.split(".", 1)[1]] = v
                else:
                    cleaned[k] = v

            # â‘¡â€‘bisï¼šæŒ‰æƒé‡â€œæ¨æ–­â€ in_channelsï¼Œä¸€è‡´æ€§ä¿æŠ¤
            wkey = "embedding.stem.linear.weight"
            if wkey in cleaned:
                in_from_ckpt = cleaned[wkey].shape[1]  # [out, in]
                if in_from_ckpt != self._point_in_channels:
                    logger.warning(
                        "Sonata ckpt in_channels=%d != configured point_feat_dim=%d; "
                        "rebuilding Sonata to match checkpoint (prefer checkpoint to avoid shape mismatch).",
                        in_from_ckpt, self._point_in_channels
                    )
                    # é‡æ–°æ„å»ºä¸æƒé‡ä¸€è‡´çš„ Sonataï¼Œå†è½½å…¥
                    sp_cfg_ckpt = {**sp_cfg, "in_channels": int(in_from_ckpt)}
                    point_model = Sonata(**sp_cfg_ckpt)
                    point_model.to(self.device).eval()
                    self._point_in_channels = int(in_from_ckpt)
                    self._enc_out_dim = sp_cfg_ckpt["enc_channels"][-1]

            # â‘¢éƒ¨åˆ†åŒ¹é…å³å¯ï¼›strict=False ä¼šè·³è¿‡å¤šä½™é”®ï¼Œä¹Ÿä¼šæç¤ºå“ªäº›æ²¡åŠ è½½
            ik = point_model.load_state_dict(cleaned, strict=False)
            if getattr(ik, "missing_keys", None):
                mk = ik.missing_keys
                logger.warning("Sonata weights: %d missing params, e.g. %s", len(mk), mk[:5])
            if getattr(ik, "unexpected_keys", None):
                uk = ik.unexpected_keys
                logger.warning("Sonata weights: %d unexpected params, e.g. %s", len(uk), uk[:5])

            logger.info("Loaded pretrained Sonata weights from %s", ckpt_path)

        else:
            logger.warning(
                "Pi0FASTâ€‘Sonata: use_pretrained_point=False -> "
                "Sonata encoder starts with random weights."
            )

        # -------- ä¿è¯ Sonata æ•´ä¸ªç½‘ç»œåœ¨ GPUï¼ˆå« spconv kernelï¼‰ --------
        point_model.to(self.device)
        point_model.eval()  # inference mode

        # ------------------------------------------------------------------
        # 4) å®šä¹‰ _TorchSonataWrapper â€”â€” ä¿æŒåŸ APIï¼Œæ–°å¢ GPU æ”¯æŒ
        # ------------------------------------------------------------------
        class _TorchSonataWrapper(torch.nn.Module):
            """
            - è¿½è¸ªæœŸï¼ˆJIT / lazy_initï¼‰åªè¿”å› ShapeDtypeStructï¼Œä¸è·‘çœŸæ¨¡å‹ã€‚
            - è¿è¡ŒæœŸé€šè¿‡ pure_callback æŠŠ numpy â†’ torch.cuda â†’ numpyã€‚
            """
            def __init__(
                self,
                pt_model: torch.nn.Module,
                device: torch.device,
                patch_size: int,
                enc_out_dim: int,
            ):
                super().__init__()
                # ç¡®ä¿ pt_model å·²åœ¨ç›®æ ‡ device
                self.inner = pt_model.to(device).eval()
                self.device = device
                self.patch_size = patch_size
                self.enc_out_dim = enc_out_dim

            # ---------- å†…éƒ¨ util ----------
            @staticmethod
            @torch.no_grad()
            def _torch_forward(
                inner: torch.nn.Module,
                host_dict: Dict[str, np.ndarray],
                device: torch.device,
                patch_size: int,
                enc_out_dim: int,
            ) -> Tuple[np.ndarray, np.ndarray]:  # ç¬¬ 2 ä¸ª ndarray æ˜¯ bool æ©ç 
                """
                æ¥æ”¶ host ä¸Šçš„ numpy è¾“å…¥ â†’ torch.Tensor.cuda â†’ è¿è¡Œ â†’ numpy è¾“å‡º
                ç»Ÿä¸€è¿”å› float32 numpy æ•°ç»„
                """

                # ---------- fastâ€‘pathï¼šè¯¥å¸§ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›å…¨é›¶ ----------
                present = int(host_dict.pop("present", 1))
                if present == 0:
                    pad_feat   = np.zeros((patch_size, enc_out_dim), dtype=np.float32)
                    valid_mask = np.zeros((patch_size,),       dtype=bool)
                    return pad_feat, valid_mask
                
                # =========================================================
                # â˜… æ–°å¢ï¼šè‹¥ä¸Šæ¸¸ä¼ å…¥ selected_batchï¼Œåªä¿ç•™è¿™ä¸€å¸§çš„ç‚¹
                #   (è¿™æ · embed_inputs é‡Œä¸ç”¨ v[sel]ï¼Œé¿å… JAX å¸ƒå°”åˆ‡ç‰‡æŠ¥é”™)
                # ---------------------------------------------------------
                if "selected_batch" in host_dict:
                    sb = int(host_dict.pop("selected_batch"))
                    if "batch" in host_dict:
                        b_arr = np.asarray(host_dict["batch"]).reshape(-1)
                        sel = (b_arr == sb)                     # sel.shape == (B*M,)
                        # 1) å…ˆæŒ‰ç‚¹çº§åˆ«åˆ‡æ‰€æœ‰â€œå±•å¹³â€çš„å¼ é‡ï¼ˆcoord/feat/batch ç­‰ï¼‰
                        for k, v in list(host_dict.items()):
                            if hasattr(v, "shape") and v.ndim and v.shape[0] == sel.shape[0]:
                                host_dict[k] = v[sel]
                        # 2) å†å¯¹â€œæŒ‰å¸§æ‰“åŒ…â€çš„å¼ é‡åˆ‡ç¬¬ 0 ç»´ï¼ˆå…¸å‹ï¼šgrid_coord[B,M,3]ã€grid_size[B,3]ï¼‰
                        #    æ¨æ–­ Bï¼šä¼˜å…ˆç”¨ offset é•¿åº¦ï¼Œå¦åˆ™ç”¨ batch ä¸­çš„æœ€å¤§å€¼+1
                        if "offset" in host_dict:
                            B = int(np.asarray(host_dict["offset"]).reshape(-1).shape[0])
                        else:
                            B = int(b_arr.max()) + 1 if b_arr.size else 0
                        if B:
                            for k, v in list(host_dict.items()):
                                if hasattr(v, "shape") and v.ndim >= 2 and v.shape[0] == B:
                                    host_dict[k] = v[sb]
                    else:
                        # æ—  batch é”®ï¼šæŒ‰ç¬¬ 0 ç»´æ˜¯ batch è½´å¤„ç†ï¼ˆv çš„å½¢çŠ¶å½¢å¦‚ (B, M, ...) æˆ– (B, 3)ï¼‰
                        for k, v in list(host_dict.items()):
                            if hasattr(v, "shape") and v.ndim >= 2 and v.shape[0] > sb:
                                host_dict[k] = v[sb]
                    # å•æ ·æœ¬è¯­ä¹‰ï¼šbatch å…¨ 0ï¼Œoffset = [ç‚¹æ•°]
                    n_pts = int(host_dict["coord"].shape[0])
                    host_dict["batch"]  = np.zeros(n_pts, dtype=np.int64)
                    host_dict["offset"] = np.array([n_pts], dtype=np.int64)
                # =========================================================

                # ---------- å…ˆå®‰å…¨æ‰å¹³åŒ– ----------
                if host_dict["coord"].ndim != 2:         # (B,N,3) â†’ (B*N,3)
                    B, N, _ = host_dict["coord"].shape
                    host_dict["coord"] = host_dict["coord"].reshape(B * N, 3)
                    host_dict["feat"]  = host_dict["feat"].reshape(B * N, -1)
                    host_dict["batch"] = np.repeat(np.arange(B, dtype=np.int64), N)
                    host_dict["offset"] = np.cumsum(np.full((B,), N, dtype=np.int64))

                # grid_coord å¯èƒ½æ¥è‡ªä½“ç´ ç½‘æ ¼ â†’ ä¿è¯æ˜¯ (P,3)
                for _key in ("grid_coord",):
                    if _key in host_dict and host_dict[_key].ndim == 3:
                        host_dict[_key] = host_dict[_key].reshape(-1, 3)
                
                # ---------- grid éè´Ÿæ€§æ£€æŸ¥ï¼ˆhost ä¾§ï¼ŒJIT å®‰å…¨ï¼‰ ----------
                if "grid_coord" not in host_dict:
                    raise ValueError(
                        "[SpatialLMâ€‘Sonata] ç¼ºå°‘ grid_coordï¼›"
                        "ä¸¥æ ¼æ¨¡å¼è¦æ±‚ä¸Šæ¸¸æ˜¾å¼æä¾›éè´Ÿ int32 ä½“ç´ åæ ‡ (N,3)ã€‚"
                        "è¯·å°† Observation.point_clouds['pointcloud'] çš„å‰ 3 åˆ—ä½œä¸º grid ä¼ å…¥ï¼Œæˆ–åœ¨ legacy dict ä¸­æä¾› 'grid_coord'ã€‚"
                    )
                gc = host_dict["grid_coord"]
                if gc.ndim == 3:
                    gc = gc.reshape(-1, 3)
                    host_dict["grid_coord"] = gc
                if gc.shape[1] != 3:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] grid_coord ç»´åº¦é”™è¯¯ï¼šæœŸå¾… (N,3)ï¼Œå®é™… {gc.shape}ã€‚")
                if not np.issubdtype(gc.dtype, np.integer):
                    raise ValueError(f"[SpatialLMâ€‘Sonata] grid_coord dtype å¿…é¡»ä¸ºæ•´æ•°ï¼ˆå»ºè®® int32ï¼‰ï¼Œå®é™… {gc.dtype}ã€‚")
                if np.any(gc < 0):
                    raise ValueError("[SpatialLMâ€‘Sonata] grid_coord å«è´Ÿå€¼ï¼›è¯·åœ¨ä¸Šæ¸¸ä½“ç´ åŒ–æ—¶ä¿è¯æ¯ç»´ç´¢å¼• â‰¥ 0ã€‚")
                # ---- coord / feat å½¢çŠ¶&dtype ä¸¥æ ¼æ ¡éªŒï¼ˆçº¯æŠ¥é”™ï¼Œä¸åšè½¬æ¢ï¼Œè¿™æ˜¯ä¸ºäº†ç¡®ä¿èƒ½æ‰¾åˆ°æ•°æ®é›†çš„é”™è¯¯è€Œä¸ä¼šé”™è¯¯åœ°æŠŠé”™è¯¯åœ°æ•°æ®é›†ç»™å¼„å¾—å¯ç”¨é€ æˆsilent errorï¼‰ ----
                c = host_dict["coord"]
                f = host_dict["feat"]
                if c.ndim != 2 or c.shape[1] != 3:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] coord å½¢çŠ¶å¿…é¡»ä¸º (N,3)ï¼Œå®é™… {c.shape}ã€‚")
                if f.ndim != 2:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] feat å½¢çŠ¶å¿…é¡»ä¸º (N,C)ï¼Œå®é™… {f.shape}ã€‚")
                if c.dtype != np.float32:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] coord dtype å¿…é¡»ä¸º float32ï¼Œå®é™… {c.dtype}ã€‚")
                if f.dtype != np.float32:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] feat dtype å¿…é¡»ä¸º float32ï¼Œå®é™… {f.dtype}ã€‚")
                # ---- batch/offsetï¼ˆå¦‚æä¾›ï¼‰ä¸€è‡´æ€§æ ¡éªŒ ----
                if "batch" in host_dict:
                    b = host_dict["batch"]
                    if b.ndim != 1:
                        raise ValueError(f"[SpatialLMâ€‘Sonata] batch å¿…é¡»æ˜¯ä¸€ç»´å‘é‡ (N,)ï¼Œå®é™… {b.shape}ã€‚")
                    if b.shape[0] != c.shape[0]:
                        raise ValueError(f"[SpatialLMâ€‘Sonata] batch é•¿åº¦ {b.shape[0]} ä¸ç‚¹æ•° {c.shape[0]} ä¸ä¸€è‡´ã€‚")
                    if not np.issubdtype(b.dtype, np.integer):
                        raise ValueError(f"[SpatialLMâ€‘Sonata] batch dtype å¿…é¡»ä¸ºæ•´æ•°ï¼Œå®é™… {b.dtype}ã€‚")
                    if np.any(b < 0):
                        raise ValueError("[SpatialLMâ€‘Sonata] batch å«è´Ÿå€¼ã€‚")
                if "offset" in host_dict:
                    off = host_dict["offset"]
                    if off.ndim != 1:
                        raise ValueError(f"[SpatialLMâ€‘Sonata] offset å¿…é¡»æ˜¯ä¸€ç»´å‘é‡ (B,)ï¼Œå®é™… {off.shape}ã€‚")
                    if not np.issubdtype(off.dtype, np.integer):
                        raise ValueError(f"[SpatialLMâ€‘Sonata] offset dtype å¿…é¡»ä¸ºæ•´æ•°ï¼Œå®é™… {off.dtype}ã€‚")
                    if np.any(off <= 0) or np.any(off[1:] < off[:-1]):
                        raise ValueError("[SpatialLMâ€‘Sonata] offset å¿…é¡»ä¸ºä¸¥æ ¼é€’å¢çš„å‰ç¼€å’Œã€‚")
                    if off[-1] != c.shape[0]:
                        raise ValueError(f"[SpatialLMâ€‘Sonata] offset[-1]={off[-1]} ä¸ç­‰äºç‚¹æ•° N={c.shape[0]}ã€‚")
                # SpatialLM æœªå¯¹ä¸Šç•Œåšç¡¬æ–­è¨€ï¼›è‹¥å®ç°æš´éœ²äº† reduced_grid_sizeï¼Œä»…è­¦å‘Šä¸€æ¬¡
                if getattr(inner, "enable_fourier_encode", False) and hasattr(inner, "reduced_grid_size"):
                    reduced_gs = int(getattr(inner, "reduced_grid_size"))
                    if np.any(gc >= reduced_gs) and not getattr(_TorchSonataWrapper, "_warned_grid_upper", False):
                        warnings.warn(
                            f"[Sonata] grid_coord è¶…è¿‡ reduced_grid_size={reduced_gs}ï¼›å¦‚å‡ºç°ç²¾åº¦/æ€§èƒ½å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ä½“ç´ åŒ–é…ç½®ã€‚",
                            RuntimeWarning
                        )
                        _TorchSonataWrapper._warned_grid_upper = True
                
                # grid_coord ä¸ coord ç‚¹æ•°å¿…é¡»ä¸€è‡´
                if host_dict["grid_coord"].shape[0] != host_dict["coord"].shape[0]:
                    raise ValueError(
                        f"[SpatialLMâ€‘Sonata] ç‚¹æ•°ä¸ä¸€è‡´ï¼šgrid_coord N={host_dict['grid_coord'].shape[0]} "
                        f"â‰  coord N={host_dict['coord'].shape[0]}ã€‚"
                    )

                # æ— è®ºä¸Šæ¸¸å¦‚ä½•ï¼Œfeat å¿…é¡»ä¸º 2â€‘Dï¼›ä¸ SpatialLM å¯¹é½
                if host_dict["feat"].ndim != 2:
                    C = host_dict["feat"].shape[-1]
                    host_dict["feat"] = host_dict["feat"].reshape(-1, C)

                
                # ---------- è‹¥ç¼º offsetï¼Œåˆ™æ ¹æ® batch ç”Ÿæˆ ----------
                if "offset" not in host_dict:
                    if "batch" in host_dict:
                        # --------------------------------------------------
                        # 1. ä¿è¯ batch æ˜¯ 1â€‘D int64
                        # --------------------------------------------------
                        b_arr = np.asarray(host_dict["batch"]).astype(np.int64)
                        if b_arr.ndim > 1:
                            b_arr = b_arr.reshape(-1)
                        host_dict["batch"] = b_arr

                        # 2. ç»Ÿè®¡æ¯ä¸ª batch çš„ç‚¹æ•° â†’ å‰ç¼€å’Œ
                        counts = np.bincount(b_arr)
                        host_dict["offset"] = np.cumsum(counts, dtype=np.int64)
                    else:
                        # å• batch æƒ…å½¢
                        host_dict["offset"] = np.array(
                            [host_dict["coord"].shape[0]], dtype=np.int64
                        )

                assert host_dict["coord"].shape[0] == host_dict["offset"][-1], (
                    f"coord N={host_dict['coord'].shape[0]}, "
                    f"but offset[-1]={host_dict['offset'][-1]}"
                )

                # ---------- NaN è¿‡æ»¤ï¼šä¸ SpatialLMâ€‘Qwen å®Œå…¨ä¸€è‡´ ----------
                nan_mask = (
                    np.isnan(host_dict["coord"]).any(axis=1)
                    | np.isnan(host_dict["feat"]).any(axis=1)
                )
                if nan_mask.any():
                    keep = ~nan_mask
                    for k in ("coord", "feat", "grid_coord"):
                        if k in host_dict:
                            host_dict[k] = host_dict[k][keep]
                    host_dict["batch"] = host_dict["batch"][keep]
                    # é‡æ–°è®¡ç®— offset  (prefixâ€sum of perâ€‘batch counts)
                    counts = np.bincount(host_dict["batch"])
                    host_dict["offset"] = np.cumsum(counts, dtype=np.int64)
                
                # ===== SpatialLMâ€‘style ç©ºç‚¹äº‘ä¿æŠ¤ =====
                if host_dict["coord"].shape[0] == 0:
                    # è¿”å›å…¨é›¶ç‰¹å¾ + å…¨ False æœ‰æ•ˆæ ‡è®°ï¼ˆç»´åº¦ä¸æ­£å¸¸è·¯å¾„ä¸€è‡´ï¼‰
                    pad_feat   = np.zeros((patch_size, enc_out_dim), dtype=np.float32)
                    valid_mask = np.zeros((patch_size,),       dtype=bool)
                    return pad_feat, valid_mask

                # ä¸¥æ ¼æ¨¡å¼ï¼šä¸å†åœ¨æ¨¡å‹å†…â€œé‡å»º/åç§»â€ gridã€‚ç¼ºå¤±å·²åœ¨å‰é¢æŠ¥é”™ã€‚
                
                # ---------- å¥‘çº¦æ ¡éªŒï¼šfeat å‰ 3 ç»´åº”ä¸ coordï¼ˆè¿ç»­ xyzï¼‰ä¸€è‡´ ----------
                if host_dict["feat"].shape[1] >= 3:
                    max_abs = float(np.max(np.abs(host_dict["feat"][:, :3] - host_dict["coord"])))
                    if not np.isfinite(max_abs) or max_abs > 1e-4:
                        raise ValueError(
                            f"[SpatialLMâ€‘Sonata] å¥‘çº¦ä¸æ»¡è¶³ï¼šfeat[:,:3]ï¼ˆåº”ä¸º xyzï¼‰ä¸ coord ä¸ä¸€è‡´ï¼›"
                            f"max|diff|={max_abs:.3e}ã€‚è¯·ä¿è¯ feats = [xyz, extras] ä¸” coord=xyzã€‚"
                        )

                # pure_callback æŠŠ jax.Array ç›´æ¥é€è¿‡æ¥ï¼›å¿…é¡»å…ˆè½¬æˆçœŸæ­£çš„ numpy
                # æ˜¾å¼ copyï¼šé¿å… "The given NumPy array is not writable" è­¦å‘Š
                tch_in = {
                    k: torch.from_numpy(np.array(v, copy=True)).to(device)
                    for k, v in host_dict.items()
                }
                # Sonata é‡Œè¦åš (batch << 48)ï¼Œå¿…é¡»æ˜¯ int64
                for key in ("batch", "offset"):
                    if key in tch_in:
                        tch_in[key] = tch_in[key].long()
                out = inner(tch_in)
                # SpatialLM çº¦å®šï¼šSonata.forward() è¿”å› torch.Tensorï¼ˆæœ€ç»ˆç‰¹å¾ï¼‰
                if not isinstance(out, torch.Tensor):
                    raise TypeError(
                        f"Sonata.forward is expected to return a torch.Tensor "
                        f"(as in SpatialLM), but got: {type(out)}. "
                        f"Please ensure Sonata.forward returns the feature tensor."
                    )

                real_len = out.size(0)
                if real_len > patch_size:
                    raise RuntimeError(
                        f"[SpatialLMâ€‘Sonata] token_len={real_len} è¶…è¿‡ä¸Šé™ patch_size={patch_size}ã€‚"
                        "è¯·å¢å¤§ Sonata enc_patch_size[-1]ï¼ˆä¼šå¢æ˜¾å­˜ï¼‰æˆ–åœ¨ä¸Šæ¸¸å‡å°‘æ¯æ ·æœ¬ç‚¹æ•°ã€‚"
                    )
                # SpatialLM: ä¸æˆªæ–­ï¼›å³ pad åˆ° patch_size çš„å€æ•°
                # --- ä¿ç•™å›ºå®š 1024â€‘padding ä»¥ç»´æŒé™æ€ shape (JAX éœ€æ±‚ï¼Œæ”¹æˆä¸å›ºå®šçš„ä»£ä»·å¾ˆå¤§ï¼Œå¦‚æœå•çº¯åŠ å¤§åˆ™å®¹æ˜“ç‚¸æ˜¾å­˜) ---
                # ------------------------------------------------------------------
                # æˆªæ–­å‰åšæ˜¾å¼æŠ¥è­¦ï¼šè¿™ä¸ªæ˜¯å› ä¸ºå¦‚æœæˆ‘ä»¬è¦æ”¹æˆéå›ºå®šï¼Œä¼šå¯¼è‡´æ— æ³•jaxåŒ–ï¼Œè®¡ç®—ä»£ä»·å¾ˆå¤§ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨è¿™ç§æ–¹å¼è¿›è¡Œæµ‹è¯•ï¼Œæ¥çœ‹çœ‹æ•°æ®é›†èƒ½ä¸èƒ½æä¾›åˆç†æ•°æ®
                # ------------------------------------------------------------------
                MAX_TOKEN = patch_size                  # =1024 (enc_patch_size[-1])
                if real_len > MAX_TOKEN:
                    # ç›´æ¥é˜»æ–­ï¼šç”¨æˆ·å¿…é¡»æ˜¾å¼æé«˜ enc_patch_size[-1] æˆ–å‡å°‘ç‚¹æ•°
                    raise RuntimeError(
                        f"[Sonata] token_len={real_len} exceeds configured MAX_TOKEN "
                        f"({MAX_TOKEN}). Increase `enc_patch_size[-1]` or reduce the "
                        "number of points per sample."
                    )
                pad_len = MAX_TOKEN - real_len
                if pad_len:
                    pad = out.new_zeros(pad_len, out.size(1))
                    out = torch.cat([out, pad], 0)
                valid_mask = np.arange(MAX_TOKEN) < real_len
                return out.float().cpu().numpy(), valid_mask

            # ---------- forward ----------
            def forward(self, pc_dict, *, train: bool = False):
                host_inputs = {k: jnp.asarray(v) for k, v in pc_dict.items()}
                # tree_flatten è¿”å› (flat_list, treedef)ï¼›åè€…è´Ÿè´£åå‘å±•å¼€
                flat, treedef = jax.tree_util.tree_flatten(host_inputs)

                # -----------------------------------------------------------
                # ä¾‹å¦‚é™æ€ä¸Šé™, è¿™é‡Œè®¾ç½®1024ï¼Œå¯ä»¥è®¾ç½®8192 (= 8 patch)ï¼›ç¡®ä¿ä¸ä¼šåœ¨çœŸå®è¾“å…¥ä¸­è¶…å‡ºä½†æ˜¯è¿™æ ·ä¼šç‚¸æ˜¾å­˜,æ‰€ä»¥æˆ‘ä»¬ä¿ç•™1024å®ç°, åç»­å¯ä»¥ç»§ç»­åŠ 
                # patch_size ç”± Wrapper æ„é€ å‡½æ•°ä¼ å…¥ï¼›ä¿æŒä¸ Sonata enc_patch_size ä¸€è‡´
                MAX_TOKEN = self.patch_size
                C = self.enc_out_dim
                out_struct = (ShapeDtypeStruct((MAX_TOKEN, C), jnp.float32),
                              ShapeDtypeStruct((MAX_TOKEN,),  jnp.bool_))

                def _host_call(*flat_np):
                    # flat_np æ˜¯å›ä¼ çš„æ‰å¹³åˆ—è¡¨/å…ƒç»„ï¼Œéœ€ç”¨ treedef.unflatten è¿˜åŸ
                    np_dict = treedef.unflatten(list(flat_np))
                    return self._torch_forward(
                        self.inner, np_dict, self.device, self.patch_size, self.enc_out_dim
                    )

                feat, valid_mask = pure_callback(
                    _host_call, out_struct, *flat, vectorized=False
                )

                # ---- Runtime contract check: channel dim must match projector ----
                assert feat.shape[-1] == self.enc_out_dim, (
                    f"[SonataWrapper] Output dim {feat.shape[-1]} "
                    f"!= expected {self.enc_out_dim}. "
                    "Check Sonata ckpt / config."
                )
                # ç›´æ¥è¿”å› (feat, valid_mask)ï¼›ç”±è°ƒç”¨æ–¹è‡ªè¡Œæ„é€  mask
                return feat, valid_mask

            # ---------- NNX åˆå§‹åŒ– ----------
            def init_with_output(
                self,
                rngs,
                pc_dict,
                *,
                train: bool = False,
                method: typing.Any = None,
                **_,
            ):
                dummy_out = self.forward(pc_dict, train=train)
                return dummy_out, {}  # æœ¬ wrapper ä¸å«å¯è®­ç»ƒå‚æ•°

            # --------------------------------------------------------------
            # â˜… å…¼å®¹ nnxâ€‘bridge è°ƒç”¨ï¼šé‡è½½ applyï¼Œå¿½ç•¥ variables / rngs. ä»¥åéœ€è¦rngéœ€è¦å°†å…¶ä¼ å…¥ä½†ç›®å‰ä¼ å…¥ä¼šé€ æˆå…¼å®¹æ€§é—®é¢˜
            # --------------------------------------------------------------
            def apply(                       # type: ignore[override]
                self,
                _variables,                  # nnxâ€‘bridge ä¼ å…¥çš„å ä½å˜é‡åŒ…ï¼ˆunusedï¼‰
                *args,
                rngs=None,
                method: str | None = "forward",
                **kwargs,
            ):
                """
                â€¢ method ä¸º nnxâ€‘bridge æŒ‡å®šçš„å‡½æ•°åï¼Œä¾‹å¦‚ "forward"ã€
                  "init_with_output"ï¼›é»˜è®¤ = "forward"  
                â€¢ rngs ä»…åœ¨ lazy_init æ—¶ä¼šä¼ å…¥ï¼ŒSonata ä¸ä½¿ç”¨ï¼Œç›´æ¥ä¸¢å¼ƒ
                """
                if method is None:
                    method = "forward"
    
                # é€‰å®šè¢«è°ƒå‡½æ•°
                target_fn = getattr(self, method)
    
                # init_with_output çš„ç­¾åä¸º (rngs, pc_dict, â€¦)
                if method == "init_with_output":
                    return target_fn(rngs, *args, **kwargs)
    
                # å…¶ä½™æ–¹æ³•ï¼ˆforward ç­‰ï¼‰
                return target_fn(*args, **kwargs)
                
        # ------------------------------------------------------------------
        # 4â€‘bis) çº¿æ€§å±‚åŒ…è£…å™¨ï¼šè®©æ™®é€š Linear æ”¯æŒ lazy_init
        # ------------------------------------------------------------------
        class _TorchLinearWrapper(torch.nn.Module):
            def __init__(self, in_dim: int, out_dim: int, device: torch.device, *, bias: bool = True):
                super().__init__()
                self.inner = torch.nn.Linear(in_dim, out_dim, bias=bias).to(device)
                self.device = device

            # -------- hostâ€‘sideè®¡ç®— --------
            @staticmethod
            @torch.no_grad()
            def _torch_forward(inner: torch.nn.Linear,
                               mat_np: np.ndarray,
                               device: torch.device) -> np.ndarray:
                """
               çº¯ host è°ƒç”¨ï¼šnp -> torch(cuda) -> np
                """
                # ä¿è¯ä¸€å®šæ˜¯ NumPyï¼Œå†é€å…¥ PyTorch
                if not isinstance(mat_np, np.ndarray):
                    mat_np = np.asarray(mat_np)
                x = torch.from_numpy(mat_np).to(inner.weight.dtype).to(device)
                y = inner(x)
                return y.cpu().numpy()

            # -------- forwardï¼ˆJAX sideï¼‰--------
            def forward(self, x_jax: jax.Array, *, train: bool = False):
                """
                â€¢ åœ¨ jit å›¾é‡Œä»¥ pure_callback æ–¹å¼è°ƒç”¨ _torch_forward  
                â€¢ è¾“å‡ºä¿æŒ float32ï¼Œåç»­å† cast
                """
                # è®¡ç®—è¾“å‡ºå½¢çŠ¶ï¼ˆå®Œå…¨ç¬¦å·åŒ–ï¼Œä¸è§¦å‘ concreteï¼‰
                out_shape = (*x_jax.shape[:-1], self.inner.out_features)
                out_struct = ShapeDtypeStruct(out_shape, jnp.float32)

                def _host_call(mat):
                    # mat æ˜¯ numpy.ndarray ï¼ˆpure_callback å·²è½¬æ¢ï¼‰
                    return self._torch_forward(self.inner, mat, self.device)

                return pure_callback(_host_call, out_struct, x_jax, vectorized=False)

            # -------- lazy_init hook --------
            def init_with_output(self, rngs, x_np, *, method=None, **_):
                """
                lazy_initâ€¯é˜¶æ®µä¸ä¼šåœ¨ jit å†…ï¼Œ
                ç›´æ¥èµ° hostâ€‘side è®¡ç®—å³å¯ï¼ŒåŠ é€Ÿåˆå§‹åŒ–ã€‚
                """
                if isinstance(x_np, jax.Array):
                    x_np = np.asarray(jax.device_get(x_np))
                y = self._torch_forward(self.inner, x_np, self.device)
                return y, {}          # no trainable vars

            # -------- nnxâ€‘bridge å…¼å®¹ --------
            def apply(self, _vars, *args, rngs=None, method: str | None = "forward", **kw):
                if method is None:
                    method = "forward"
                fn = getattr(self, method)
                if method == "init_with_output":
                    return fn(rngs, *args, **kw)
                return fn(*args, **kw)

        # ---------- 5) åŸç”Ÿ NNX çº¿æ€§æŠ•å½±ï¼šæ”¯æŒç«¯åˆ°ç«¯åå‘ä¼ æ’­ã€é¿å… host å¾€è¿” ----------
        # enc_out_dim â†’ PaLIâ€‘Gemma hidden_size
        self.PointProjector = nnx.Linear(self._enc_out_dim, _model_width, rngs=rngs)

        # è®©æŠ•å½±å±‚è·Ÿéš PyTorch çš„ deviceï¼Œä¸å¿…æ‰‹åŠ¨è¿ç§»é™¤éåç»­ç»§ç»­é‡å†™åˆ°jax

        N = 64               # 64 points (dummy)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Sonata çº¦å®šçš„ Point ç»“æ„ï¼ˆåŠ¡å¿…æ‰å¹³åŒ–ï¼‰ï¼š
        #   coord : (Total_N, 3)   float32 / int32
        #   feat  : (Total_N, C)
        #   batch : (Total_N,)     **int64**  â† è¦èƒ½åš Â«batchÂ <<Â 48Â»
        #   offset: (B,)           ç´¯è®¡ç‚¹æ•°å‰ç¼€å’Œ  **int64**
        #   grid_size : (B, 3)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ä¸ SpatialLM å¥‘çº¦ä¸€è‡´ï¼šfeat[:,:3] å¿…é¡»ç­‰äº coordï¼ˆè¿ç»­ xyzï¼‰
        coord_dummy = jnp.arange(N * 3, dtype=jnp.float32).reshape(N, 3)
        extra_dims = int(self._point_in_channels) - 3
        feat_dummy = (
            jnp.concatenate(
                [coord_dummy, jnp.zeros((N, extra_dims), jnp.float32)], axis=-1
            )
            if extra_dims > 0 else coord_dummy
        )
        raw_dummy_pc = {
            "coord":  coord_dummy,
            "feat":   feat_dummy,                         # â† å‰ 3 åˆ— = coord
            # JAX ç«¯ int32ï¼›host ç«¯å†å‡åˆ° int64
            "batch":  jnp.zeros((N,),  dtype=jnp.int32),
            "offset": jnp.array([N],   dtype=jnp.int32)
        }
        dummy_pc = _canonicalize_point_dict(raw_dummy_pc)

        _patch_sz = sp_cfg["enc_patch_size"][-1]   # 1024 (ä¿æŒä¸ ckpt ä¸€è‡´)
        point = nnx_bridge.ToNNX(
            _TorchSonataWrapper(
                point_model,
                self.device,
                _patch_sz,
                self._enc_out_dim,   # â† ä¸ __init__ å¯¹é½
            )
        )
        # è®°å½• point block çš„å›ºå®šé•¿åº¦ï¼ˆ= Sonata enc_patch_size[-1]ï¼‰
        self._pt_block_len = int(_patch_sz)
        
        # åˆå§‹åŒ– wrapperï¼ˆä¸€æ¬¡æ€§ shape æ¨æ–­ï¼‰
        point.lazy_init(dummy_pc, train=False, rngs=rngs)

        # ------------------------------------------------------------------
        # 6) æ‰“åŒ…æ‰€æœ‰å­æ¨¡å—
        # ------------------------------------------------------------------
        self.PaliGemma = nnx.Dict(
            llm   = llm,
            img   = img,
            point = point,
            point_proj = self.PointProjector,
        )
        # æ’å…¥ç­–ç•¥ä¸ special ids
        self._insert_points_in_place = bool(getattr(config, "insert_points_in_place", True))
        self._point_start_id = getattr(config, "point_start_id", None)
        self._point_end_id   = getattr(config, "point_end_id", None)
        self._warned_no_point_ids = False
        self._allow_text_between = bool(getattr(config, "allow_text_between_markers", False))

    def embed_inputs(
        self, obs: _model.Observation
    ) -> tuple[jax.Array, jax.Array, jax.Array]:
        """
        Embed all input modalities (images, point cloud, text tokens) into sequences of token embeddings.
        Returns:
            token_embeddings (jax.Array): concatenated token features of shape [B, N, emb_dim]
            input_mask (jax.Array[bool]): mask indicating valid tokens [B, N]
            ar_mask (jax.Array[int]): autoregressive mask for tokens [B, N] (0 where tokens attend freely, 1 where causal dependence begins).
        """
        token_embeddings: list[jax.Array] = []
        input_mask: list[jax.Array] = []
        ar_mask: list[jax.Array] = []

        # ---------- 1) èšåˆå›¾åƒ tokens ï¼ˆå…ˆåˆå¹¶æ‰€æœ‰ç›¸æœºï¼Œä¾¿äºåç»­é€æ ·æœ¬æ’å…¥é€»è¾‘ï¼‰ ----------
        img_tok_list = []
        img_msk_list = []
        for cam_name, image in obs.images.items():
            img_t, _ = self.PaliGemma.img(image, train=False)       # [B, n_img_tok, D]
            img_tok_list.append(img_t)
            m = jnp.broadcast_to(
                obs.image_masks[cam_name][:, None],
                (obs.image_masks[cam_name].shape[0], img_t.shape[1]),
            )
            img_msk_list.append(m)
        if len(img_tok_list):
            img_tokens = jnp.concatenate(img_tok_list, axis=1)      # [B, Nimg, D]
            img_mask   = jnp.concatenate(img_msk_list, axis=1)      # [B, Nimg]
        else:
            # ç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼ˆä½ çš„ config.require_image=Trueï¼‰ï¼Œå…œåº•
            B = obs.tokenized_prompt.shape[0]
            D = int(getattr(self.PaliGemma.llm.module, "hidden_size", 1024))
            img_tokens = jnp.zeros((B, 0, D), dtype=jnp.float32)
            img_mask   = jnp.zeros((B, 0),   dtype=bool)
        img_ar = jnp.zeros_like(img_mask, dtype=jnp.int32)

        # 2. Point cloud tokens --------------------------------------------------
        pc_pack = _extract_point_batch(obs)
        # è‹¥æœ¬æ¨¡å‹å¯ç”¨äº† Sonataï¼ˆå³æœ¬ç±»æœ¬èº«ï¼‰ä¸”é…ç½®è¦æ±‚ç‚¹äº‘ï¼Œåˆ™ç¼ºå¤±æ—¶ç›´æ¥æŠ¥é”™
        if pc_pack is None and self._require_pointcloud:
            raise ValueError(
                "Pi0FASTâ€‘Sonata: æœªæä¾›ç‚¹äº‘ï¼Œä½†é…ç½® require_pointcloud=Trueã€‚"
                "è¯·æä¾› Observation.point_clouds['pointcloud']ï¼ˆåŠ maskï¼‰æˆ– Observation.pointcloud_dataï¼›"
                "è‹¥ç¡®éœ€åªç”¨å›¾åƒ+æ–‡æœ¬ï¼Œè¯·å°† Pi0FASTSonataConfig.require_pointcloud=Falseã€‚"
            )
        if pc_pack is not None:
            # --------------------------------------------------------
            # ä¸ SpatialLMâ€‘Qwen forward_point_cloud å®Œå…¨ä¸€è‡´çš„ç­–ç•¥ï¼š
            # forâ€‘loop é€æ ·æœ¬è°ƒç”¨ Sonata â†’ æ¯æ¬¡å¾—åˆ° (K*1024, C)ï¼Œ
            # å†ç»Ÿä¸€ pad åˆ°åŒä¸€é•¿åº¦ã€‚
            # --------------------------------------------------------
            pc_dict_all, pc_frame_mask = pc_pack        # pc_frame_mask : [B, M]
            # å¦‚æœç‚¹äº‘ä¹Ÿå£°æ˜ require_pointcloud=Trueï¼Œä½† pc_frame_mask å…¨ Falseï¼Œè¿™ä¸€æ‰¹æ•°æ®åº”ç›´æ¥å¤±è´¥ï¼Œè€Œä¸æ˜¯æŠŠç‚¹äº‘å½“ä½œä¸å­˜åœ¨ï¼ˆé˜²æ­¢æ‚„æ‚„è®­ç»ƒåœ¨é”™è¯¯åˆ†å¸ƒä¸Šï¼‰
            if self._require_pointcloud:
                # ã€ä¿®å¤ã€‘ç¦æ­¢åœ¨ jit ä¸­åš Python å¸ƒå°”åˆ¤æ–­ï¼›æ”¹ä¸º host æ–­è¨€ï¼ˆè¿è¡ŒæœŸï¼‰ï¼š
                # present_any ä¸º 0-d boolï¼ˆtracedï¼‰ï¼Œç”¨ pure_callback åœ¨ host ä¸Šåˆ¤æ–­å¹¶æŠ›å¼‚å¸¸ï¼ˆå¿…è¦æ—¶ï¼‰ã€‚
                present_any = jnp.any(pc_frame_mask.astype(bool))

                def _host_assert_present(x):
                    # x: numpy 0-d bool
                    x = bool(np.asarray(x))
                    if not x:
                        raise RuntimeError(
                            "Pi0FASTâ€‘Sonata: require_pointcloud=True ä½†è¯¥ batch æ‰€æœ‰æ ·æœ¬å‡æ— ç‚¹äº‘ã€‚"
                        )
                    # è¿”å›ä¸€ä¸ªè™šå ä½ï¼ˆæ»¡è¶³ pure_callback çš„è¿”å›å¥‘çº¦ï¼‰
                    return np.int32(0)

                # å ä½è¾“å‡ºæè¿°
                _ = pure_callback(
                    _host_assert_present,
                    ShapeDtypeStruct((), jnp.int32),
                    present_any,
                    vectorized=False,
                )
            # B çš„é²æ£’æ¨æ–­ï¼šä¼˜å…ˆ offsetï¼›å¦åˆ™é€€åŒ–åˆ° mask / prompt çš„ batch ç»´
            if "offset" in pc_dict_all:
                B = int(pc_dict_all["offset"].shape[0])
            elif pc_frame_mask.ndim in (1, 2):
                B = int(pc_frame_mask.shape[0])
            else:
                B = int(obs.tokenized_prompt.shape[0])

            # è¿è¡Œæ—¶ç»´åº¦æ£€æŸ¥ï¼šfeat = xyz(3) + extra(...)ï¼Œå…¶åˆ—æ•°åº”ç­‰äº in_channels
            feat_dim = int(pc_dict_all["feat"].shape[-1])            # = feats ç»´åº¦ï¼ˆxyz+extrasï¼‰
            expected_feat_dim = int(self._point_in_channels)          # = config.point_feat_dim
            if feat_dim != expected_feat_dim:
                raise ValueError(
                    "ç‚¹äº‘ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼šæœŸæœ› feats ç»´åº¦ï¼ˆxyz+extraï¼‰= "
                    f"{expected_feat_dim}ï¼Œä½†æ”¶åˆ° {feat_dim}ã€‚"
                    "è¯·ç¡®ä¿ Observation.pointcloud çš„å‰3åˆ—ä¸º gridï¼Œåç»­åˆ—ä¸º feats=[xyz, extras]ï¼›"
                    "Sonata çš„ in_channels=feats åˆ—æ•°ï¼ˆä¸å« gridï¼‰ã€‚"
                )

            per_sample_tokens  = []
            per_sample_masks   = []
            max_len            = 0

            for b in range(B):                                    # **é€ batch**
                # æŠŠ sample id + present ä¼ ç»™ wrapperï¼›çœŸæ­£åˆ‡ç‰‡åœ¨ PyTorch ä¾§å®Œæˆ
                if pc_frame_mask.ndim == 2:
                    present_b = pc_frame_mask[b].any()
                else:
                    present_b = pc_frame_mask[b]
                single_dict = {
                    **pc_dict_all,                                  # å…¨é‡ç‚¹äº‘
                    "selected_batch": jnp.array(b, jnp.int32),      # æŒ‡å®šæ ·æœ¬
                    "present": present_b.astype(jnp.int32),         # å¸§å­˜åœ¨æ ‡å¿—
                }
                # æ—©æœŸå½¢çŠ¶æ£€æŸ¥ï¼šgrid_coord å¿…é¡»æœ€åä¸€ç»´=3ï¼Œè¿™æ˜¯ä¸ºäº†æµ‹è¯•æ•°æ®é›†æ˜¯ä¸æ˜¯çœŸæ­£çš„x,y,z,r,g,b,æ–¹ä¾¿åç»­æµ‹è¯•
                if "grid_coord" in single_dict:
                    if single_dict["grid_coord"].shape[-1] != 3:
                        raise ValueError(
                            f"pointcloud grid_coord çš„æœ€åä¸€ç»´å¿…é¡»ä¸º 3ï¼Œ"
                            f"å®é™… shape={single_dict['grid_coord'].shape}"
                        )
                # grid_coord ç¼ºå¤±å…œåº•ï¼šfloor + é€ç»´å½’é›¶ï¼ˆç¡®ä¿éè´Ÿï¼‰
                if "grid_coord" not in single_dict:
                    if not getattr(self, "_warned_missing_grid", False):
                        logger.warning(
                            "[Sonata] missing grid_coord; reconstructing from coord via floor() + per-dim min-shift. "
                            "For strict SpatialLM parity, pass explicit voxelized non-negative int32 grid."
                        )
                        self._warned_missing_grid = True
                    gc = jnp.floor(single_dict["coord"]).astype(jnp.int32)
                    gc = gc - gc.min(axis=0, keepdims=True)
                    single_dict["grid_coord"] = gc

                tok, vmask = self.PaliGemma.point(single_dict, train=False)

                # -------- é•¿åº¦ä¸€è‡´æ€§æ–­è¨€ --------
                assert tok.shape[0] == vmask.shape[0], (
                    f"Sonata è¿”å› token é•¿åº¦ {tok.shape[0]} "
                    f"â‰  valid_mask é•¿åº¦ {vmask.shape[0]}"
                )

                # æŠ•å½±åˆ° LLM hidden_size ï¼Œä¿æŒä¸å›¾åƒ / æ–‡æœ¬ç»´åº¦ä¸€è‡´
                tok = self.PointProjector(tok.astype(jnp.float32))
                # æŠŠ padding / æ— æ•ˆ token ç‰¹å¾å¼ºåˆ¶å½’é›¶ï¼Œé˜²æ­¢ Linear åç½®æ³„æ¼
                tok = tok * vmask[:, None]

                # SpatialLM ä¿ç•™è¡¥é›¶ tokenï¼Œé  vmask æŒ‡ç¤ºæœ‰æ•ˆæ€§
                per_sample_tokens.append(tok)       # â† ç›´æ¥æ•´å—ä¿å­˜
                per_sample_masks.append(vmask)
                max_len = max(max_len, tok.shape[0])   # ä¸€èˆ¬å°±æ˜¯ 1024

            # ----- pad åˆ° batch å†…æœ€å¤§é•¿åº¦ -----------
            def _pad_to(x, tgt):
                pad = [(0, tgt - x.shape[0])] + [(0, 0)]*(x.ndim-1)
                return jnp.pad(x, pad)

            pt_tokens = jnp.stack([_pad_to(t, max_len) for t in per_sample_tokens])  # (B,P,C) P=max_len(=patch_size)
            valid_m   = jnp.stack([_pad_to(m, max_len) for m in per_sample_masks])   # (B,P)

            # äºŒæ¬¡éªŒè¯ï¼šæ‰€æœ‰ batch é•¿åº¦å·²ç»å¯¹é½
            assert (pt_tokens.shape[1] == valid_m.shape[1] == max_len), \
                "pad å token / mask é•¿åº¦ä¸ä¸€è‡´"

            # --- å¸§çº§æ©ç ï¼šå…ˆæŠŠ [B] æˆ– [B, M] å‹æˆ [B,1]ï¼ˆæ˜¯å¦å­˜åœ¨è¯¥æ¨¡æ€ï¼‰ï¼Œå†å¹¿æ’­åˆ° token ç»´ ---
            frame_present = (
                pc_frame_mask.any(axis=1, keepdims=True)  # [B,1] é€‚é… [B,M] æƒ…å†µ
                if pc_frame_mask.ndim == 2 else
                pc_frame_mask[:, None]                   # [B,1]
            )
            pc_frame_mask_b = jnp.broadcast_to(frame_present, (B, max_len))  # [B, max_len]
            pt_final_mask   = pc_frame_mask_b & valid_m

            # æ•°å€¼æ›´å¹²å‡€ï¼šæŠŠæœ€ç»ˆ mask ä¹Ÿä¹˜è¿›ç‰¹å¾ï¼ˆä»…ç”¨äºå¯è§†åŒ–ï¼›ä¸‹é¢åŸä½æ’å…¥æ—¶ä»ä¼šå†å†™å…¥ä¸€æ¬¡ï¼‰
            pt_tokens = pt_tokens * pt_final_mask[:, :, None]
        else:
            # æ²¡æœ‰ç‚¹äº‘ï¼šæ„é€ ç©º blockï¼ˆé•¿åº¦ = 0ï¼›ä½†é€šå¸¸ require_pointcloud=True ä¸ä¼šèµ°åˆ°è¿™é‡Œï¼‰
            B = obs.tokenized_prompt.shape[0]
            D = int(getattr(self.PaliGemma.llm.module, "hidden_size", 1024))
            pt_tokens = jnp.zeros((B, 0, D), dtype=jnp.float32)
            pt_final_mask = jnp.zeros((B, 0), dtype=bool)

        # 3. Text tokens (from language model embedding)
        # Ensure textual inputs are present
        assert obs.tokenized_prompt is not None and obs.tokenized_prompt_mask is not None and obs.token_ar_mask is not None, \
            "Tokenized prompt and corresponding masks must be provided for text inputs."
        txt_tokens = self.PaliGemma.llm(obs.tokenized_prompt, embed_only=True)  # [B, L, emb_dim]
        # é¿å…å¦‚æœé”™è¯¯åœ°ç»™äº†ç©ºpromptæˆ–åªæœ‰1ä¸ªtokenï¼Œåœ¨åé¢é€»è¾‘é‡Œäº§ç”Ÿâ€œ0é•¿åº¦ä½†ä¸æŠ¥é”™â€
        if obs.tokenized_prompt.shape[1] < 2:
           raise ValueError("tokenized_prompt é•¿åº¦å¿…é¡» â‰¥ 2ï¼Œç”¨äºæ„é€  next-token ç›‘ç£ã€‚")
        # â€”â€” ç»Ÿä¸€ä¸‰æ¨¡æ€ embedding çš„ dtypeï¼ˆå°¤å…¶æ˜¯åŸä½æ’å…¥æ—¶ dynamic_update_slice å¿…é¡»ä¸€è‡´ï¼‰â€”â€” #
        target_dtype = txt_tokens.dtype
        pt_tokens = pt_tokens.astype(target_dtype)
        # ---- A) åŸä½æ’å…¥ï¼ˆSpatialLM ä¸€è‡´ï¼‰æˆ–å®‰å…¨å›é€€ ----
        use_inplace = (
            self._insert_points_in_place
            and (self._point_start_id is not None)
            and (self._point_end_id   is not None)
        )
        if self._insert_points_in_place and not use_inplace and not self._warned_no_point_ids:
            logger.warning(
                "insert_points_in_place=True ä½†æœªæä¾› point_start_id/point_end_idï¼›"
                "å°†å›é€€åˆ°å‰ç¼€æ‹¼æ¥è·¯å¾„ã€‚è¦è·å¾—ä¸ SpatialLM å®Œå…¨ä¸€è‡´çš„æ’å…¥è¡Œä¸ºï¼Œè¯·åœ¨é…ç½®ä¸­æä¾›è¿™ä¸¤ä¸ªç‰¹æ®Š token çš„ idã€‚"
            )
            self._warned_no_point_ids = True
        if use_inplace:
            B, L, D = txt_tokens.shape
            P = pt_tokens.shape[1]  # å›ºå®šå—é•¿åº¦ï¼ˆé€šå¸¸=1024ï¼‰
            # å›¾åƒéƒ¨åˆ†å…ˆå‡†å¤‡å¥½
            img_tokens = img_tokens.astype(target_dtype)
            # ä¸ºæ¯ä¸ªæ ·æœ¬è®¡ç®—çª—å£ä¸ keep ç´¢å¼•ï¼ˆhost ä¾§ï¼‰
            out_struct = (
                ShapeDtypeStruct((2,),   jnp.int32),   # window [s,e]
                ShapeDtypeStruct((L-2,), jnp.int32),   # keep_idx
            )
            win_list = []
            keep_list = []
            for b in range(B):
                def _host_call(arr):
                    return _host_find_window_and_keep_idx(
                        np.asarray(arr),
                        int(self._point_start_id),
                        int(self._point_end_id),
                        allow_text_between=self._allow_text_between,
                    )
                w_b, k_b = pure_callback(_host_call, out_struct, obs.tokenized_prompt[b], vectorized=False)
                win_list.append(w_b)
                keep_list.append(k_b)
            win_all  = jnp.stack(win_list,  axis=0)    # [B,2]
            keep_all = jnp.stack(keep_list, axis=0)    # [B,L-2]

            # ç›®æ ‡â€œæ–‡æœ¬+ç‚¹â€æ®µçš„é•¿åº¦ï¼š (L-2)+P
            LM = (L - 2) + P
            # é€æ ·æœ¬ç»„è£… â€”â€” æ”¹ä¸ºä¸¤æ®µå¼ slice å†™å…¥ï¼Œé¿å… one-hotÃ—matmul çš„å·¨å¤§ä¸­é—´å¼ é‡
            seq_list, msk_list, ar_list = [], [], []
            for b in range(B):
                s_idx = win_all[b, 0]
                # å»æ‰ start/end çš„æ–‡æœ¬ï¼ˆä¿æŒæ¬¡åºï¼‰
                txt_all = jnp.take(txt_tokens[b], keep_all[b], axis=0)                # [L-2, D]
                m_all   = jnp.take(obs.tokenized_prompt_mask[b], keep_all[b], axis=0) # [L-2]
                ar_all  = jnp.take(obs.token_ar_mask[b],        keep_all[b], axis=0) # [L-2]
                # æ‹†æˆä¸¤æ®µï¼š s å·¦ï¼ˆä¿æŒä½ç½®ä¸å˜ï¼‰ä¸ s å³ï¼ˆæ•´ä½“å³ç§» P ä½ï¼‰
                left_sel  = keep_all[b] < s_idx
                right_sel = jnp.logical_not(left_sel)
                txt_left  = txt_all[left_sel]     # [L_left, D]
                txt_right = txt_all[right_sel]    # [L_right, D]
                m_left    = m_all[left_sel]       # [L_left]
                m_right   = m_all[right_sel]      # [L_right]
                ar_left   = ar_all[left_sel]      # [L_left]
                ar_right  = ar_all[right_sel]     # [L_right]

                # ç›®æ ‡ç¼“å†²åŒº
                txt_scatter = jnp.zeros((LM, D), dtype=target_dtype)
                m_scatter_i = jnp.zeros((LM,),   dtype=jnp.int32)
                ar_scatter  = jnp.zeros((LM,),   dtype=jnp.int32)

                # å†™å…¥å·¦æ®µï¼š [0 : L_left)
                L_left  = txt_left.shape[0]
                txt_scatter = jax.lax.dynamic_update_slice(txt_scatter, txt_left.astype(target_dtype), (0, 0))
                m_scatter_i = jax.lax.dynamic_update_slice(m_scatter_i, m_left.astype(jnp.int32), (0,))
                ar_scatter  = jax.lax.dynamic_update_slice(ar_scatter, ar_left.astype(jnp.int32), (0,))

                # å†™å…¥å³æ®µï¼š [s_idx + P : s_idx + P + L_right)
                L_right = txt_right.shape[0]
                if L_right > 0:
                    txt_scatter = jax.lax.dynamic_update_slice(
                        txt_scatter, txt_right.astype(target_dtype), (s_idx + P, 0)
                    )
                    m_scatter_i = jax.lax.dynamic_update_slice(
                        m_scatter_i, m_right.astype(jnp.int32), (s_idx + P,)
                    )
                    ar_scatter  = jax.lax.dynamic_update_slice(
                        ar_scatter, ar_right.astype(jnp.int32), (s_idx + P,)
                    )
                # åœ¨ [s_idx : s_idx+P) å†™å…¥ç‚¹ token å—ï¼ˆmask/ar=0, loss=0ï¼‰
                mod_emb = jax.lax.dynamic_update_slice(txt_scatter, pt_tokens[b], (s_idx, 0))
                mod_msk_i = jax.lax.dynamic_update_slice(m_scatter_i, pt_final_mask[b].astype(jnp.int32), (s_idx,))
                mod_ar_i  = jax.lax.dynamic_update_slice(ar_scatter, jnp.zeros((P,), jnp.int32), (s_idx,))
                # ä¸å›¾åƒæ‹¼æ¥ï¼š [img | (text+points)]
                seq_b = jnp.concatenate([img_tokens[b], mod_emb], axis=0)                # [Nimg+LM, D]
                m_bf  = jnp.concatenate([img_mask[b].astype(jnp.int32), mod_msk_i], 0).astype(bool)
                ar_bf = jnp.concatenate([img_ar[b],                    mod_ar_i], 0).astype(jnp.int32)
                seq_list.append(seq_b)
                msk_list.append(m_bf)
                ar_list.append(ar_bf)
            tokens = jnp.stack(seq_list, 0)
            mask   = jnp.stack(msk_list,  0)
            ar     = jnp.stack(ar_list,   0)
            return tokens, mask, ar

        # ---- B) å‰ç¼€æ‹¼æ¥ï¼ˆé»˜è®¤å›é€€è·¯å¾„ï¼‰ ----
        if len(token_embeddings):
            token_embeddings = [t.astype(target_dtype) for t in token_embeddings]
        token_embeddings.append(img_tokens.astype(target_dtype))
        input_mask.append(img_mask)
        ar_mask.append(img_ar)
        if pt_tokens.shape[1] > 0:
            token_embeddings.append(pt_tokens.astype(target_dtype))
            input_mask.append(pt_final_mask)
            ar_mask.append(jnp.zeros_like(pt_final_mask, dtype=jnp.int32))
        token_embeddings.append(txt_tokens)
        input_mask.append(obs.tokenized_prompt_mask)
        ar_mask.append(obs.token_ar_mask)
        tokens = jnp.concatenate(token_embeddings, axis=1)
        mask   = jnp.concatenate(input_mask,       axis=1)
        ar     = jnp.concatenate(ar_mask,          axis=1)
        return tokens, mask, ar

    def compute_loss(
        self,
        rng: jax.Array,
        observation: _model.Observation,
        actions: _model.Actions,
        *,
        train: bool = False
    ) -> jax.Array:
        """Compute sequence loss for the model (predict next token loss for language prompt)."""
        # Preprocess observation (normalize/augment images, ensure masks)
        # å‘å›¾åƒé¢„å¤„ç†å‡½æ•°ä¼ é€’ RNGï¼ˆä»…åœ¨è®­ç»ƒé˜¶æ®µéœ€è¦ï¼‰
        prep_rng = rng if train else None
        observation = _model.preprocess_observation(prep_rng, observation, train=train, image_keys=list(observation.images.keys()))
        # è‹¥è¦æ±‚æ ·æœ¬å¿…é¡»åŒ…å«å›¾åƒï¼Œè€Œå½“å‰ observation æ— å›¾åƒï¼Œåˆ™ç›´æ¥ä¸­æ­¢è®­ç»ƒ
        if self._require_image and len(observation.images) == 0:
            raise RuntimeError(
                "Pi0FASTâ€‘Sonata: require_image=True but observation contains no images; "
                "abort this training step or filter such samples upstream."
            )
        # Embed all inputs to tokens and get masks
        tokens, mask, ar = self.embed_inputs(observation)
        # Compute attention mask for the sequence (prefix + causal masking as needed)
        attn_mask = _pi0_fast.make_attn_mask(mask, ar)
        # === SpatialLM å¯¹é½çš„æŸå¤±ï¼šåŸä½æ’å…¥åï¼Œæ–‡æœ¬ token ä¸å†â€œæ•´æ®µä½äºæœ«å°¾â€ ===
        # æ–¹æ¡ˆï¼šdecode å…¨é•¿åº¦ï¼Œç„¶åæŒ‰â€œæ–‡æœ¬ token åœ¨æ’å…¥åçš„æ–°ä½ç½® - 1â€å» gather å¯¹åº” logitsï¼Œå†åš CEã€‚
        vocab_size = self.PaliGemma.llm.module.vocab_size
        B, L = observation.tokenized_prompt.shape
        # 1) å…ˆå¾—åˆ°æ•´æ®µ pre_logits â†’ logits_all
        pre_logits, _, _ = self.PaliGemma.llm(
            embedded_prefix=tokens[:, :-1],
            mask=attn_mask[:, :-1, :-1],
            return_prelogits=True
        )
        logits_all, _ = self.PaliGemma.llm(pre_logits=pre_logits)   # [B, T_total-1, V]

        # é™æ€ gatingï¼šåŸä½æ’å…¥éœ€é…ç½®å¥½ä¸¤ä¸ªç‰¹æ®Š token çš„ idï¼Œå¦åˆ™å›é€€å°¾éƒ¨å¯¹é½æŸå¤±
        use_inplace = (
            self._insert_points_in_place
            and (self._point_start_id is not None)
            and (self._point_end_id   is not None)
        )
        if not use_inplace:
            targets = jax.nn.one_hot(observation.tokenized_prompt[:, 1:], vocab_size)
            logits_tail = logits_all[:, -targets.shape[1]:]
            log_probs = jax.nn.log_softmax(logits_tail, axis=-1)
            assert observation.token_loss_mask is not None
            loss_mask = observation.token_loss_mask[:, 1:]
            token_nll = -jnp.sum(targets * log_probs, axis=-1)
            denom = jnp.maximum(jnp.sum(loss_mask, axis=-1), 1)
            seq_loss = jnp.sum(token_nll * loss_mask, axis=-1) / denom
            return seq_loss

        # 2) åŸä½æ’å…¥ï¼šæ ¹æ® start/end å’Œ keep_idx è®¡ç®—â€œæ–‡æœ¬ token çš„æ–°ä½ç½®â€
        # ï¼ˆæ­¤å¤„æ— éœ€å†æ¬¡åˆ¤æ–­ ids æ˜¯å¦å­˜åœ¨ï¼›use_inplace=True å·²ä¿è¯ï¼‰
        # æ¨å¯¼ï¼šNimg = æ€»é•¿åº¦ - ((L-2) + P)
        T_total = tokens.shape[1]
        P = int(getattr(self, "_pt_block_len", 1024))
        Nimg = T_total - ((L - 2) + P)
        out_struct = (
            ShapeDtypeStruct((2,),   jnp.int32),
            ShapeDtypeStruct((L-2,), jnp.int32),
        )
        win_list, keep_list = [], []
        for b in range(B):
            def _host_call(arr):
                return _host_find_window_and_keep_idx(
                    np.asarray(arr),
                    int(self._point_start_id),
                    int(self._point_end_id),
                    allow_text_between=self._allow_text_between,
                )
            w_b, k_b = pure_callback(_host_call, out_struct, observation.tokenized_prompt[b], vectorized=False)
            win_list.append(w_b)
            keep_list.append(k_b)
        win_all  = jnp.stack(win_list,  axis=0)    # [B,2]
        keep_all = jnp.stack(keep_list, axis=0)    # [B,L-2]
        s_all = win_all[:, 0]                      # [B]

        # æ–‡æœ¬ ids / loss mask å»æ‰ start/end
        text_ids   = jnp.take_along_axis(observation.tokenized_prompt,   keep_all, axis=1)  # [B,L-2]
        text_lossm = jnp.take_along_axis(observation.token_loss_mask,    keep_all, axis=1)  # [B,L-2]
        # é¢„æµ‹ç›®æ ‡ï¼šæ–‡æœ¬è‡ªèº«å³ç§»ä¸€ä½ï¼ˆé¦–ä¸ªæ–‡æœ¬ token æ— â€œå‰ä¸€ä½ç½®â€ï¼Œä¸è®¡ lossï¼‰
        text_targets = jax.nn.one_hot(text_ids[:, 1:], vocab_size)       # [B,L-3?,V]
        loss_mask_t  = text_lossm[:, 1:]                                  # [B,L-3?]

        # è®¡ç®—æ¯ä¸ªæ–‡æœ¬ token çš„â€œæ’å…¥åä½ç½®â€ï¼ˆç›¸å¯¹æ–‡æœ¬+ç‚¹æ®µï¼‰ï¼Œå† +Nimg å˜æˆå…¨å±€ä½ç½®
        # keep_all ä¸å« s/eï¼Œå› æ­¤â€œ> sâ€ç­‰ä»·â€œ> eâ€ï¼Œå³ç§» P ä½
        dst_mod = jnp.where(keep_all < s_all[:, None], keep_all, keep_all - 2 + P)  # [B,L-2]
        # å¯¹äº text_ids[:,1:]ï¼Œå…¶ logits æ¥æºæ˜¯â€œè¯¥ token åœ¨åºåˆ—ä¸­çš„ä½ç½® âˆ’ 1â€
        pos_before = Nimg + dst_mod[:, 1:] - 1                                        # [B,L-3?]
        # æŒ‰æ‰¹åœ¨æ—¶é—´è½´ä¸Š gather å¯¹åº”ä½ç½®çš„ logitsï¼š
        # logits_all[b].shape == [T_total-1, V] ï¼Œpos_before[b].shape == [K] â†’ é€‰å‡º [K, V]
        def _gather_rows(a_b, idx_b):
            return a_b[idx_b.astype(jnp.int32), :]    # [K, V]
        logits_sel = jax.vmap(_gather_rows, in_axes=(0, 0), out_axes=0)(logits_all, pos_before)  # [B, K, V]
        log_probs  = jax.nn.log_softmax(logits_sel, axis=-1)

        token_nll = -jnp.sum(text_targets * log_probs, axis=-1)                      # [B, L-3?]
        denom_t = jnp.maximum(jnp.sum(loss_mask_t, axis=-1), 1)
        seq_loss  = jnp.sum(token_nll * loss_mask_t, axis=-1) / denom_t
        return seq_loss

    def sample_actions(
        self,
        rng: jax.Array,
        observation: _model.Observation,
        *,
        max_decoding_steps: int = 256,
        temperature: float = 0.0
    ) -> _model.Actions:
        """
        Autoregressively sample a sequence of actions (or action tokens) from the model given an observation.
        This uses the model as a prefix model (prefix = images + prompt tokens + optional point tokens),
        then generates additional tokens up to max_decoding_steps or until an EOS token is produced.
        """
        # Preprocess observation (no augmentation, just ensure correct shapes/masks)
        observation = _model.preprocess_observation(None, observation, train=False, image_keys=list(observation.images.keys()))
        # Embed inputs to get prefix token embeddings and masks
        prefix_tokens, prefix_mask, prefix_ar_mask = self.embed_inputs(observation)
        prefix_attn_mask = _pi0_fast.make_attn_mask(prefix_mask, prefix_ar_mask)
        # Align all prefix sequences to the right (required for caching in prefix)
        prefix_tokens, prefix_mask, prefix_attn_mask = _pi0_fast.left_to_right_align(prefix_tokens, prefix_mask, prefix_attn_mask)
        # â‘   â€”â€”  ä¸ SpatialLM ä¸€è‡´ï¼šprefill_len æ˜ç¡® cast ä¸º int32ï¼ˆåç»­ä¸ lax.iota ç­‰ä¿æŒç±»å‹åŒ¹é…ï¼‰
        prefill_size = prefix_tokens.shape[1]   # total sequence length after alignment (prefix padded to some length)
        prefill_len = jnp.sum(prefix_mask, axis=-1).astype(jnp.int32)   # actual prefix length per batch (number of valid tokens)
        prefix_start = prefill_size - prefill_len   # start index of actual prefix tokens after right-align (for each batch)
        # Prepare attention mask for prefix + decoding steps
        prefix_attn_mask = jnp.pad(prefix_attn_mask, ((0, 0), (0, 0), (0, max_decoding_steps)))
        prefix_positions = (jnp.cumsum(prefix_mask.astype(jnp.int32), axis=-1) - 1).astype(jnp.int32)  # positions of prefix tokens (0-indexed)
        # Run the LLM in decoding mode to fill KV cache with prefix
        prefix_logits, kv_cache, _ = self.PaliGemma.llm(
            embedded_prefix=prefix_tokens,
            mask=prefix_attn_mask,
            positions=prefix_positions,
            decode=True
        )
        # Start from the last logit of the prefix as the beginning for new generation
        last_logit = prefix_logits[:, -1:]   # [B, 1, V]
        # Placeholder for generated token outputs (initialize with zeros)
        output_tokens = jnp.zeros((last_logit.shape[0], max_decoding_steps), dtype=jnp.int32)

        # Now run autoregressive decoding for at most max_decoding_steps
        # Prepare attention mask for single-step decoding (prefix length + current step)
        # We will update the attention mask dynamically in the loop if needed

        # Use a while loop to generate tokens until done or max steps
        def cond_fn(state):
            _rng, _last, _cache, _step, _out = state
            # while_loop çš„æ¡ä»¶å¿…é¡»æ˜¯**æ ‡é‡ bool**ã€‚
            # è¿™é‡Œæˆ‘ä»¬è®¤ä¸ºâ€œæ‰€æœ‰æ ·æœ¬éƒ½å·²ç”Ÿæˆ EOSâ€æ‰æå‰åœæ­¢ï¼Œå› æ­¤ç”¨ jnp.all(...) â†’ æ ‡é‡ã€‚
            def _false_scalar(_):
                return jnp.array(False, dtype=bool)
            def _all_eos_scalar(_):
                # _out[:, _step - 1] å½¢çŠ¶ä¸º [B]ï¼Œjnp.all(...) è¿”å›æ ‡é‡ï¼ˆæ‰€æœ‰æ ·æœ¬å‡ä¸º EOSï¼‰
                # æ³¨æ„ï¼šstep==0 æ—¶è¿˜æ²¡æœ‰æœ‰æ•ˆ tokenï¼Œå› æ­¤èµ° _false_scalar åˆ†æ”¯ã€‚
                return jnp.all(_out[:, _step - 1] == _pi0_fast.PALIGEMMA_EOS_TOKEN)
            has_eos = jax.lax.cond(
                _step == 0,
                _false_scalar,
                _all_eos_scalar,
                operand=None,
            )
            return jnp.logical_and(_step < max_decoding_steps, jnp.logical_not(has_eos))

        def body_fn(state):
            rng_key, last_logits, cache, step, out_tokens = state
            rng_key, subkey = jax.random.split(rng_key)
            logits_step = last_logits.squeeze(1)
            token = jax.lax.cond(
                temperature > 1e-6,
                lambda key: jax.random.categorical(key, logits_step / temperature, axis=-1),
                lambda key: jnp.argmax(logits_step, axis=-1),
                operand=subkey,
            ).astype(jnp.int32)
            # åŸ put_along_last_axis æ„é€  O(NÂ²) oneâ€‘hotï¼›æ”¹ç”¨ scatter æ›´æ–°
            out_tokens = out_tokens.at[:, step].set(token)

            # Gemmaâ€‘fast & SpatialLMï¼šä½ç½® = å·²å¡« prefix token æ•° + å½“å‰ step
            # â‘¡  â€”â€”  positions ç»Ÿä¸€ int32ï¼Œå¯é¿å… multiâ€‘host sharding â€œmixed signednessâ€ æŠ¥è­¦
            # ä¸ SpatialLM/pi0_fast å¯¹é½ï¼ˆ0â€‘basedï¼‰ï¼šé¦–ä¸ªæ–° token ä½ç½® = prefill_len + 0
            positions = (prefill_len[:, None] + step).astype(jnp.int32)
            # Gemmaâ€‘fast æ—  token=kwargï¼šå…ˆåµŒå…¥ï¼Œå† decode ä¸€æ­¥
            token_emb = self.PaliGemma.llm(token[:, None], embed_only=True)
            # ä¸åŸ Pi0â€‘FAST ä¿æŒä¸€è‡´ï¼šæ˜¾å¼ä¼ å…¥ causalÂ maskï¼Œ
            # å±è”½å³å¯¹é½å‰ç¼€å·¦ä¾§ padding çš„ KVã€‚
            mask = jnp.logical_and(
                jnp.arange(prefill_size + max_decoding_steps, dtype=jnp.int32)[None, None, :]
                >= prefix_start[:, None, None],
                jnp.arange(prefill_size + max_decoding_steps, dtype=jnp.int32)[None, None, :]
                < (
                    jnp.broadcast_to(
                        prefill_size + step + 1,
                        (prefix_start.shape[0], 1, 1),
                    )
                ),
            )
            logits, cache = self.PaliGemma.llm(
                embedded_prefix=token_emb,
                kv_cache=cache,
                positions=positions,
                decode=True,
                mask=mask,  # â˜… æ–°å¢
            )
            return rng_key, logits, cache, step+1, out_tokens

        init_state = (rng, last_logit, kv_cache, jnp.array(0, jnp.int32), output_tokens)
        _, _, _, final_step, output_seq = jax.lax.while_loop(cond_fn, body_fn, init_state)

        # Return the output sequence of tokens as the model's predicted "actions"
        # (In practice, these tokens might represent discretized actions or a planned sequence encoded as text tokens)
        return output_seq[:, :final_step]   # [B, <=max_dec_steps]