"""
+Pi0FAST-Sonata
+--------------
+æœ¬æ–‡ä»¶å°† SpatialLM çš„ Sonata ç‚¹äº‘ç¼–ç å™¨åŸæ ·èåˆåˆ° Pi0-FAST backbone ä¸­ã€‚
+
+æœ¬è¡¥ä¸åˆ‡æ¢åˆ°â€œæ–°æ¥å£â€ä»¥å¯¹é½ SpatialLM çš„å®é™…æ•°æ®å½¢æ€ï¼š
+  â€¢ Observation.point_clouds["pointcloud"] : [B, M, 3 + C] (float32)
+      - [:, :, 0:3]     = grid_coord ä½“ç´ ç½‘æ ¼ï¼ˆæºæ•°æ®ä¸­å¯ä»¥æ˜¯ floatï¼Œä½†ä¼šåœ¨æ¨¡å‹ä¾§å¼ºåˆ¶ cast->int32ï¼›å¼ºçƒˆå»ºè®®ä¸Šæ¸¸ç›´æ¥ int32ï¼‰
+      - [:, :, 3:6]     = coord è¿ç»­ xyz (float32)
+      - [:, :, 6:]      = å…¶å®ƒç‰¹å¾ (float32)
+      - ä¸¥æ ¼å¥‘çº¦ï¼šfeat = [xyz, extras...]ï¼Œä¸” feat[:,:3] å¿…é¡»ä¸ coord ä¸€è‡´ï¼ˆwrapper ä¸¥æ ¼æ ¡éªŒï¼‰ã€‚
+  â€¢ Observation.point_cloud_masks["pointcloud"] : [B] bool
+      - æŒ‡ç¤ºè¯¥æ ·æœ¬æ˜¯å¦æä¾›ç‚¹äº‘ï¼›ç©ºå¸§å°†è·³è¿‡ Sonata å‰å‘ï¼ˆç›´æ¥è¿”å›é›¶å‘é‡å’Œå…¨ False æ©ç ï¼‰ã€‚
+
+ä¸ SpatialLM çš„å·®å¼‚ï¼š
+  - æ ¸å¿ƒåŠŸèƒ½å®Œå…¨ç­‰ä»·ï¼ˆåŒä¸€ä»½ Point dict å–‚ Sonataï¼ŒFourier + input_proj ä¸€è‡´ï¼‰ã€‚
+  - æˆ‘ä»¬æ˜¾å¼åŒ–äº†â€œæ˜¯å¦å­˜åœ¨ç‚¹äº‘â€çš„å¸§çº§æ©ç ï¼›SpatialLM åœ¨æ•°æ®ä¾§ç­‰ä»·å¤„ç†ï¼Œè¿™é‡Œåšæˆæ˜¾å¼å¥‘çº¦ã€‚
+  - æˆ‘ä»¬æ›´ä¸¥æ ¼ï¼šè‹¥ grid/xyz ä¸æ»¡è¶³å¥‘çº¦ï¼Œç›´æ¥æŠ›é”™ï¼Œä¸åšä»»ä½•â€œè‡ªåŠ¨ä¿®å¤â€æˆ–ä½“ç´ åŒ–ï¼Œä»¥é¿å…æŠŠé”™è¯¯æ•°æ®â€œæ‚„æ‚„ä¿®æ­£â€ã€‚
+æ•°æ®è¦æ±‚ä¸å»ºè®®ï¼š
+  - grid_coord å¿…é¡»æ˜¯éè´Ÿæ•´æ•°ç´¢å¼•ï¼›æ¨èä¸ num_bins=1280ã€4 æ¬¡ stride=2 å¯¹åº”çš„æœ€æœ«çº§èŒƒå›´ [0, 80)ï¼ˆå†…éƒ¨æœ‰ warnï¼‰ï¼Œä»¥åˆ© Fourier å½’ä¸€åŒ–ã€‚
+"""

# è¯¥ç‰ˆæœ¬å·²çŸ¥é—®é¢˜ï¼ˆè¿™äº›é—®é¢˜ç›®å‰æš‚æ—¶ä¸ç”¨ç«‹åˆ»è§£å†³ï¼‰ï¼š
# è®­ç»ƒæ—¶æ¢¯åº¦ï¼šä¸ä¼šå›ä¼ åˆ° **Sonata**ï¼ˆpure_callback éå¯å¾®ï¼‰ï¼›**Projector å¯è®­ç»ƒ**ã€‚
# è‹¥åç»­éœ€è¦ç«¯åˆ°ç«¯è®­ç»ƒ Sonataï¼Œéœ€è¦æŠŠç‚¹äº‘åˆ†æ”¯è¿åˆ° JAXï¼ˆæˆ–è‡ªå®šä¹‰å¯å¾® callbackï¼‰ï¼Œå†è®¨è®º flashâ€‘attn / spconv çš„å¯å¾®æ›¿ä»£ã€‚
# æ€§èƒ½æ½œåœ¨ç“¶é¢ˆ	CPUâ€¯â†”â€¯GPU copy / å¤šç¼–è¯‘	åç»­è¿­ä»£å¯èƒ½ä¼šå½±å“è¿™ä¸ªï¼Œæ‰€ä»¥é¦–å…ˆè§£å†³é—®é¢˜1
# 1024 token sizeï¼Œè¿™ä¸ªæš‚æ—¶ä¸èƒ½è®¾ç½®å¤ªå¤§å› ä¸ºä¼šç‚¸æ˜¾å­˜ï¼Œé¦–å…ˆä½¿ç”¨æç¤ºæ–¹å¼æ¥ç¡®å®šæ˜¯å¦ä¼šæœ‰è¿‡å¤šçš„æƒ…å†µï¼Œæ²¡æœ‰å°±ç»§ç»­è®­ç»ƒï¼Œæœ‰çš„è¯åç»­å†ç»§ç»­å¤„ç†
# æ³¨æ„ï¼Œgridä¼¼ä¹ä¸èƒ½æ˜¯è´Ÿæ•°ï¼
# per-sample pure_callback batch>1 æ—¶ CPUâ†”GPU æ¥å›å’Œ XLA â†’ host äº¤äº’ä¼šæ‹–æ…¢ï¼Œæ¢¯åº¦ç§¯ç´¯åœºæ™¯å°¤ç”š
# grid â†’ coord åç§»ï¼šå½“å‰ä¸ä¼šåœ¨æ¨¡å‹å†…æ”¹åŠ¨ grid_coordï¼ˆåªåšâ€œéè´Ÿ + å½¢çŠ¶ + dtypeâ€æ ¡éªŒï¼‰ï¼›æ˜¯å¦å½’é›¶æˆ–å¯¹é½ï¼Œè¯·åœ¨æ•°æ®ä¾§ç»Ÿä¸€å¤„ç†ã€‚
# ä¸ºäº†é¿å…è­¦å‘Šï¼Œå®æ–½äº†JAX ç«¯ batch/offset ç”¨ int32ï¼Œhost(PyTorch) ç«¯ç»Ÿä¸€ .long()ï¼›é¿å… JAX_ENABLE_X64 ç›¸å…³è­¦å‘Šã€‚
# ã€è¿™ä¸ªä¼¼ä¹ä¿®å¤äº†ï¼Ÿã€‘â€œæ’å…¥ä½ç½®â€ä¸¥æ ¼ä¸€è‡´æ€§é—®é¢˜å­˜åœ¨ï¼šæˆ‘ä»¬æ˜¯å‰ç¼€æ‹¼æ¥ï¼›SpatialLM æ˜¯ <point_start>..ç‚¹token.. <point_end> æ’å›åˆ°æ–‡æœ¬åºåˆ—ã€‚è¯­ä¹‰ç­‰ä»·ï¼ˆæ–‡æœ¬ä¾æ—§èƒ½çœ‹åˆ°ç‚¹ tokenï¼‰ï¼Œä½†ä¸æ˜¯å®Œå…¨åŒä¸€ä½ç½®ã€‚å¦‚æœä½ è¦é€å­—èŠ‚ä¸€è‡´ï¼Œéœ€è¦è®© tokenizer/prompt ä¸­çœŸçš„åŒ…å« <point_start>/<point_end>ï¼Œå¹¶åœ¨æ‹¼æ¥æ—¶æ‰¾åˆ°è¿™ä¸¤ä¸ªä½ç½®å†åšæ’å…¥ï¼ˆæˆæœ¬è¾ƒé«˜ï¼Œä¸”å¯¹ä½ å½“å‰ Pi0â€‘FAST çš„å¤šæ¨¡æ€æ‹¼æ¥æ¥å£ä¸è‡ªç„¶ï¼‰ã€‚


import dataclasses
import inspect
import logging
import typing
import jax
import jax.numpy as jnp
import jax.nn as jnn
import numpy as np
import torch
import warnings
from pathlib import Path
from typing import Any, Dict, Tuple, Optional

# ---- JAX <-> openpi å…¼å®¹ï¼šKeyArray åœ¨ JAX 0.4.14+ è¢«ç§»é™¤ ----
import jax.random as _jr
if not hasattr(_jr, "KeyArray"): _jr.KeyArray = jax.Array  # type: ignore[attr-defined]

from flax import nnx
# nnx_bridge allows bridging PyTorch modules to NNX (Flax) modules
import flax.nnx.bridge as nnx_bridge

from jax import ShapeDtypeStruct
from jax import pure_callback

from openpi.models import sonata_encoder  # This module should define the Sonata point cloud encoder
import openpi.models.gemma_fast as _gemma 
from openpi.models import pi0_fast as _pi0_fast
from openpi.models import siglip as _siglip
from openpi.models import PointBackboneType, ProjectorType
import openpi.models.model as _model  # for BaseModel and Observation
from openpi.shared import array_typing as at  # for inputs_spec override
# from openpi.shared import download     # utility for downloading resources like weights, not used for now

# optional â€“ hugâ€‘hub ä¼˜å…ˆ
try:
    from huggingface_hub import hf_hub_download
    _HF_OK = True
except ImportError:          # ç¯å¢ƒé‡Œæ²¡è£… huggingface_hub ä¼šèµ°æ—§é€»è¾‘
    _HF_OK = False
logger = logging.getLogger("openpi")

# ç”¨äºç”Ÿæˆæµ‹è¯•ç”¨æ•°æ®çš„å·¥å…·å‡½æ•°
def _canonicalize_point_dict(pd):
    pd = {k: jnp.asarray(v) for k, v in pd.items()}  # â† ç”¨ jnpï¼›ä¸åšä»»ä½•â€œæ•°æ®ä¿®å¤â€ï¼Œåªåšå½¢çŠ¶è§„èŒƒåŒ–ä¸ dtype çº¦æŸ
 

    if pd["coord"].ndim == 3:      # (B,N,3) â†’ (B*N,3)
        B, N, _ = pd["coord"].shape
        pd["coord"] = jnp.reshape(pd["coord"], (B * N, 3))
        pd["feat"]  = jnp.reshape(pd["feat"],  (B * N, -1))
        # JAX ç«¯ç»Ÿä¸€ int32ï¼›host(PyTorch) ç«¯å†å‡ä¸º int64 ä»¥æ”¯æŒ (batch << 48)
        pd["batch"]  = jnp.repeat(jnp.arange(B, dtype=jnp.int32), N)
        pd["offset"] = jnp.cumsum(jnp.full((B,), N, dtype=jnp.int32))

    if "grid_size" in pd and pd["grid_size"].ndim == 3:
        pd["grid_size"] = jnp.reshape(pd["grid_size"], (-1, 3))

    # JAX ç«¯ä¿æŒ int32ï¼ˆé¿å… x64 è­¦å‘Šï¼‰ï¼›host ç«¯å†å‡ä¸º int64
    for key in ("batch", "offset"):
         if key in pd:
            pd[key] = pd[key].astype(jnp.int32, copy=False)

    # SpatialLM çº¦å®šï¼šæ˜¾å¼æä¾› int32 ä½“ç´ åæ ‡ï¼ˆä¸åšé›¶ç‚¹å¹³ç§»/é‡å»ºï¼‰
    if "grid_coord" in pd:
        # è¿™é‡Œæœ‰ä¸ªæ½œåœ¨çš„é—®é¢˜ï¼Œè‹¥ç”¨æˆ·è‡ªå·±ç»„è£…çš„grid_coordå·²ç»è¶…è¿‡65535ï¼Œåˆ™å¯èƒ½å†æ¬¡æº¢å‡ºï¼Œä½†è¿™ä¸ªå®é™…ä¸Šä¸å¤ªå¯èƒ½ï¼Œå› æ­¤åªå†™æ³¨é‡Šï¼Œç­‰ä»¥åå¦‚æœè®­ç»ƒæœ‰é—®é¢˜å†å›æ¥çœ‹ã€‚
        if pd["grid_coord"].shape[-1] != 3:
            raise ValueError("pointcloud.grid_coord çš„æœ€åä¸€ç»´å¿…é¡»ä¸º 3ï¼ˆxyzï¼‰ã€‚")
        pd["grid_coord"] = pd["grid_coord"].astype(jnp.int32, copy=False)

    return pd

# ---------- host-side helper: find <point_start>/<point_end> & keep indices ----------
def _host_find_window_and_keep_idx(
    prompt_np: np.ndarray,
    start_id: int,
    end_id: int,
    *,
    allow_text_between: bool = False,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    åœ¨ host ä¸Šè§£æä¸€ä¸ªæ ·æœ¬çš„ tokenized_promptï¼Œè¿”å›:
      â€¢ window: np.int32[2] = [s_idx, e_idx]
      â€¢ keep_idx: np.int32[L-2] â€”â€” å»æ‰ s/e ä¸¤ä¸ªä½ç½®åï¼Œä¿ç•™çš„ L-2 ä¸ªæ–‡æœ¬ä½ç½®ç´¢å¼•
    è‹¥æœªæ‰¾åˆ°æˆ–ä¸åˆæ³•ï¼ŒæŠ›å‡ºå¼‚å¸¸ã€‚
    """
    arr = np.asarray(prompt_np).tolist()
    L = len(arr)
    s_pos = [i for i, t in enumerate(arr) if t == start_id]
    e_pos = [i for i, t in enumerate(arr) if t == end_id]
    if len(s_pos) != 1 or len(e_pos) != 1:
        raise ValueError(
            f"[point-window] expect exactly one <start>/<end>, got start={s_pos}, end={e_pos}"
        )
    s, e = s_pos[0], e_pos[0]
    if not (0 <= s < e < L):
        raise ValueError(f"[point-window] invalid order: start={s}, end={e}, L={L}")
    if not allow_text_between and e != s + 1:
        raise ValueError(
            f"[point-window] found text between <start> and <end> (start={s}, end={e}). "
            "Set allow_text_between_markers=True if this is intentional."
        )
    keep = np.array([i for i in range(L) if i != s and i != e], dtype=np.int32)
    win = np.array([s, e], dtype=np.int32)
    return win, keep

# ---------- host-side helper: find <point_start>/<point_end> (no adjacency check) ----------
def _host_find_window_only(
    prompt_np: np.ndarray,
    start_id: int,
    end_id: int,
) -> np.ndarray:
    """
    è¿”å› np.int32[2] = [s_idx, e_idx]ï¼Œåªå®šä½èµ·æ­¢ä½ç½®ï¼Œ
    ä¸å¯¹äºŒè€…é—´æ˜¯å¦æœ‰æ–‡æœ¬åšä»»ä½•çº¦æŸï¼ˆå¯¹é½ SpatialLM çš„å®½æ¾å‡è®¾ï¼‰ã€‚
    """
    arr = np.asarray(prompt_np).tolist()
    L = len(arr)
    s_pos = [i for i, t in enumerate(arr) if t == start_id]
    e_pos = [i for i, t in enumerate(arr) if t == end_id]
    if len(s_pos) != 1 or len(e_pos) != 1:
        raise ValueError(f"[point-window] expect exactly one <start>/<end>, got start={s_pos}, end={e_pos}")
    s, e = s_pos[0], e_pos[0]
    if not (0 <= s < e < L): raise ValueError(f"[point-window] invalid order: start={s}, end={e}, L={L}")
    return np.array([s, e], dtype=np.int32)

# -------- åœ¨â€œæ–°æ¥å£ / æ—§æ¥å£(legacy)â€ä¸¤ç±» Observation ä¹‹é—´ç»Ÿä¸€æŠ½å–ç‚¹äº‘ ----------
def _extract_point_batch(obs) -> tuple[dict[str, jnp.ndarray], jnp.ndarray] | None:
    """
    è¿”å› (pc_dict, frame_mask) æˆ– None
    ä¼˜å…ˆèµ°â€œæ–°æ¥å£â€ï¼Œä¸ SpatialLM çš„ Sonata è°ƒç”¨è¯­ä¹‰ç­‰ä»·ï¼š
      â€¢ obs.point_clouds["pointcloud"] : [B, M, 3 + C]
          - [:, :, :3]  = grid_coord (æœŸæœ› int32ï¼Œéè´Ÿï¼›è¿™é‡Œä¼š cast)
          - [:, :, 3:6] = coord xyz   (float32)
          - [:, :, 6:]  = extras      (float32)
      â€¢ obs.point_cloud_masks["pointcloud"] : [B]  æŒ‡ç¤ºè¯¥æ ·æœ¬æ˜¯å¦æœ‰ç‚¹äº‘

    ä»å…¼å®¹ legacyï¼ˆobs.pointcloud_data å­—å…¸ï¼‰ï¼Œä½†ä¸å†åœ¨æ¨¡å‹å†…â€œä½“ç´ åŒ–/ä¿®å¤â€ï¼Œ
    ä¸”ä¼šä» offset/batch æ¨å¯¼å¸§çº§æ©ç ä»¥ä¸æ–°æ¥å£ä¿æŒä¸€è‡´è¯­ä¹‰ã€‚

    æ”¯æŒä¸¤ç§æ¥æºï¼š
    1) æ–°æ¥å£ :  obs.point_clouds["pointcloud"]  +  obs.point_cloud_masks["pointcloud"]
    2) æ—§æ¥å£ :  obs.pointcloud_data
       - a) å·²æ˜¯ Sonata å…¼å®¹ dictï¼ˆå¿…é¡»å« grid_coordï¼‰â†’ ç›´æ¥ä½¿ç”¨
       - b) ä¸å†æ”¯æŒä»… [B,P,C] åŸå§‹æ•°ç»„ï¼ˆé¿å…â€œè¶Šæƒä¿®å¤â€ï¼‰
    """
    # ---------- ğŸ’¡ æ–°æ¥å£ ----------
    if hasattr(obs, "point_clouds") and "pointcloud" in getattr(obs, "point_clouds"):
        # å½¢çŠ¶: [B, M, 3(grid) + point_feat_dim(feats)]
        # [:,:,0:3] grid (castâ†’int32), [:,:,3:6] è¿ç»­ xyz, [:,:,6:] å…¶å®ƒç‰¹å¾
        pc_arr  = obs.point_clouds["pointcloud"]
        pc_mask = obs.point_cloud_masks["pointcloud"]     # [B]

        B, M, _ = pc_arr.shape
        # SpatialLMâ€‘Qwen çº¦å®š:
        #   0â€‘2 : ä½“ç´ ç½‘æ ¼åæ ‡ (int32)
        #   3â€‘5 : è¿ç»­ xyz (float32)
        #   6+ : å…¶ä»–è¯­ä¹‰ç‰¹å¾
        grid_int = pc_arr[..., :3].astype(jnp.int32)           # (B,M,3)
        coords   = pc_arr[..., 3:6].astype(jnp.float32)        # è¿ç»­ xyz
        feats    = pc_arr[..., 3:].astype(jnp.float32)         # xyz + è¯­ä¹‰

        # ä¸åœ¨ JAX ä¾§åšâ€œä¿®å¤â€ï¼›å±•å¹³/NaN è¿‡æ»¤ç­‰ç•™åˆ° host ä¾§ï¼ˆwrapper å†…ï¼‰åšç¡¬æ ¡éªŒ
        pc_dict = _canonicalize_point_dict(
            dict(coord=coords, grid_coord=grid_int, feat=feats)
        )

        # ç›´æ¥ä½¿ç”¨é™æ€ç»´åº¦ M ä½œä¸º pad é•¿åº¦ï¼Œé¿å… runâ€‘time int()
        # åªè¿”å›å¸§çº§æ©ç  [B]ï¼›åœ¨ embed_inputs ä¸­å†æŒ‰ token ç»´å¹¿æ’­
        return pc_dict, pc_mask

    # ---------- æ—§æ¥å£ ----------
    legacy = getattr(obs, "pointcloud_data", None)
    if legacy is None:
        return None

    # a) å·²ç»æ˜¯ dict
    if isinstance(legacy, dict) and "coord" in legacy:
        pc_dict = _canonicalize_point_dict(legacy)
        # å¼ºå¥‘çº¦ï¼šlegacy-dict å¿…é¡»å·²æ˜¯ Sonata å…¼å®¹æ ¼å¼ï¼›ä¸å¾—åœ¨æ¨¡å‹å†…â€œæ¨æ–­/ä¿®å¤â€ã€‚
        # 1) éœ€è¦æ˜¾å¼æä¾› grid_coordï¼ˆN,3ï¼‰å¹¶ä¸”ä¸º int32 éè´Ÿ
        if "grid_coord" not in pc_dict:
            raise ValueError(
                "Legacy dict ç¼ºå°‘ grid_coordã€‚ä¸¥æ ¼å¯¹é½ SpatialLMï¼šè¯·åœ¨ä¸Šæ¸¸æ˜¾å¼æä¾›éè´Ÿ int32 ä½“ç´ åæ ‡ (N,3)ã€‚"
            )
        # 2) offset/batch è‹¥ç¼ºçœå¯ç”± wrapper æŒ‰ batch é‡å»ºï¼›ä½†ä¸åšä»»ä½•å€¼åŸŸä¿®å¤
    else:
        # b) æ—§æ¥å£è‹¥åªæ˜¯ [B,P,C] åŸå§‹æ•°ç»„ï¼šä¸å†åœ¨æ¨¡å‹å†…ä½“ç´ åŒ–/é‡å»º gridï¼ˆé¿å…â€œè¶Šæƒä¿®å¤â€ï¼‰ã€‚
        raise ValueError(
            "Legacy path æ”¶åˆ° [B,P,C] æ•°ç»„ï¼Œä½†ä¸¥æ ¼æ¨¡å¼ä¸‹æ¨¡å‹ä¸å†ä»£æ›¿ä½ ä½“ç´ åŒ–/æ„é€  gridã€‚"
            "è¯·åœ¨ä¸Šæ¸¸æŠŠç‚¹äº‘è½¬æ¢ä¸º Sonata å…¼å®¹ dictï¼Œæ˜¾å¼æä¾› grid_coord(int32,éè´Ÿ)ã€coord(float32,xyz)ã€feat([xyz,...])ã€‚"
        )

    # æ—§æ¥å£ï¼šä» offset æˆ– batch æ¨å¯¼æ¯å¸§æ˜¯å¦å­˜åœ¨ç‚¹äº‘ï¼ˆä¸æ–°æ¥å£çš„å¸§çº§è¯­ä¹‰ä¸€è‡´ï¼‰
    if "offset" in pc_dict:
        off = pc_dict["offset"].astype(jnp.int32)
        B = off.shape[0]
        counts = jnp.diff(jnp.pad(off, (1, 0)))
        mask = counts > 0
        return pc_dict, mask
    if "batch" in pc_dict:
        b = pc_dict["batch"].astype(jnp.int32)
        B = int(jnp.max(b)) + 1 if b.size else 0
        counts = jnp.bincount(b, length=B)
        mask = counts > 0
        return pc_dict, mask
    raise ValueError("Legacy dict éœ€åŒ…å« 'offset' æˆ– 'batch' ä»¥æ¨æ–­ batch å°ºå¯¸ã€‚")

# Alias the Sonata class from the sonata_encoder module for convenience
Sonata = sonata_encoder.Sonata

@dataclasses.dataclass(frozen=True)
class Pi0FASTSonataConfig(_pi0_fast.Pi0FASTConfig):
    """Configuration for the Pi0FASTSonata model (Pi0FAST with Sonata point cloud encoder)."""

    # === SpatialLM å¥‘çº¦ ===
    # point_feat_dim å®šä¹‰ä¸ºä¼ å…¥ Sonata çš„ feats ç»´åº¦ï¼ˆä¸å« gridï¼‰ï¼š
    # feats = [xyz(3), extra...]ï¼Œä¾‹å¦‚ xyzrgb â‡’ point_feat_dim = 6
    # Observation.pointcloud çš„æœ€åä¸€ç»´ = 3(grid) + point_feat_dim
    point_feat_dim: int = 6
    # æ¯å¸§ç‚¹æ•°çš„é™æ€ä¸Šç•Œï¼ˆä»…ç”¨äº inputs_spec çš„å½¢çŠ¶å£°æ˜ï¼›ä¸ä¼šæˆªæ–­å®é™…è¾“å…¥ï¼‰
    max_points: int = 32768
    # è®©çˆ¶ç±» Pi0FASTConfig.inputs_spec() æŒ‰åŸé€»è¾‘è‡ªåŠ¨æ³¨å…¥ç‚¹äº‘å­—æ®µ
    # ï¼ˆPi0FASTSonata æœ¬èº«ä¸ä¼šç”¨è¿™ä¸ªæšä¸¾å»æ„å»ºæ¨¡å—ï¼Œåªç”¨äº specï¼‰
    point_backbone_type: PointBackboneType = PointBackboneType.SONATA
    # projector_type å¯¹ spec æ— å½±å“ï¼Œè¿™é‡Œä¿æŒ None æˆ– LINEAR å‡å¯
    projector_type: ProjectorType | None = None

    dtype: str = "bfloat16"
    paligemma_variant: _gemma.Variant = "gemma_2b"
    # Inherits default action_dim, action_horizon, max_token_len from Pi0FASTConfig (e.g., 32, 32, 250)
    use_pretrained_point: bool = True      # è°ƒè¯•é˜¶æ®µå¯è®¾ False è·³è¿‡ä¸‹è½½
    # è‹¥ä½¿ç”¨ Sonataï¼Œåˆ™é»˜è®¤**å¿…é¡»**æä¾›ç‚¹äº‘ï¼›ç¼ºå¤±æ—¶ç›´æ¥æŠ¥é”™è€Œä¸æ˜¯é™é»˜é™çº§
    # è‹¥éœ€è¦åªç”¨å›¾åƒ+æ–‡æœ¬åšæ¶ˆèï¼Œå¯æŠŠè¯¥å¼€å…³è®¾ä¸º False
    require_pointcloud: bool = True
    # è‹¥æ— å›¾åƒåˆ™ç›´æ¥ä¸è®­ç»ƒï¼ˆè®­ç»ƒæ—¶æŠ¥é”™ç»ˆæ­¢ï¼›æ¨ç†ä¸å—å½±å“ï¼Œè¿™é‡Œä¸»è¦ç”¨äºè¿›è¡Œè°ƒè¯•ç¡®ä¿æ•°æ®é›†æ­£ç¡®ï¼‰
    require_image: bool = True
    # === åŸä½æ’å…¥ï¼ˆSpatialLM å¯¹é½ï¼‰ ===
    insert_points_in_place: bool = True
    # è¿™ä¸¤ä¸ª id å¿…é¡»ä¸ä½ çš„ tokenizer ä¸­çš„ special tokens ä¸€è‡´
    point_start_id: Optional[int] = None   # ä¾‹å¦‚ tokenizer("<|point_start|>") çš„ id
    point_end_id:   Optional[int] = None   # ä¾‹å¦‚ tokenizer("<|point_end|>")   çš„ id
    # é»˜è®¤ä¸å…è®¸ start/end ä¹‹é—´ä»æœ‰äººç±»æ–‡æœ¬ï¼›è‹¥ä½ çš„æ•°æ®ä¸­ç¡®å®å­˜åœ¨ï¼Œå¯è®¾ True
    allow_text_between_markers: bool = False
    # è‹¥ä¸º Trueï¼Œåˆ™åœ¨åŸä½æ’å…¥è·¯å¾„ä¸¥æ ¼å¤åˆ» SpatialLMï¼š
    #   â€¢ ä¿ç•™ <start>/<end>ï¼›â€¢ åˆ é™¤ä¸­é—´æ–‡æœ¬ï¼›â€¢ åœ¨ <start> åæ’å…¥ K ä¸ªç‚¹ tokenï¼›
    spatiallm_exact: bool = True

    @property
    def model_type(self) -> _model.ModelType:
        # Reuse the PI0_FAST model type (since this is an extension of Pi0-FAST architecture)
        return _model.ModelType.PI0_FAST

    def create(self, rng: jax.Array) -> "Pi0FASTSonata":
        """Instantiate a Pi0FASTSonata model with random initialization."""
        return Pi0FASTSonata(self, rngs=nnx.Rngs(rng))

# ---- è¦†å†™ inputs_specï¼šåˆ‡æ¢åˆ°â€œæ–°æ¥å£â€ï¼Œä¸ SpatialLM çš„ Sonata è¾“å…¥å¥‘çº¦ç­‰ä»· ----
    def inputs_spec(self, *, batch_size: int = 1) -> tuple[_model.Observation, _model.Actions]:
        image_spec = jax.ShapeDtypeStruct([batch_size, *_model.IMAGE_RESOLUTION, 3], jnp.float32)
        image_mask_spec = jax.ShapeDtypeStruct([batch_size], jnp.bool_)
        with at.disable_typechecking():
            observation_spec = _model.Observation(
                images={
                    "base_0_rgb": image_spec,
                    "base_1_rgb": image_spec,
                    "wrist_0_rgb": image_spec,
                },
                image_masks={
                    "base_0_rgb": image_mask_spec,
                    "base_1_rgb": image_mask_spec,
                    "wrist_0_rgb": image_mask_spec,
                },
                state=jax.ShapeDtypeStruct([batch_size, self.action_dim], jnp.float32),
                tokenized_prompt=jax.ShapeDtypeStruct([batch_size, self.max_token_len], jnp.int32),
                tokenized_prompt_mask=jax.ShapeDtypeStruct([batch_size, self.max_token_len], jnp.bool_),
                token_ar_mask=jax.ShapeDtypeStruct([batch_size, self.max_token_len], jnp.int32),
                token_loss_mask=jax.ShapeDtypeStruct([batch_size, self.max_token_len], jnp.bool_),
                # ç‚¹äº‘ï¼ˆæ–°æ¥å£ï¼‰ï¼šä¸ SpatialLM çš„ Sonata è°ƒç”¨ä¿æŒç­‰ä»·è¯­ä¹‰
                #  - point_clouds["pointcloud"]: [B, M, 3 + C] (float32)
                #      [:,:,0:3] = grid_coordï¼ˆæœŸæœ› int32ï¼Œéè´Ÿï¼›æ­¤å¤„æŒ‰ float32 è§„æ ¼å£°æ˜ï¼Œè¿è¡Œæ—¶ä¼š castï¼‰
                #      [:,:,3:6] = coord xyzï¼ˆfloat32ï¼‰
                #      [:,:,6:]  = å…¶å®ƒç‰¹å¾ï¼ˆfloat32ï¼‰
                #  - point_cloud_masks["pointcloud"]: [B] bool  â€”â€” æŒ‡ç¤ºè¯¥æ ·æœ¬æ˜¯å¦å­˜åœ¨ç‚¹äº‘
                point_clouds={"pointcloud": jax.ShapeDtypeStruct([batch_size, self.max_points, 3 + self.point_feat_dim], jnp.float32)},
                point_cloud_masks={"pointcloud": jax.ShapeDtypeStruct([batch_size], jnp.bool_)},
            )
        action_spec = jax.ShapeDtypeStruct([batch_size, self.action_horizon, self.action_dim], jnp.float32)
        return observation_spec, action_spec
class Pi0FASTSonata(_model.BaseModel):
    """
    Pi0FASTSonata model: Extends Pi0-FAST to incorporate a Sonata point cloud encoder.
    Combines vision (SigLIP image encoder), language (PaLI-Gemma LLM), and point cloud (Sonata) encoders.
    """
    def __init__(self, config: Pi0FASTSonataConfig, rngs: nnx.Rngs):
        # Initialize base model (setup action_dim, action_horizon, etc.)
        super().__init__(config.action_dim, config.action_horizon, config.max_token_len)

        # --------------------------------------------------------------
        # è®°å½•æ˜¯å¦å¼ºåˆ¶è¦æ±‚ç‚¹äº‘
        self._require_pointcloud = bool(getattr(config, "require_pointcloud", True))
        self._require_image = bool(getattr(config, "require_image", True))
        # è®¾å®šç»Ÿä¸€ deviceï¼ˆGPU å¦‚æœå¯ç”¨ï¼Œå¦åˆ™ CPUï¼‰
        # --------------------------------------------------------------
        self.device: torch.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        
        # ------------------------------------------------------------------
        # 1) è¯­è¨€æ¨¡å‹  Gemma  ------------------------------------------------
        # ------------------------------------------------------------------
        # ------------------------------------------------------------------
        # Gemmaâ€‘fast LLM ----------------------------------------------------
        # ------------------------------------------------------------------
        pal_cfg = _gemma.get_config(config.paligemma_variant)

        # æ ¹æ® gemma_fast.Module çš„ __init__ ç­¾åè‡ªåŠ¨æ”¶é›†éœ€è¦çš„å‚æ•°
        gemma_sig = inspect.signature(_gemma.Module.__init__)
        pal_kwargs: dict[str, typing.Any] = {}
        for name in gemma_sig.parameters:
            if name == "self":          # è·³è¿‡ self
                continue
            if hasattr(pal_cfg, name):
                pal_kwargs[name] = getattr(pal_cfg, name)

        # è‹¥ get_config æ²¡è¿”å› variantï¼Œåˆ™ç”¨ä¼ å…¥çš„æšä¸¾å­—ç¬¦ä¸²è¡¥é½
        pal_kwargs.setdefault("variant", config.paligemma_variant)

        # å…¶å®ƒ dtype ç›¸å…³è¦†å†™
        pal_kwargs["embed_dtype"] = config.dtype
        pal_kwargs["cache_dtype"] = config.dtype

        llm = nnx_bridge.ToNNX(_gemma.Module(**pal_kwargs))

        # åˆå§‹åŒ–
        llm.lazy_init(rngs=rngs, method="init")

        # ------------------------------------------------------------------
        # 2) å›¾åƒç¼–ç å™¨  SigLIP  --------------------------------------------
        # ------------------------------------------------------------------
        _model_width = getattr(pal_cfg, "width", getattr(pal_cfg, "hidden_size", 1024))
        
        raw_img_kwargs = dict(
            # _siglip.Module å¯èƒ½ä¸éœ€è¦ num_classesï¼›å¦‚æœ signature é‡Œæ²¡æœ‰ä¼šè¢«è‡ªåŠ¨ä¸¢å¼ƒ
            num_classes=_model_width,
            variant="So400m/14",
            pool_type="none",
            scan=True,
            dtype_mm=config.dtype,
        )

        # ---------------------------------------------------------------------------------

        img = nnx_bridge.ToNNX(_siglip.Module(**raw_img_kwargs))

        # Initialize image encoder with a dummy image to set dimensions
        dummy_image = next(iter(config.fake_obs(batch_size=1).images.values()))
        img.lazy_init(dummy_image, train=False, rngs=rngs)

        # ------------------------------------------------------------------
        # 3) åˆ›å»ºå¹¶åŠ è½½ç‚¹äº‘ç¼–ç å™¨ (Sonata) â€” å‚æ•°å¯¹é½ SpatialLMâ€‘1.1, åé¢å¯ä»¥æ”¹æˆconfigä¼ è¾“
        # ------------------------------------------------------------------
        
        # ---------- Sonata hyperâ€‘params â€“ ä¸ ckpt ä¿æŒ 100â€¯% ä¸€è‡´ ----------
        # in_channels = feats ç»´åº¦ï¼ˆä¸å« grid çš„3åˆ—ï¼‰
        if not hasattr(config, "point_feat_dim"):
            raise ValueError(
                "Pi0FASTSonataConfig éœ€æ˜¾å¼æä¾› point_feat_dimï¼ˆ= feats ç»´åº¦ï¼Œxyz+extrasï¼Œä¸å« gridï¼‰"
            )
        # ä¸ SpatialLM å¥‘çº¦ä¸€è‡´ï¼šin_channels = feats åˆ—æ•°ï¼ˆå« xyzï¼Œä¸å« gridï¼‰
        _in_channels = int(config.point_feat_dim)  # e.g., xyzrgb -> 6
        if _in_channels < 3:
            raise ValueError(
                f"é…ç½® point_feat_dim={config.point_feat_dim} æ— æ•ˆï¼Œé¡» â‰¥ 3ï¼ˆè‡³å°‘åŒ…å«è¿ç»­ xyzï¼‰"
            )
        # è‹¥åç»­è¾“å…¥ç‚¹äº‘ç‰¹å¾ç»´ä¸é…ç½®ä¸ç¬¦ï¼Œå°†åœ¨ embed_inputs æ—©æœŸæŠ¥é”™

        # è‹¥æœªå®‰è£… flash_attnï¼Œè‡ªåŠ¨ç¦ç”¨ä»¥é¿å…æ–­è¨€å¤±è´¥
        _enable_flash = (getattr(sonata_encoder, "flash_attn", None) is not None)
        if not _enable_flash and not getattr(Pi0FASTSonata, "_warned_no_flash", False):
            logger.warning("[Sonata] flash-attn not found; falling back to non-flash path (slower, it is highly recommended to use flash-attn).")
            Pi0FASTSonata._warned_no_flash = True
        sp_cfg = dict(
            in_channels   = _in_channels,
            order         = ("z", "z-trans"),
            stride        = (2, 2, 2, 2),         # 5â€‘stage â‡’ 4 æ¬¡ä¸‹é‡‡æ ·
            enc_depths    = (3, 3, 3, 12, 3),
            enc_channels  = (48, 96, 192, 384, 512),   # â˜… æœ«ç«¯ 512
            enc_num_head  = (3, 6, 12, 24, 32),
            enc_patch_size= (1024,)*5,            # ckpt é»˜è®¤
            mlp_ratio     = 4.0,
            mask_token    = True,                   # Sonata.Embedding ä¸­ mask_token åŠŸèƒ½è¢«ç¦ç”¨ï¼Œæ­¤å‚æ•°æ— æ•ˆ
            enc_mode=True,  # å³voxel
            enable_fourier_encode = True,         # â˜… ckpt å« fourier+input_proj
            num_bins      = 1280,
            enable_flash  = _enable_flash,
        )
        point_model = Sonata(**sp_cfg)
        # è®°å½•ä¾›åç»­æ–­è¨€ï¼Projector ä½¿ç”¨
        self._point_in_channels = _in_channels  # feats ç»´åº¦ï¼ˆxyz+extrasï¼‰
        # ä¸ SpatialLM ä¸€è‡´ï¼šproj è¾“å…¥ç»´ = ç¼–ç å™¨æœ«å±‚é€šé“
        self._enc_out_dim = sp_cfg["enc_channels"][-1]

        if config.use_pretrained_point:
            # ------------------------------------------------------------------
            # ä»…ä½¿ç”¨æœ¬åœ°ç²¾ç®€åçš„ SpatialLM1.1 Sonata æƒé‡
            # æ–‡ä»¶æ”¾ç½®: <repo_root>/openpi/pretrain/SpatialLM_Sonata_encoder.pth
            # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œè¯·ä½¿ç”¨uv run scripts/sonata_weight_gen.pyæ¥è·å–sonataçš„checkpoint
            # ------------------------------------------------------------------
            # è·¯å¾„æŒ‡å‘ <repo_root>/src/pretrain/
            ckpt_path = (
                Path(__file__).resolve().parents[2]  # -> â€¦/openpi/src
                / "pretrain" / "SpatialLM_Sonata_encoder.pth"
            )
            if not ckpt_path.is_file():
                raise FileNotFoundError(
                    f"Sonata é¢„è®­ç»ƒæƒé‡æœªæ‰¾åˆ°: {ckpt_path}\n"
                    "è¯·å…ˆè¿è¡Œ scripts/sonata_weight_gen.py ç”Ÿæˆæ–‡ä»¶ï¼Œ"
                    "å¹¶æ”¾ç½®åˆ° src/pretrain/ ç›®å½•ã€‚"
                )
            logger.info("Using local Sonata weights: %s", ckpt_path)


            # åŠ è½½æƒé‡ â€”â€” PyTorch 2.6+ é»˜è®¤ weights_only=Trueï¼Œä¼šæ‹¦ä½åŒ…å«
            # numpy æ ‡é‡çš„è€å¼ state_dictï¼Œè¿™é‡Œæ˜¾å¼å…³æ‰å³å¯ã€‚
            load_kwargs = dict(map_location="cpu")
            if "weights_only" in inspect.signature(torch.load).parameters:
                load_kwargs["weights_only"] = False

            raw_obj = torch.load(ckpt_path, **load_kwargs)

            # â‘ è‹¥æ˜¯è®­ç»ƒ checkpointï¼Œå…ˆå–å‡ºçœŸæ­£æƒé‡
            if isinstance(raw_obj, dict) and "state_dict" in raw_obj:
                state_dict = raw_obj["state_dict"]
            else:
                state_dict = raw_obj

            # â‘¡å»æ‰å¤šä½™å‰ç¼€ï¼ˆå¦‚ "module." æˆ– "model.")
            cleaned = {}
            for k, v in state_dict.items():
                if k.startswith(("module.", "model.", "student.backbone.", "student.", "point_backbone.")):
                    cleaned[k.split(".", 1)[1]] = v
                else:
                    cleaned[k] = v

            # â‘¡â€‘bisï¼šæŒ‰æƒé‡â€œæ¨æ–­â€ in_channelsï¼Œä¸€è‡´æ€§ä¿æŠ¤
            wkey = "embedding.stem.linear.weight"
            if wkey in cleaned:
                in_from_ckpt = cleaned[wkey].shape[1]  # [out, in]
                if in_from_ckpt != self._point_in_channels:
                    logger.warning(
                        "Sonata ckpt in_channels=%d != configured point_feat_dim=%d; "
                        "rebuilding Sonata to match checkpoint (prefer checkpoint to avoid shape mismatch).",
                        in_from_ckpt, self._point_in_channels
                    )
                    # é‡æ–°æ„å»ºä¸æƒé‡ä¸€è‡´çš„ Sonataï¼Œå†è½½å…¥
                    sp_cfg_ckpt = {**sp_cfg, "in_channels": int(in_from_ckpt)}
                    point_model = Sonata(**sp_cfg_ckpt)
                    point_model.to(self.device).eval()
                    self._point_in_channels = int(in_from_ckpt)
                    self._enc_out_dim = sp_cfg_ckpt["enc_channels"][-1]

            # â‘¢éƒ¨åˆ†åŒ¹é…å³å¯ï¼›strict=False ä¼šè·³è¿‡å¤šä½™é”®ï¼Œä¹Ÿä¼šæç¤ºå“ªäº›æ²¡åŠ è½½
            ik = point_model.load_state_dict(cleaned, strict=False)
            if getattr(ik, "missing_keys", None):
                mk = ik.missing_keys
                logger.warning("Sonata weights: %d missing params, e.g. %s", len(mk), mk[:5])
            if getattr(ik, "unexpected_keys", None):
                uk = ik.unexpected_keys
                logger.warning("Sonata weights: %d unexpected params, e.g. %s", len(uk), uk[:5])

            logger.info("Loaded pretrained Sonata weights from %s", ckpt_path)

        else:
            logger.warning(
                "Pi0FASTâ€‘Sonata: use_pretrained_point=False -> "
                "Sonata encoder starts with random weights."
            )

        # -------- ä¿è¯ Sonata æ•´ä¸ªç½‘ç»œåœ¨ GPUï¼ˆå« spconv kernelï¼‰ --------
        point_model.to(self.device)
        point_model.eval()  # inference mode

        # ------------------------------------------------------------------
        # 4) å®šä¹‰ _TorchSonataWrapper â€”â€” ä¿æŒåŸ APIï¼Œæ–°å¢ GPU æ”¯æŒ
        # ------------------------------------------------------------------
        class _TorchSonataWrapper(torch.nn.Module):
            """
            - è¿½è¸ªæœŸï¼ˆJIT / lazy_initï¼‰åªè¿”å› ShapeDtypeStructï¼Œä¸è·‘çœŸæ¨¡å‹ã€‚
            - è¿è¡ŒæœŸé€šè¿‡ pure_callback æŠŠ numpy â†’ torch.cuda â†’ numpyã€‚
            """
            def __init__(
                self,
                pt_model: torch.nn.Module,
                device: torch.device,
                patch_size: int,
                enc_out_dim: int,
            ):
                super().__init__()
                # ç¡®ä¿ pt_model å·²åœ¨ç›®æ ‡ device
                self.inner = pt_model.to(device).eval()
                self.device = device
                self.patch_size = patch_size
                self.enc_out_dim = enc_out_dim

            # ---------- å†…éƒ¨ util ----------
            @staticmethod
            @torch.no_grad()
            def _torch_forward(
                inner: torch.nn.Module,
                host_dict: Dict[str, np.ndarray],
                device: torch.device,
                patch_size: int,
                enc_out_dim: int,
            ) -> Tuple[np.ndarray, np.ndarray]:  # ç¬¬ 2 ä¸ª ndarray æ˜¯ bool æ©ç 
                """
                æ¥æ”¶ host ä¸Šçš„ numpy è¾“å…¥ â†’ torch.Tensor.cuda â†’ è¿è¡Œ â†’ numpy è¾“å‡º
                ç»Ÿä¸€è¿”å› float32 numpy æ•°ç»„
                """

                # ---------- fastâ€‘pathï¼šè¯¥å¸§ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›å…¨é›¶ ----------
                present = int(host_dict.pop("present", 1))
                if present == 0:
                    pad_feat   = np.zeros((patch_size, enc_out_dim), dtype=np.float32)
                    valid_mask = np.zeros((patch_size,),       dtype=bool)
                    return pad_feat, valid_mask
                
                # =========================================================
                # â˜… æ–°å¢ï¼šè‹¥ä¸Šæ¸¸ä¼ å…¥ selected_batchï¼Œåªä¿ç•™è¿™ä¸€å¸§çš„ç‚¹
                #   (è¿™æ · embed_inputs é‡Œä¸ç”¨ v[sel]ï¼Œé¿å… JAX å¸ƒå°”åˆ‡ç‰‡æŠ¥é”™)
                # ---------------------------------------------------------
                if "selected_batch" in host_dict:
                    sb = int(host_dict.pop("selected_batch"))
                    if "batch" in host_dict:
                        b_arr = np.asarray(host_dict["batch"]).reshape(-1)
                        sel = (b_arr == sb)                     # sel.shape == (B*M,)
                        # 1) å…ˆæŒ‰ç‚¹çº§åˆ«åˆ‡æ‰€æœ‰â€œå±•å¹³â€çš„å¼ é‡ï¼ˆcoord/feat/batch ç­‰ï¼‰
                        for k, v in list(host_dict.items()):
                            if hasattr(v, "shape") and v.ndim and v.shape[0] == sel.shape[0]:
                                host_dict[k] = v[sel]
                        # 2) å†å¯¹â€œæŒ‰å¸§æ‰“åŒ…â€çš„å¼ é‡åˆ‡ç¬¬ 0 ç»´ï¼ˆå…¸å‹ï¼šgrid_coord[B,M,3]ã€grid_size[B,3]ï¼‰
                        #    æ¨æ–­ Bï¼šä¼˜å…ˆç”¨ offset é•¿åº¦ï¼Œå¦åˆ™ç”¨ batch ä¸­çš„æœ€å¤§å€¼+1
                        if "offset" in host_dict:
                            B = int(np.asarray(host_dict["offset"]).reshape(-1).shape[0])
                        else:
                            B = int(b_arr.max()) + 1 if b_arr.size else 0
                        if B:
                            for k, v in list(host_dict.items()):
                                if hasattr(v, "shape") and v.ndim >= 2 and v.shape[0] == B:
                                    host_dict[k] = v[sb]
                    else:
                        # æ—  batch é”®ï¼šæŒ‰ç¬¬ 0 ç»´æ˜¯ batch è½´å¤„ç†ï¼ˆv çš„å½¢çŠ¶å½¢å¦‚ (B, M, ...) æˆ– (B, 3)ï¼‰
                        for k, v in list(host_dict.items()):
                            if hasattr(v, "shape") and v.ndim >= 2 and v.shape[0] > sb:
                                host_dict[k] = v[sb]
                    # å•æ ·æœ¬è¯­ä¹‰ï¼šbatch å…¨ 0ï¼Œoffset = [ç‚¹æ•°]
                    n_pts = int(host_dict["coord"].shape[0])
                    host_dict["batch"]  = np.zeros(n_pts, dtype=np.int64)
                    host_dict["offset"] = np.array([n_pts], dtype=np.int64)
                # =========================================================

                # ---------- å…ˆå®‰å…¨æ‰å¹³åŒ– ----------
                if host_dict["coord"].ndim != 2:         # (B,N,3) â†’ (B*N,3)
                    B, N, _ = host_dict["coord"].shape
                    host_dict["coord"] = host_dict["coord"].reshape(B * N, 3)
                    host_dict["feat"]  = host_dict["feat"].reshape(B * N, -1)
                    host_dict["batch"] = np.repeat(np.arange(B, dtype=np.int64), N)
                    host_dict["offset"] = np.cumsum(np.full((B,), N, dtype=np.int64))

                # grid_coord å¯èƒ½æ¥è‡ªä½“ç´ ç½‘æ ¼ â†’ ä¿è¯æ˜¯ (P,3)
                for _key in ("grid_coord",):
                    if _key in host_dict and host_dict[_key].ndim == 3:
                        host_dict[_key] = host_dict[_key].reshape(-1, 3)
                
                # ---------- grid éè´Ÿæ€§æ£€æŸ¥ï¼ˆhost ä¾§ï¼ŒJIT å®‰å…¨ï¼‰ ----------
                if "grid_coord" not in host_dict:
                    raise ValueError(
                        "[SpatialLMâ€‘Sonata] ç¼ºå°‘ grid_coordï¼›"
                        "ä¸¥æ ¼æ¨¡å¼è¦æ±‚ä¸Šæ¸¸æ˜¾å¼æä¾›éè´Ÿ int32 ä½“ç´ åæ ‡ (N,3)ã€‚"
                        "è¯·å°† Observation.point_clouds['pointcloud'] çš„å‰ 3 åˆ—ä½œä¸º grid ä¼ å…¥ï¼Œæˆ–åœ¨ legacy dict ä¸­æä¾› 'grid_coord'ã€‚"
                    )
                gc = host_dict["grid_coord"]
                if gc.ndim == 3:
                    gc = gc.reshape(-1, 3)
                    host_dict["grid_coord"] = gc
                if gc.shape[1] != 3:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] grid_coord ç»´åº¦é”™è¯¯ï¼šæœŸå¾… (N,3)ï¼Œå®é™… {gc.shape}ã€‚")
                if not np.issubdtype(gc.dtype, np.integer):
                    raise ValueError(f"[SpatialLMâ€‘Sonata] grid_coord dtype å¿…é¡»ä¸ºæ•´æ•°ï¼ˆå»ºè®® int32ï¼‰ï¼Œå®é™… {gc.dtype}ã€‚")
                if np.any(gc < 0):
                    raise ValueError("[SpatialLMâ€‘Sonata] grid_coord å«è´Ÿå€¼ï¼›è¯·åœ¨ä¸Šæ¸¸ä½“ç´ åŒ–æ—¶ä¿è¯æ¯ç»´ç´¢å¼• â‰¥ 0ã€‚")
                # ---- coord / feat å½¢çŠ¶&dtype ä¸¥æ ¼æ ¡éªŒï¼ˆçº¯æŠ¥é”™ï¼Œä¸åšè½¬æ¢ï¼Œè¿™æ˜¯ä¸ºäº†ç¡®ä¿èƒ½æ‰¾åˆ°æ•°æ®é›†çš„é”™è¯¯è€Œä¸ä¼šé”™è¯¯åœ°æŠŠé”™è¯¯åœ°æ•°æ®é›†ç»™å¼„å¾—å¯ç”¨é€ æˆsilent errorï¼‰ ----
                c = host_dict["coord"]
                f = host_dict["feat"]
                if c.ndim != 2 or c.shape[1] != 3:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] coord å½¢çŠ¶å¿…é¡»ä¸º (N,3)ï¼Œå®é™… {c.shape}ã€‚")
                if f.ndim != 2:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] feat å½¢çŠ¶å¿…é¡»ä¸º (N,C)ï¼Œå®é™… {f.shape}ã€‚")
                if c.dtype != np.float32:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] coord dtype å¿…é¡»ä¸º float32ï¼Œå®é™… {c.dtype}ã€‚")
                if f.dtype != np.float32:
                    raise ValueError(f"[SpatialLMâ€‘Sonata] feat dtype å¿…é¡»ä¸º float32ï¼Œå®é™… {f.dtype}ã€‚")
                # ---- batch/offsetï¼ˆå¦‚æä¾›ï¼‰ä¸€è‡´æ€§æ ¡éªŒ ----
                if "batch" in host_dict:
                    b = host_dict["batch"]
                    if b.ndim != 1:
                        raise ValueError(f"[SpatialLMâ€‘Sonata] batch å¿…é¡»æ˜¯ä¸€ç»´å‘é‡ (N,)ï¼Œå®é™… {b.shape}ã€‚")
                    if b.shape[0] != c.shape[0]:
                        raise ValueError(f"[SpatialLMâ€‘Sonata] batch é•¿åº¦ {b.shape[0]} ä¸ç‚¹æ•° {c.shape[0]} ä¸ä¸€è‡´ã€‚")
                    if not np.issubdtype(b.dtype, np.integer):
                        raise ValueError(f"[SpatialLMâ€‘Sonata] batch dtype å¿…é¡»ä¸ºæ•´æ•°ï¼Œå®é™… {b.dtype}ã€‚")
                    if np.any(b < 0):
                        raise ValueError("[SpatialLMâ€‘Sonata] batch å«è´Ÿå€¼ã€‚")
                if "offset" in host_dict:
                    off = host_dict["offset"]
                    if off.ndim != 1:
                        raise ValueError(f"[SpatialLMâ€‘Sonata] offset å¿…é¡»æ˜¯ä¸€ç»´å‘é‡ (B,)ï¼Œå®é™… {off.shape}ã€‚")
                    if not np.issubdtype(off.dtype, np.integer):
                        raise ValueError(f"[SpatialLMâ€‘Sonata] offset dtype å¿…é¡»ä¸ºæ•´æ•°ï¼Œå®é™… {off.dtype}ã€‚")
                    if np.any(off <= 0) or np.any(off[1:] < off[:-1]):
                        raise ValueError("[SpatialLMâ€‘Sonata] offset å¿…é¡»ä¸ºä¸¥æ ¼é€’å¢çš„å‰ç¼€å’Œã€‚")
                    if off[-1] != c.shape[0]:
                        raise ValueError(f"[SpatialLMâ€‘Sonata] offset[-1]={off[-1]} ä¸ç­‰äºç‚¹æ•° N={c.shape[0]}ã€‚")
                # SpatialLM æœªå¯¹ä¸Šç•Œåšç¡¬æ–­è¨€ï¼›è‹¥å®ç°æš´éœ²äº† reduced_grid_sizeï¼Œä»…è­¦å‘Šä¸€æ¬¡
                if getattr(inner, "enable_fourier_encode", False) and hasattr(inner, "reduced_grid_size"):
                    reduced_gs = int(getattr(inner, "reduced_grid_size"))
                    if np.any(gc >= reduced_gs) and not getattr(_TorchSonataWrapper, "_warned_grid_upper", False):
                        warnings.warn(
                            f"[Sonata] grid_coord è¶…è¿‡ reduced_grid_size={reduced_gs}ï¼›å¦‚å‡ºç°ç²¾åº¦/æ€§èƒ½å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ä½“ç´ åŒ–é…ç½®ã€‚",
                            RuntimeWarning
                        )
                        _TorchSonataWrapper._warned_grid_upper = True
                
                # grid_coord ä¸ coord ç‚¹æ•°å¿…é¡»ä¸€è‡´
                if host_dict["grid_coord"].shape[0] != host_dict["coord"].shape[0]:
                    raise ValueError(
                        f"[SpatialLMâ€‘Sonata] ç‚¹æ•°ä¸ä¸€è‡´ï¼šgrid_coord N={host_dict['grid_coord'].shape[0]} "
                        f"â‰  coord N={host_dict['coord'].shape[0]}ã€‚"
                    )
                
                # ---------- è‹¥ç¼º offsetï¼Œåˆ™æ ¹æ® batch ç”Ÿæˆ ----------
                if "offset" not in host_dict:
                    if "batch" in host_dict:
                        # --------------------------------------------------
                        # 1. ä¿è¯ batch æ˜¯ 1â€‘D int64
                        # --------------------------------------------------
                        b_arr = np.asarray(host_dict["batch"]).astype(np.int64)
                        if b_arr.ndim > 1:
                            b_arr = b_arr.reshape(-1)
                        host_dict["batch"] = b_arr

                        # 2. ç»Ÿè®¡æ¯ä¸ª batch çš„ç‚¹æ•° â†’ å‰ç¼€å’Œ
                        counts = np.bincount(b_arr)
                        host_dict["offset"] = np.cumsum(counts, dtype=np.int64)
                    else:
                        # å• batch æƒ…å½¢
                        host_dict["offset"] = np.array(
                            [host_dict["coord"].shape[0]], dtype=np.int64
                        )

                assert host_dict["coord"].shape[0] == host_dict["offset"][-1], (
                    f"coord N={host_dict['coord'].shape[0]}, "
                    f"but offset[-1]={host_dict['offset'][-1]}"
                )

                # ---------- NaN è¿‡æ»¤ï¼šä¸ SpatialLMâ€‘Qwen å®Œå…¨ä¸€è‡´ ----------
                nan_mask = (
                    np.isnan(host_dict["coord"]).any(axis=1)
                    | np.isnan(host_dict["feat"]).any(axis=1)
                )
                if nan_mask.any():
                    keep = ~nan_mask
                    for k in ("coord", "feat", "grid_coord"):
                        if k in host_dict:
                            host_dict[k] = host_dict[k][keep]
                    host_dict["batch"] = host_dict["batch"][keep]
                    # é‡æ–°è®¡ç®— offset  (prefixâ€sum of perâ€‘batch counts)
                    counts = np.bincount(host_dict["batch"])
                    host_dict["offset"] = np.cumsum(counts, dtype=np.int64)
                
                # ===== SpatialLMâ€‘style ç©ºç‚¹äº‘ä¿æŠ¤ =====
                if host_dict["coord"].shape[0] == 0:
                    # è¿”å›å…¨é›¶ç‰¹å¾ + å…¨ False æœ‰æ•ˆæ ‡è®°ï¼ˆç»´åº¦ä¸æ­£å¸¸è·¯å¾„ä¸€è‡´ï¼‰
                    pad_feat   = np.zeros((patch_size, enc_out_dim), dtype=np.float32)
                    valid_mask = np.zeros((patch_size,),       dtype=bool)
                    return pad_feat, valid_mask

                # ä¸¥æ ¼æ¨¡å¼ï¼šä¸å†åœ¨æ¨¡å‹å†…â€œé‡å»º/åç§»â€ gridã€‚ç¼ºå¤±å·²åœ¨å‰é¢æŠ¥é”™ã€‚
                
                # ---------- å¥‘çº¦æ ¡éªŒï¼šfeat å‰ 3 ç»´åº”ä¸ coordï¼ˆè¿ç»­ xyzï¼‰ä¸€è‡´ ----------
                if host_dict["feat"].shape[1] >= 3:
                    max_abs = float(np.max(np.abs(host_dict["feat"][:, :3] - host_dict["coord"])))
                    if not np.isfinite(max_abs) or max_abs > 1e-4:
                        raise ValueError(
                            f"[SpatialLMâ€‘Sonata] å¥‘çº¦ä¸æ»¡è¶³ï¼šfeat[:,:3]ï¼ˆåº”ä¸º xyzï¼‰ä¸ coord ä¸ä¸€è‡´ï¼›"
                            f"max|diff|={max_abs:.3e}ã€‚è¯·ä¿è¯ feats = [xyz, extras] ä¸” coord=xyzã€‚"
                        )

                # pure_callback æŠŠ jax.Array ç›´æ¥é€è¿‡æ¥ï¼›å¿…é¡»å…ˆè½¬æˆçœŸæ­£çš„ numpy
                # æ˜¾å¼ copyï¼šé¿å… "The given NumPy array is not writable" è­¦å‘Š
                tch_in = {
                    k: torch.from_numpy(np.array(v, copy=True)).to(device)
                    for k, v in host_dict.items()
                }
                # Sonata é‡Œè¦åš (batch << 48)ï¼Œå¿…é¡»æ˜¯ int64
                for key in ("batch", "offset"):
                    if key in tch_in:
                        tch_in[key] = tch_in[key].long()
                out = inner(tch_in)
                # SpatialLM çº¦å®šï¼šSonata.forward() è¿”å› torch.Tensorï¼ˆæœ€ç»ˆç‰¹å¾ï¼‰
                if not isinstance(out, torch.Tensor):
                    raise TypeError(
                        f"Sonata.forward is expected to return a torch.Tensor "
                        f"(as in SpatialLM), but got: {type(out)}. "
                        f"Please ensure Sonata.forward returns the feature tensor."
                    )

                real_len = out.size(0)
                if real_len > patch_size:
                    raise RuntimeError(
                        f"[SpatialLMâ€‘Sonata] token_len={real_len} è¶…è¿‡ä¸Šé™ patch_size={patch_size}ã€‚"
                        "è¯·å¢å¤§ Sonata enc_patch_size[-1]ï¼ˆä¼šå¢æ˜¾å­˜ï¼‰æˆ–åœ¨ä¸Šæ¸¸å‡å°‘æ¯æ ·æœ¬ç‚¹æ•°ã€‚"
                    )
                # SpatialLM: ä¸æˆªæ–­ï¼›å³ pad åˆ° patch_size çš„å€æ•°
                # --- ä¿ç•™å›ºå®š 1024â€‘padding ä»¥ç»´æŒé™æ€ shape (JAX éœ€æ±‚ï¼Œæ”¹æˆä¸å›ºå®šçš„ä»£ä»·å¾ˆå¤§ï¼Œå¦‚æœå•çº¯åŠ å¤§åˆ™å®¹æ˜“ç‚¸æ˜¾å­˜) ---
                # ------------------------------------------------------------------
                # æˆªæ–­å‰åšæ˜¾å¼æŠ¥è­¦ï¼šè¿™ä¸ªæ˜¯å› ä¸ºå¦‚æœæˆ‘ä»¬è¦æ”¹æˆéå›ºå®šï¼Œä¼šå¯¼è‡´æ— æ³•jaxåŒ–ï¼Œè®¡ç®—ä»£ä»·å¾ˆå¤§ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨è¿™ç§æ–¹å¼è¿›è¡Œæµ‹è¯•ï¼Œæ¥çœ‹çœ‹æ•°æ®é›†èƒ½ä¸èƒ½æä¾›åˆç†æ•°æ®
                # ------------------------------------------------------------------
                MAX_TOKEN = patch_size                  # =1024 (enc_patch_size[-1])
                if real_len > MAX_TOKEN:
                    # ç›´æ¥é˜»æ–­ï¼šç”¨æˆ·å¿…é¡»æ˜¾å¼æé«˜ enc_patch_size[-1] æˆ–å‡å°‘ç‚¹æ•°
                    raise RuntimeError(
                        f"[Sonata] token_len={real_len} exceeds configured MAX_TOKEN "
                        f"({MAX_TOKEN}). Increase `enc_patch_size[-1]` or reduce the "
                        "number of points per sample."
                    )
                pad_len = MAX_TOKEN - real_len
                if pad_len:
                    pad = out.new_zeros(pad_len, out.size(1))
                    out = torch.cat([out, pad], 0)
                valid_mask = np.arange(MAX_TOKEN) < real_len
                return out.float().cpu().numpy(), valid_mask

            # ---------- forward ----------
            def forward(self, pc_dict, *, train: bool = False):
                host_inputs = {k: jnp.asarray(v) for k, v in pc_dict.items()}
                # tree_flatten è¿”å› (flat_list, treedef)ï¼›åè€…è´Ÿè´£åå‘å±•å¼€
                flat, treedef = jax.tree_util.tree_flatten(host_inputs)

                # -----------------------------------------------------------
                # ä¾‹å¦‚é™æ€ä¸Šé™, è¿™é‡Œè®¾ç½®1024ï¼Œå¯ä»¥è®¾ç½®8192 (= 8 patch)ï¼›ç¡®ä¿ä¸ä¼šåœ¨çœŸå®è¾“å…¥ä¸­è¶…å‡ºä½†æ˜¯è¿™æ ·ä¼šç‚¸æ˜¾å­˜,æ‰€ä»¥æˆ‘ä»¬ä¿ç•™1024å®ç°, åç»­å¯ä»¥ç»§ç»­åŠ 
                # patch_size ç”± Wrapper æ„é€ å‡½æ•°ä¼ å…¥ï¼›ä¿æŒä¸ Sonata enc_patch_size ä¸€è‡´
                MAX_TOKEN = self.patch_size
                C = self.enc_out_dim
                out_struct = (ShapeDtypeStruct((MAX_TOKEN, C), jnp.float32),
                              ShapeDtypeStruct((MAX_TOKEN,),  jnp.bool_))

                def _host_call(*flat_np):
                    # flat_np æ˜¯å›ä¼ çš„æ‰å¹³åˆ—è¡¨/å…ƒç»„ï¼Œéœ€ç”¨ treedef.unflatten è¿˜åŸ
                    np_dict = treedef.unflatten(list(flat_np))
                    return self._torch_forward(
                        self.inner, np_dict, self.device, self.patch_size, self.enc_out_dim
                    )

                feat, valid_mask = pure_callback(
                    _host_call, out_struct, *flat, vectorized=False
                )

                # ---- Runtime contract check: channel dim must match projector ----
                assert feat.shape[-1] == self.enc_out_dim, (
                    f"[SonataWrapper] Output dim {feat.shape[-1]} "
                    f"!= expected {self.enc_out_dim}. "
                    "Check Sonata ckpt / config."
                )
                # ç›´æ¥è¿”å› (feat, valid_mask)ï¼›ç”±è°ƒç”¨æ–¹è‡ªè¡Œæ„é€  mask
                return feat, valid_mask

            # ---------- NNX åˆå§‹åŒ– ----------
            def init_with_output(
                self,
                rngs,
                pc_dict,
                *,
                train: bool = False,
                method: typing.Any = None,
                **_,
            ):
                dummy_out = self.forward(pc_dict, train=train)
                return dummy_out, {}  # æœ¬ wrapper ä¸å«å¯è®­ç»ƒå‚æ•°

            # --------------------------------------------------------------
            # â˜… å…¼å®¹ nnxâ€‘bridge è°ƒç”¨ï¼šé‡è½½ applyï¼Œå¿½ç•¥ variables / rngs. ä»¥åéœ€è¦rngéœ€è¦å°†å…¶ä¼ å…¥ä½†ç›®å‰ä¼ å…¥ä¼šé€ æˆå…¼å®¹æ€§é—®é¢˜
            # --------------------------------------------------------------
            def apply(                       # type: ignore[override]
                self,
                _variables,                  # nnxâ€‘bridge ä¼ å…¥çš„å ä½å˜é‡åŒ…ï¼ˆunusedï¼‰
                *args,
                rngs=None,
                method: str | None = "forward",
                **kwargs,
            ):
                """
                â€¢ method ä¸º nnxâ€‘bridge æŒ‡å®šçš„å‡½æ•°åï¼Œä¾‹å¦‚ "forward"ã€
                  "init_with_output"ï¼›é»˜è®¤ = "forward"  
                â€¢ rngs ä»…åœ¨ lazy_init æ—¶ä¼šä¼ å…¥ï¼ŒSonata ä¸ä½¿ç”¨ï¼Œç›´æ¥ä¸¢å¼ƒ
                """
                if method is None:
                    method = "forward"
    
                # é€‰å®šè¢«è°ƒå‡½æ•°
                target_fn = getattr(self, method)
    
                # init_with_output çš„ç­¾åä¸º (rngs, pc_dict, â€¦)
                if method == "init_with_output":
                    return target_fn(rngs, *args, **kwargs)
    
                # å…¶ä½™æ–¹æ³•ï¼ˆforward ç­‰ï¼‰
                return target_fn(*args, **kwargs)
                
        # ------------------------------------------------------------------
        # 4â€‘bis) çº¿æ€§å±‚åŒ…è£…å™¨ï¼šè®©æ™®é€š Linear æ”¯æŒ lazy_init
        # ------------------------------------------------------------------
        class _TorchLinearWrapper(torch.nn.Module):
            def __init__(self, in_dim: int, out_dim: int, device: torch.device, *, bias: bool = True):
                super().__init__()
                self.inner = torch.nn.Linear(in_dim, out_dim, bias=bias).to(device)
                self.device = device

            # -------- hostâ€‘sideè®¡ç®— --------
            @staticmethod
            @torch.no_grad()
            def _torch_forward(inner: torch.nn.Linear,
                               mat_np: np.ndarray,
                               device: torch.device) -> np.ndarray:
                """
               çº¯ host è°ƒç”¨ï¼šnp -> torch(cuda) -> np
                """
                # ä¿è¯ä¸€å®šæ˜¯ NumPyï¼Œå†é€å…¥ PyTorch
                if not isinstance(mat_np, np.ndarray):
                    mat_np = np.asarray(mat_np)
                x = torch.from_numpy(mat_np).to(inner.weight.dtype).to(device)
                y = inner(x)
                return y.cpu().numpy()

            # -------- forwardï¼ˆJAX sideï¼‰--------
            def forward(self, x_jax: jax.Array, *, train: bool = False):
                """
                â€¢ åœ¨ jit å›¾é‡Œä»¥ pure_callback æ–¹å¼è°ƒç”¨ _torch_forward  
                â€¢ è¾“å‡ºä¿æŒ float32ï¼Œåç»­å† cast
                """
                # è®¡ç®—è¾“å‡ºå½¢çŠ¶ï¼ˆå®Œå…¨ç¬¦å·åŒ–ï¼Œä¸è§¦å‘ concreteï¼‰
                out_shape = (*x_jax.shape[:-1], self.inner.out_features)
                out_struct = ShapeDtypeStruct(out_shape, jnp.float32)

                def _host_call(mat):
                    # mat æ˜¯ numpy.ndarray ï¼ˆpure_callback å·²è½¬æ¢ï¼‰
                    return self._torch_forward(self.inner, mat, self.device)

                return pure_callback(_host_call, out_struct, x_jax, vectorized=False)

            # -------- lazy_init hook --------
            def init_with_output(self, rngs, x_np, *, method=None, **_):
                """
                lazy_initâ€¯é˜¶æ®µä¸ä¼šåœ¨ jit å†…ï¼Œ
                ç›´æ¥èµ° hostâ€‘side è®¡ç®—å³å¯ï¼ŒåŠ é€Ÿåˆå§‹åŒ–ã€‚
                """
                if isinstance(x_np, jax.Array):
                    x_np = np.asarray(jax.device_get(x_np))
                y = self._torch_forward(self.inner, x_np, self.device)
                return y, {}          # no trainable vars

            # -------- nnxâ€‘bridge å…¼å®¹ --------
            def apply(self, _vars, *args, rngs=None, method: str | None = "forward", **kw):
                if method is None:
                    method = "forward"
                fn = getattr(self, method)
                if method == "init_with_output":
                    return fn(rngs, *args, **kw)
                return fn(*args, **kw)

        # ---------- 5) åŸç”Ÿ NNX çº¿æ€§æŠ•å½±ï¼šæ”¯æŒç«¯åˆ°ç«¯åå‘ä¼ æ’­ã€é¿å… host å¾€è¿” ----------
        # enc_out_dim â†’ PaLIâ€‘Gemma hidden_size
        self.PointProjector = nnx.Linear(self._enc_out_dim, _model_width, rngs=rngs)

        # è®©æŠ•å½±å±‚è·Ÿéš PyTorch çš„ deviceï¼Œä¸å¿…æ‰‹åŠ¨è¿ç§»é™¤éåç»­ç»§ç»­é‡å†™åˆ°jax

        N = 64               # 64 points (dummy)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Sonata çº¦å®šçš„ Point ç»“æ„ï¼ˆåŠ¡å¿…æ‰å¹³åŒ–ï¼‰ï¼š
        #   coord : (Total_N, 3)   float32 / int32
        #   feat  : (Total_N, C)
        #   batch : (Total_N,)     **int64**  â† è¦èƒ½åš Â«batchÂ <<Â 48Â»
        #   offset: (B,)           ç´¯è®¡ç‚¹æ•°å‰ç¼€å’Œ  **int64**
        #   grid_size : (B, 3)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ä¸ SpatialLM å¥‘çº¦ä¸€è‡´ï¼šfeat[:,:3] å¿…é¡»ç­‰äº coordï¼ˆè¿ç»­ xyzï¼‰
        coord_dummy = jnp.arange(N * 3, dtype=jnp.float32).reshape(N, 3)
        extra_dims = int(self._point_in_channels) - 3
        feat_dummy = (
            jnp.concatenate(
                [coord_dummy, jnp.zeros((N, extra_dims), jnp.float32)], axis=-1
            )
            if extra_dims > 0 else coord_dummy
        )
        grid_dummy = jnp.zeros((N, 3), dtype=jnp.int32)   # ä¸¥æ ¼æ¨¡å¼ï¼šdummy ä¹Ÿæä¾›éè´Ÿ int32 grid
        raw_dummy_pc = {
            "coord":  coord_dummy,
            "feat":   feat_dummy,                         # â† å‰ 3 åˆ— = coord
            # JAX ç«¯ int32ï¼›host ç«¯å†å‡åˆ° int64
            "batch":  jnp.zeros((N,),  dtype=jnp.int32),
            "offset": jnp.array([N],   dtype=jnp.int32),
            "grid_coord": grid_dummy,
        }
        dummy_pc = _canonicalize_point_dict(raw_dummy_pc)

        _patch_sz = sp_cfg["enc_patch_size"][-1]   # 1024 (ä¿æŒä¸ ckpt ä¸€è‡´)
        point = nnx_bridge.ToNNX(
            _TorchSonataWrapper(
                point_model,
                self.device,
                _patch_sz,
                self._enc_out_dim,   # â† ä¸ __init__ å¯¹é½
            )
        )
        # è®°å½• point block çš„å›ºå®šé•¿åº¦ï¼ˆ= Sonata enc_patch_size[-1]ï¼Œé»˜è®¤ 1024ï¼‰
        self._pt_block_len = int(_patch_sz)
        
        # æ˜ç¡®ä½¿ç”¨ wrapper çš„ init_with_output ä»¥é¿å…åœ¨ä¸åŒ nnx-bridge ç‰ˆæœ¬ä¸‹çš„æ­§ä¹‰
        point.lazy_init(dummy_pc, train=False, rngs=rngs, method="init_with_output")
        # â†‘ è‹¥ä½ çš„ nnx ç‰ˆæœ¬ä¼šè‡ªåŠ¨è¯†åˆ«ï¼Œåˆ™è¿™è¡Œä¸ä¸Šä¸€è¡Œç­‰ä»·ï¼›æ˜¾å¼åŒ–æ›´ç¨³

        # ------------------------------------------------------------------
        # 6) æ‰“åŒ…æ‰€æœ‰å­æ¨¡å—
        # ------------------------------------------------------------------
        self.PaliGemma = nnx.Dict(
            llm   = llm,
            img   = img,
            point = point,
            point_proj = self.PointProjector,
        )
        # æ’å…¥ç­–ç•¥ä¸ special ids
        self._insert_points_in_place = bool(getattr(config, "insert_points_in_place", True))
        self._point_start_id = getattr(config, "point_start_id", None)
        self._point_end_id   = getattr(config, "point_end_id", None)
        self._warned_no_point_ids = False
        self._allow_text_between = bool(getattr(config, "allow_text_between_markers", False))
        self._spatiallm_exact = bool(getattr(config, "spatiallm_exact", True))

    def embed_inputs(
        self, obs: _model.Observation
    ) -> tuple[jax.Array, jax.Array, jax.Array]:
        """
        Embed all input modalities (images, point cloud, text tokens) into sequences of token embeddings.
        Returns:
            token_embeddings (jax.Array): concatenated token features of shape [B, N, emb_dim]
            input_mask (jax.Array[bool]): mask indicating valid tokens [B, N]
            ar_mask (jax.Array[int]): autoregressive mask for tokens [B, N] (0 where tokens attend freely, 1 where causal dependence begins).
        """
        token_embeddings: list[jax.Array] = []
        input_mask: list[jax.Array] = []
        ar_mask: list[jax.Array] = []

        # ---------- 1) èšåˆå›¾åƒ tokens ï¼ˆå…ˆåˆå¹¶æ‰€æœ‰ç›¸æœºï¼Œä¾¿äºåç»­é€æ ·æœ¬æ’å…¥é€»è¾‘ï¼‰ ----------
        img_tok_list = []
        img_msk_list = []
        for cam_name, image in obs.images.items():
            img_t, _ = self.PaliGemma.img(image, train=False)       # [B, n_img_tok, D]
            img_tok_list.append(img_t)
            m = jnp.broadcast_to(
                obs.image_masks[cam_name][:, None],
                (obs.image_masks[cam_name].shape[0], img_t.shape[1]),
            )
            img_msk_list.append(m)
        if len(img_tok_list):
            img_tokens = jnp.concatenate(img_tok_list, axis=1)      # [B, Nimg, D]
            img_mask   = jnp.concatenate(img_msk_list, axis=1)      # [B, Nimg]
        else:
            # ç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼ˆä½ çš„ config.require_image=Trueï¼‰ï¼Œå…œåº•
            B = obs.tokenized_prompt.shape[0]
            D = int(getattr(self.PaliGemma.llm.module, "hidden_size", 1024))
            img_tokens = jnp.zeros((B, 0, D), dtype=jnp.float32)
            img_mask   = jnp.zeros((B, 0),   dtype=bool)
        img_ar = jnp.zeros_like(img_mask, dtype=jnp.int32)

        # 2. Point cloud tokens --------------------------------------------------
        pc_pack = _extract_point_batch(obs)
        # è‹¥æœ¬æ¨¡å‹å¯ç”¨äº† Sonataï¼ˆå³æœ¬ç±»æœ¬èº«ï¼‰ä¸”é…ç½®è¦æ±‚ç‚¹äº‘ï¼Œåˆ™ç¼ºå¤±æ—¶ç›´æ¥æŠ¥é”™
        if pc_pack is None and self._require_pointcloud:
            raise ValueError(
                "Pi0FASTâ€‘Sonata: æœªæä¾›ç‚¹äº‘ï¼Œä½†é…ç½® require_pointcloud=Trueã€‚"
                "è¯·æä¾› Observation.point_clouds['pointcloud']ï¼ˆåŠ maskï¼‰æˆ– Observation.pointcloud_dataï¼›"
                "è‹¥ç¡®éœ€åªç”¨å›¾åƒ+æ–‡æœ¬ï¼Œè¯·å°† Pi0FASTSonataConfig.require_pointcloud=Falseã€‚"
            )
        if pc_pack is not None:
            # --------------------------------------------------------
            # ä¸ SpatialLMâ€‘Qwen forward_point_cloud å®Œå…¨ä¸€è‡´çš„ç­–ç•¥ï¼š
            # forâ€‘loop é€æ ·æœ¬è°ƒç”¨ Sonata â†’ æ¯æ¬¡å¾—åˆ° (K*1024, C)ï¼Œ
            # å†ç»Ÿä¸€ pad åˆ°åŒä¸€é•¿åº¦ã€‚
            # --------------------------------------------------------
            pc_dict_all, pc_frame_mask = pc_pack        # pc_frame_mask : [B, M]
            # å¦‚æœç‚¹äº‘ä¹Ÿå£°æ˜ require_pointcloud=Trueï¼Œä½† pc_frame_mask å…¨ Falseï¼Œè¿™ä¸€æ‰¹æ•°æ®åº”ç›´æ¥å¤±è´¥ï¼Œè€Œä¸æ˜¯æŠŠç‚¹äº‘å½“ä½œä¸å­˜åœ¨ï¼ˆé˜²æ­¢æ‚„æ‚„è®­ç»ƒåœ¨é”™è¯¯åˆ†å¸ƒä¸Šï¼‰
            if self._require_pointcloud:
                # ã€ä¿®å¤ã€‘ç¦æ­¢åœ¨ jit ä¸­åš Python å¸ƒå°”åˆ¤æ–­ï¼›æ”¹ä¸º host æ–­è¨€ï¼ˆè¿è¡ŒæœŸï¼‰ï¼š
                # present_any ä¸º 0-d boolï¼ˆtracedï¼‰ï¼Œç”¨ pure_callback åœ¨ host ä¸Šåˆ¤æ–­å¹¶æŠ›å¼‚å¸¸ï¼ˆå¿…è¦æ—¶ï¼‰ã€‚
                present_any = jnp.any(pc_frame_mask.astype(bool))

                def _host_assert_present(x):
                    # x: numpy 0-d bool
                    x = bool(np.asarray(x))
                    if not x:
                        raise RuntimeError(
                            "Pi0FASTâ€‘Sonata: require_pointcloud=True ä½†è¯¥ batch æ‰€æœ‰æ ·æœ¬å‡æ— ç‚¹äº‘ã€‚"
                        )
                    # è¿”å›ä¸€ä¸ªè™šå ä½ï¼ˆæ»¡è¶³ pure_callback çš„è¿”å›å¥‘çº¦ï¼‰
                    return np.int32(0)

                # å ä½è¾“å‡ºæè¿°
                _ = pure_callback(
                    _host_assert_present,
                    ShapeDtypeStruct((), jnp.int32),
                    present_any,
                    vectorized=False,
                )
            # B çš„é²æ£’æ¨æ–­ï¼šä¼˜å…ˆ offsetï¼›å¦åˆ™é€€åŒ–åˆ° mask / prompt çš„ batch ç»´
            if "offset" in pc_dict_all:
                B = int(pc_dict_all["offset"].shape[0])
            elif pc_frame_mask.ndim in (1, 2):
                B = int(pc_frame_mask.shape[0])
            else:
                B = int(obs.tokenized_prompt.shape[0])

            # è¿è¡Œæ—¶ç»´åº¦æ£€æŸ¥ï¼šfeat = xyz(3) + extra(...)ï¼Œå…¶åˆ—æ•°åº”ç­‰äº in_channels
            feat_dim = int(pc_dict_all["feat"].shape[-1])            # = feats ç»´åº¦ï¼ˆxyz+extrasï¼‰
            expected_feat_dim = int(self._point_in_channels)          # = config.point_feat_dim
            if feat_dim != expected_feat_dim:
                raise ValueError(
                    "ç‚¹äº‘ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼šæœŸæœ› feats ç»´åº¦ï¼ˆxyz+extraï¼‰= "
                    f"{expected_feat_dim}ï¼Œä½†æ”¶åˆ° {feat_dim}ã€‚"
                    "è¯·ç¡®ä¿ Observation.pointcloud çš„å‰3åˆ—ä¸º gridï¼Œåç»­åˆ—ä¸º feats=[xyz, extras]ï¼›"
                    "Sonata çš„ in_channels=feats åˆ—æ•°ï¼ˆä¸å« gridï¼‰ã€‚"
                )

            per_sample_tokens  = []
            per_sample_masks   = []
            max_len            = 0

            for b in range(B):                                    # **é€ batch**
                # æŠŠ sample id + present ä¼ ç»™ wrapperï¼›çœŸæ­£åˆ‡ç‰‡åœ¨ PyTorch ä¾§å®Œæˆ
                if pc_frame_mask.ndim == 2:
                    present_b = pc_frame_mask[b].any()
                else:
                    present_b = pc_frame_mask[b]
                single_dict = {
                    **pc_dict_all,                                  # å…¨é‡ç‚¹äº‘
                    "selected_batch": jnp.array(b, jnp.int32),      # æŒ‡å®šæ ·æœ¬
                    "present": present_b.astype(jnp.int32),         # å¸§å­˜åœ¨æ ‡å¿—
                }
                # æ—©æœŸå½¢çŠ¶æ£€æŸ¥ï¼šgrid_coord å¿…é¡»æœ€åä¸€ç»´=3ï¼Œè¿™æ˜¯ä¸ºäº†æµ‹è¯•æ•°æ®é›†æ˜¯ä¸æ˜¯çœŸæ­£çš„x,y,z,r,g,b,æ–¹ä¾¿åç»­æµ‹è¯•
                if "grid_coord" in single_dict:
                    if single_dict["grid_coord"].shape[-1] != 3:
                        raise ValueError(
                            f"pointcloud grid_coord çš„æœ€åä¸€ç»´å¿…é¡»ä¸º 3ï¼Œ"
                            f"å®é™… shape={single_dict['grid_coord'].shape}"
                        )
                # ä¸¥æ ¼æ¨¡å¼ï¼šä¸å†åœ¨æ¨¡å‹å†…é‡å»º gridï¼›ç¼ºå¤±ç«‹åˆ»æŠ¥é”™ï¼ˆä¿æŒä¸ SpatialLM å¥‘çº¦ä¸€è‡´ï¼‰
                if "grid_coord" not in single_dict:
                    raise ValueError(
                        "[SpatialLMâ€‘Sonata] å½“å‰æ ·æœ¬ç¼ºå°‘ grid_coordï¼›è¯·åœ¨æ•°æ®ç®¡çº¿ä¸­æ˜¾å¼æä¾›ä½“ç´ ç´¢å¼• (N,3,int32,éè´Ÿ)ã€‚"
                    )

                tok, vmask = self.PaliGemma.point(single_dict, train=False)

                # -------- é•¿åº¦ä¸€è‡´æ€§æ–­è¨€ --------
                assert tok.shape[0] == vmask.shape[0], (
                    f"Sonata è¿”å› token é•¿åº¦ {tok.shape[0]} "
                    f"â‰  valid_mask é•¿åº¦ {vmask.shape[0]}"
                )

                # æŠ•å½±åˆ° LLM hidden_size ï¼Œä¿æŒä¸å›¾åƒ / æ–‡æœ¬ç»´åº¦ä¸€è‡´
                tok = self.PointProjector(tok.astype(jnp.float32))
                # æŠŠ padding / æ— æ•ˆ token ç‰¹å¾å¼ºåˆ¶å½’é›¶ï¼Œé˜²æ­¢ Linear åç½®æ³„æ¼
                tok = tok * vmask[:, None]

                # SpatialLM ä¿ç•™è¡¥é›¶ tokenï¼Œé  vmask æŒ‡ç¤ºæœ‰æ•ˆæ€§
                per_sample_tokens.append(tok)       # â† ç›´æ¥æ•´å—ä¿å­˜
                per_sample_masks.append(vmask)
                max_len = max(max_len, tok.shape[0])   # ä¸€èˆ¬å°±æ˜¯ 1024

            # ----- pad åˆ° batch å†…æœ€å¤§é•¿åº¦ -----------
            def _pad_to(x, tgt):
                pad = [(0, tgt - x.shape[0])] + [(0, 0)]*(x.ndim-1)
                return jnp.pad(x, pad)

            pt_tokens = jnp.stack([_pad_to(t, max_len) for t in per_sample_tokens])  # (B,P,C) P=max_len(=patch_size)
            valid_m   = jnp.stack([_pad_to(m, max_len) for m in per_sample_masks])   # (B,P)

            # äºŒæ¬¡éªŒè¯ï¼šæ‰€æœ‰ batch é•¿åº¦å·²ç»å¯¹é½
            assert (pt_tokens.shape[1] == valid_m.shape[1] == max_len), \
                "pad å token / mask é•¿åº¦ä¸ä¸€è‡´"

            # --- å¸§çº§æ©ç ï¼šå…ˆæŠŠ [B] æˆ– [B, M] å‹æˆ [B,1]ï¼ˆæ˜¯å¦å­˜åœ¨è¯¥æ¨¡æ€ï¼‰ï¼Œå†å¹¿æ’­åˆ° token ç»´ ---
            frame_present = (
                pc_frame_mask.any(axis=1, keepdims=True)  # [B,1] é€‚é… [B,M] æƒ…å†µ
                if pc_frame_mask.ndim == 2 else
                pc_frame_mask[:, None]                   # [B,1]
            )
            pc_frame_mask_b = jnp.broadcast_to(frame_present, (B, max_len))  # [B, max_len]
            pt_final_mask   = pc_frame_mask_b & valid_m

            # æ•°å€¼æ›´å¹²å‡€ï¼šæŠŠæœ€ç»ˆ mask ä¹Ÿä¹˜è¿›ç‰¹å¾ï¼ˆä»…ç”¨äºå¯è§†åŒ–ï¼›ä¸‹é¢åŸä½æ’å…¥æ—¶ä»ä¼šå†å†™å…¥ä¸€æ¬¡ï¼‰
            pt_tokens = pt_tokens * pt_final_mask[:, :, None]
        else:
            # æ²¡æœ‰ç‚¹äº‘ï¼šæ„é€ ç©º blockï¼ˆé•¿åº¦ = 0ï¼›ä½†é€šå¸¸ require_pointcloud=True ä¸ä¼šèµ°åˆ°è¿™é‡Œï¼‰
            B = obs.tokenized_prompt.shape[0]
            D = int(getattr(self.PaliGemma.llm.module, "hidden_size", 1024))
            pt_tokens = jnp.zeros((B, 0, D), dtype=jnp.float32)
            pt_final_mask = jnp.zeros((B, 0), dtype=bool)

        # 3. Text tokens (from language model embedding)
        # Ensure textual inputs are present
        assert obs.tokenized_prompt is not None and obs.tokenized_prompt_mask is not None and obs.token_ar_mask is not None, \
            "Tokenized prompt and corresponding masks must be provided for text inputs."
        txt_tokens = self.PaliGemma.llm(obs.tokenized_prompt, embed_only=True)  # [B, L, emb_dim]
        # é¿å…å¦‚æœé”™è¯¯åœ°ç»™äº†ç©ºpromptæˆ–åªæœ‰1ä¸ªtokenï¼Œåœ¨åé¢é€»è¾‘é‡Œäº§ç”Ÿâ€œ0é•¿åº¦ä½†ä¸æŠ¥é”™â€
        if obs.tokenized_prompt.shape[1] < 2:
           raise ValueError("tokenized_prompt é•¿åº¦å¿…é¡» â‰¥ 2ï¼Œç”¨äºæ„é€  next-token ç›‘ç£ã€‚")
        # â€”â€” ç»Ÿä¸€ä¸‰æ¨¡æ€ embedding çš„ dtypeï¼ˆå°¤å…¶æ˜¯åŸä½æ’å…¥æ—¶ dynamic_update_slice å¿…é¡»ä¸€è‡´ï¼‰â€”â€” #
        target_dtype = txt_tokens.dtype
        pt_tokens = pt_tokens.astype(target_dtype)
        # ---- A) åŸä½æ’å…¥ï¼ˆSpatialLM ä¸€è‡´ï¼‰æˆ–å®‰å…¨å›é€€ ----
        use_inplace = (
            self._spatiallm_exact
            and self._insert_points_in_place
            and (self._point_start_id is not None)
            and (self._point_end_id   is not None)
        )
        if self._insert_points_in_place and not use_inplace and not self._warned_no_point_ids:
            logger.warning(
                "insert_points_in_place=True ä½†æœªæä¾› point_start_id/point_end_idï¼›"
                "å°†å›é€€åˆ°å‰ç¼€æ‹¼æ¥è·¯å¾„ã€‚è¦è·å¾—ä¸ SpatialLM å®Œå…¨ä¸€è‡´çš„æ’å…¥è¡Œä¸ºï¼Œè¯·åœ¨é…ç½®ä¸­æä¾›è¿™ä¸¤ä¸ªç‰¹æ®Š token çš„ idã€‚"
            )
            self._warned_no_point_ids = True
        if use_inplace:
            # ===== SpatialLM-exact æ’å…¥ï¼šä¿ç•™ <start>/<end>ï¼Œåˆ é™¤ä¸­é—´æ–‡æœ¬ï¼Œ<start> åæ’å…¥ K ä¸ªç‚¹ =====
            # è¯´æ˜ï¼š
            #   â€¢ ä¸ºäº†é¿å… JAX å½¢çŠ¶å¤šæ€ï¼Œæœ¬å®ç°å°†â€œæ–‡æœ¬+ç‚¹æ®µâ€çš„ buffer å›ºå®šä¸º L + Pï¼ˆP=å›ºå®šç‚¹å—ä¸Šé™ï¼‰ï¼Œ
            #     ç„¶è€Œå³ä¾§æ–‡æœ¬çš„â€œæœ‰æ•ˆèµ·ç‚¹â€åŸºäºçœŸå® Kï¼ˆ= sum(valid_mask)ï¼‰ï¼Œå¹¶ä¸” mask/labels åªè¦†ç›–æœ‰æ•ˆèŒƒå›´ã€‚
            #   â€¢ è¿™æ ·åœ¨è¯­ä¹‰ä¸ç›‘ç£ä¸Šå®Œå…¨ç­‰ä»·äº SpatialLM çš„â€œpad åˆ°æœ¬ batch çš„ max_num_tokensâ€ï¼Œåªæ˜¯æˆ‘ä»¬å›ºå®šåˆ° L+Pã€‚
            B, L, D = txt_tokens.shape
            P = pt_tokens.shape[1]                  # å›ºå®šå—ä¸Šé™ï¼ˆé€šå¸¸=1024ï¼‰
            LM = L + P                              # å›ºå®šçš„â€œæ–‡æœ¬+ç‚¹â€æ®µ buffer é•¿åº¦
            img_tokens = img_tokens.astype(target_dtype)
            pt_tokens  = pt_tokens.astype(target_dtype)

            # --- å®šä½æ¯ä¸ªæ ·æœ¬çš„ <start>/<end>ï¼ˆä¸é™åˆ¶äºŒè€…ä¹‹é—´æ˜¯å¦æœ‰æ–‡æœ¬ï¼›ä¸ SpatialLM ä¸€è‡´ï¼‰ ---
            out_struct = (ShapeDtypeStruct((2,), jnp.int32),)
            win_list = []
            for b in range(B):
                def _host_call(arr):
                    return _host_find_window_only(
                        np.asarray(arr),
                        int(self._point_start_id),
                        int(self._point_end_id),
                    )
                (w_b,) = pure_callback(_host_call, out_struct, obs.tokenized_prompt[b], vectorized=False)
                win_list.append(w_b)
            win_all = jnp.stack(win_list, axis=0)         # [B,2]  -> (s,e)

            # --- é€æ ·æœ¬è£…é…ï¼šé€šè¿‡â€œæ¡ä»¶ç´¢å¼• + takeâ€é¿å…åŠ¨æ€å½¢çŠ¶æ›´æ–° ---
            seq_list, msk_list, ar_list = [], [], []
            for b in range(B):
                s_idx = win_all[b, 0]                     # <start> ä½ç½®
                e_idx = win_all[b, 1]                     # <end>   ä½ç½®
                # æœ‰æ•ˆç‚¹æ•° Kï¼šåªç»Ÿè®¡æœ‰æ•ˆ maskï¼ˆframe å­˜åœ¨ + Sonata è¾“å‡º validï¼‰
                K_b = jnp.sum(pt_final_mask[b].astype(jnp.int32))     # scalar int32
                L_right = L - e_idx                                     # å³æ®µæ–‡æœ¬é•¿åº¦ï¼ˆå« <end> åŠå…¶åçš„æ–‡æœ¬ï¼‰

                # ç›®æ ‡åºåˆ—ï¼ˆä»…æ–‡æœ¬+ç‚¹æ®µï¼‰çš„å…¨é•¿ç´¢å¼•ï¼š0..LM-1ï¼Œå…¶ä¸­ï¼š
                #   [0 .. s]         â† æ–‡æœ¬å·¦æ®µï¼ˆå« <start>ï¼‰
                #   [s+1 .. s+K_b]   â† ç‚¹ tokenï¼ˆçœŸå® K_b ä¸ªï¼‰
                #   [s+K_b+1 .. ...] â† æ–‡æœ¬å³æ®µï¼ˆä» <end> å¼€å§‹ï¼‰
                t = jnp.arange(LM, dtype=jnp.int32)
                pt_start = s_idx + 1
                pt_end   = pt_start + K_b

                left_cond   = (t <  pt_start)
                points_cond = (t >= pt_start) & (t < pt_end)
                right_cond  = (t >= pt_end)   & (t < pt_end + L_right)

                # æ–‡æœ¬ï¼ˆå·¦+å³ï¼‰æºä½ç½®ï¼š
                #   å·¦ï¼š   idx = t
                #   å³ï¼š   idx = e_idx + (t - pt_end)
                txt_idx = jnp.where(left_cond, t, e_idx + (t - pt_end))
                txt_idx = jnp.clip(txt_idx, 0, L - 1)
                # ç‚¹ æºä½ç½®ï¼š
                pt_idx = jnp.clip(t - pt_start, 0, P - 1)

                # å–å‡ºå¹¶æŒ‰æ¡ä»¶æ‹¼è£… embedding
                txt_part = jnp.take(txt_tokens[b], txt_idx, axis=0)
                txt_part = txt_part * (left_cond | right_cond)[:, None].astype(txt_part.dtype)
                pt_part  = jnp.take(pt_tokens[b],  pt_idx,  axis=0)
                pt_part  = pt_part * points_cond[:, None].astype(pt_part.dtype)
                txtpts_scatter = txt_part + pt_part                      # [LM, D]

                # mask / arï¼šæ–‡æœ¬æ²¿ç”¨æºï¼Œç‚¹ä¸€å¾‹ ar=0ï¼›padding ä½ç½®å…¨ False
                txt_mask_src = jnp.take(obs.tokenized_prompt_mask[b].astype(bool), txt_idx, axis=0)
                m_txt = txt_mask_src & (left_cond | right_cond)
                m_pt  = points_cond
                m_txtpt = m_txt | m_pt                                    # [LM]

                txt_ar_src = jnp.take(obs.token_ar_mask[b].astype(jnp.int32), txt_idx, axis=0)
                ar_txt = txt_ar_src * (left_cond | right_cond).astype(jnp.int32)
                ar_pt  = jnp.zeros_like(t, dtype=jnp.int32)
                ar_txtpt = jnp.where(points_cond, ar_pt, ar_txt)          # ç‚¹ token ar=0

                # ä¸å›¾åƒæ‹¼æ¥ï¼š [img | (text+points)]
                seq_b = jnp.concatenate([img_tokens[b], txtpts_scatter], axis=0)
                m_b   = jnp.concatenate([img_mask[b],   m_txtpt], axis=0)
                ar_b  = jnp.concatenate([img_ar[b],     ar_txtpt], axis=0).astype(jnp.int32)

                seq_list.append(seq_b)
                msk_list.append(m_b)
                ar_list.append(ar_b)

            tokens = jnp.stack(seq_list, axis=0)   # [B, Nimg+LM, D]  (LM = L + P)
            mask   = jnp.stack(msk_list,  axis=0)  # [B, Nimg+LM]
            ar     = jnp.stack(ar_list,   axis=0)  # [B, Nimg+LM]
            return tokens, mask, ar

        # ---- B) å‰ç¼€æ‹¼æ¥ï¼ˆé»˜è®¤å›é€€è·¯å¾„ï¼‰ ----
        if len(token_embeddings):
            token_embeddings = [t.astype(target_dtype) for t in token_embeddings]
        token_embeddings.append(img_tokens.astype(target_dtype))
        input_mask.append(img_mask)
        ar_mask.append(img_ar)
        if pt_tokens.shape[1] > 0:
            token_embeddings.append(pt_tokens.astype(target_dtype))
            input_mask.append(pt_final_mask)
            ar_mask.append(jnp.zeros_like(pt_final_mask, dtype=jnp.int32))
        token_embeddings.append(txt_tokens)
        input_mask.append(obs.tokenized_prompt_mask)
        ar_mask.append(obs.token_ar_mask)
        tokens = jnp.concatenate(token_embeddings, axis=1)
        mask   = jnp.concatenate(input_mask,       axis=1)
        ar     = jnp.concatenate(ar_mask,          axis=1)
        return tokens, mask, ar

    def compute_loss(
        self,
        rng: jax.Array,
        observation: _model.Observation,
        actions: _model.Actions,
        *,
        train: bool = False
    ) -> jax.Array:
        """Compute sequence loss for the model (predict next token loss for language prompt)."""
        # Preprocess observation (normalize/augment images, ensure masks)
        # å‘å›¾åƒé¢„å¤„ç†å‡½æ•°ä¼ é€’ RNGï¼ˆä»…åœ¨è®­ç»ƒé˜¶æ®µéœ€è¦ï¼‰
        prep_rng = rng if train else None
        observation = _model.preprocess_observation(prep_rng, observation, train=train, image_keys=list(observation.images.keys()))
        # è‹¥è¦æ±‚æ ·æœ¬å¿…é¡»åŒ…å«å›¾åƒï¼Œè€Œå½“å‰ observation æ— å›¾åƒï¼Œåˆ™ç›´æ¥ä¸­æ­¢è®­ç»ƒ
        if self._require_image and len(observation.images) == 0:
            raise RuntimeError(
                "Pi0FASTâ€‘Sonata: require_image=True but observation contains no images; "
                "abort this training step or filter such samples upstream."
            )
        # Embed all inputs to tokens and get masks
        tokens, mask, ar = self.embed_inputs(observation)
        # Compute attention mask for the sequence (prefix + causal masking as needed)
        attn_mask = _pi0_fast.make_attn_mask(mask, ar)
        # === SpatialLM å¯¹é½çš„æŸå¤±ï¼šåŸä½æ’å…¥åï¼Œæ–‡æœ¬ token ä¸å†â€œæ•´æ®µä½äºæœ«å°¾â€ ===
        # æ–¹æ¡ˆï¼šdecode å…¨é•¿åº¦ï¼Œç„¶åæŒ‰â€œæ–‡æœ¬ token åœ¨æ’å…¥åçš„æ–°ä½ç½® - 1â€å» gather å¯¹åº” logitsï¼Œå†åš CEã€‚
        vocab_size = self.PaliGemma.llm.module.vocab_size
        B, L = observation.tokenized_prompt.shape
        # 1) å…ˆå¾—åˆ°æ•´æ®µ pre_logits â†’ logits_all
        pre_logits, _, _ = self.PaliGemma.llm(
            embedded_prefix=tokens[:, :-1],
            mask=attn_mask[:, :-1, :-1],
            return_prelogits=True
        )
        logits_all, _ = self.PaliGemma.llm(pre_logits=pre_logits)   # [B, T_total-1, V]

        # é™æ€ gatingï¼šåŸä½æ’å…¥éœ€é…ç½®å¥½ä¸¤ä¸ªç‰¹æ®Š token çš„ idï¼Œå¦åˆ™å›é€€å°¾éƒ¨å¯¹é½æŸå¤±
        use_inplace = (
            self._spatiallm_exact
            and self._insert_points_in_place
            and (self._point_start_id is not None)
            and (self._point_end_id   is not None)
        )
        if not use_inplace:
            targets = jax.nn.one_hot(observation.tokenized_prompt[:, 1:], vocab_size)
            logits_tail = logits_all[:, -targets.shape[1]:]
            log_probs = jax.nn.log_softmax(logits_tail, axis=-1)
            assert observation.token_loss_mask is not None
            loss_mask = observation.token_loss_mask[:, 1:]
            token_nll = -jnp.sum(targets * log_probs, axis=-1)
            denom = jnp.maximum(jnp.sum(loss_mask, axis=-1), 1)
            seq_loss = jnp.sum(token_nll * loss_mask, axis=-1) / denom
            return seq_loss

        # 2) SpatialLM-exactï¼šç›´æ¥é‡å»ºâ€œæ’å…¥åâ€çš„ labelsï¼ˆåŒ…å« <start>/<end>ï¼‰ï¼Œç‚¹ä½ç½® IGNORE
        #    æˆ‘ä»¬çš„ tokens åºåˆ—æ˜¯ [img | text+points]ï¼Œå…¶ä¸­ text+points å›ºå®šä¸º L+Pï¼ŒçœŸå®æœ‰æ•ˆé•¿åº¦ä¾ K å†³å®šã€‚
        T_total = tokens.shape[1]
        P = int(getattr(self, "_pt_block_len", 1024))
        LM = observation.tokenized_prompt.shape[1] + P           # = L + P
        Nimg = T_total - LM
        IGNORE = jnp.int32(-100)

        # --- (a) <start>/<end> ä½ç½® ---
        out_struct = (ShapeDtypeStruct((2,), jnp.int32),)
        wins = []
        for b in range(B):
            def _host_call(arr):
                return _host_find_window_only(
                    np.asarray(arr),
                    int(self._point_start_id),
                    int(self._point_end_id),
                )
            (w_b,) = pure_callback(_host_call, out_struct, observation.tokenized_prompt[b], vectorized=False)
            wins.append(w_b)
        win_all = jnp.stack(wins, axis=0)     # [B,2] -> (s,e)
        s_all = win_all[:, 0]
        e_all = win_all[:, 1]

        # --- (b) é€æ ·æœ¬æ±‚æœ‰æ•ˆç‚¹æ•° K â€”â€” ä¸ embed_inputs å®Œå…¨ä¸€è‡´ï¼šå†æ¬¡è°ƒç”¨ Sonata wrapper åªå– valid_mask
        #     æ³¨æ„ï¼šä¸èƒ½ç”¨ mask åœ¨ [s+1 : s+1+P) çš„å’Œæ¥è¿‘ä¼¼ Kï¼Œå› ä¸ºè¯¥çª—å£ä¼šåŒ…å«ä» <end> èµ·çš„å³ä¾§æ–‡æœ¬ï¼›
        #     è¿™ä¼šæŠŠ K ç®—å¤§ï¼Œå¯¼è‡´ label é”™ä½ã€‚å¿…é¡»ä»¥ Sonata çš„ valid_mask ä¸ºå‡†ã€‚
        k_list = []
        pc_pack = _extract_point_batch(observation)
        if pc_pack is None:
            k_list = [jnp.array(0, jnp.int32) for _ in range(B)]
        else:
            pc_dict_all, pc_frame_mask = pc_pack
            for b in range(B):
                present_b = pc_frame_mask[b].any() if pc_frame_mask.ndim == 2 else pc_frame_mask[b]
                single_dict = {
                    **pc_dict_all,
                    "selected_batch": jnp.array(b, jnp.int32),
                    "present": present_b.astype(jnp.int32),
                }
                _, vmask = self.PaliGemma.point(single_dict, train=False)  # [P]
                K_b = jnp.sum(vmask.astype(jnp.int32))
                k_list.append(K_b)
        K_all = jnp.stack(k_list, axis=0)  # [B]

        # --- (c) æ„é€ â€œæ’å…¥åâ€çš„ labels_textï¼ˆé•¿åº¦ LM=L+Pï¼‰ï¼Œå†ä¸å›¾åƒå‰ç¼€æ‹¼æ¥ ---
        labels_full_list = []
        L = observation.tokenized_prompt.shape[1]
        for b in range(B):
            s_idx = s_all[b]; e_idx = e_all[b]; K_b = K_all[b]
            right_len = L - e_idx
            t = jnp.arange(LM, dtype=jnp.int32)
            pt_start = s_idx + 1
            pt_end   = pt_start + K_b
            left_cond   = (t <  pt_start)
            points_cond = (t >= pt_start) & (t < pt_end)
            right_cond  = (t >= pt_end)   & (t < pt_end + right_len)

            txt_idx = jnp.where(left_cond, t, e_idx + (t - pt_end))
            txt_idx = jnp.clip(txt_idx, 0, L - 1)

            # æº labelsï¼šä¾æ® token_loss_mask è¿‡æ»¤ï¼›å¿½ç•¥ä½ = -100ï¼Œä¸ HF ä¸€è‡´
            lbl_src = jnp.where(
                observation.token_loss_mask[b].astype(bool),
                observation.tokenized_prompt[b],
                IGNORE,
            )
            lbl_txt = jnp.take(lbl_src, txt_idx, axis=0)
            lbl_txt = jnp.where((left_cond | right_cond), lbl_txt, IGNORE)
            lbl_txt = jnp.where(points_cond, IGNORE, lbl_txt)     # ç‚¹ä½å¿½ç•¥

            lbl_img = jnp.full((Nimg,), IGNORE, dtype=jnp.int32)
            lbl_all = jnp.concatenate([lbl_img, lbl_txt], axis=0)  # [T_total]
            labels_full_list.append(lbl_all)

        labels_full = jnp.stack(labels_full_list, axis=0)  # [B, T_total]

        # --- (d) è®¡ç®— NLLï¼šindex æ–¹å¼ï¼ˆé¿å…å¤§ one-hotï¼‰ ---
        log_probs = jax.nn.log_softmax(logits_all, axis=-1)         # [B, T_total-1, V]
        tgt = labels_full[:, 1:]                                    # é¢„æµ‹çš„æ˜¯ä¸‹ä¸€ä¸ª token
        valid = (tgt != IGNORE)
        tgt_safe = jnp.clip(tgt, 0, vocab_size - 1)
        picked = jnp.take_along_axis(log_probs, tgt_safe[..., None], axis=-1).squeeze(-1)  # [B, T_total-1]
        nll = -jnp.where(valid, picked, 0.0)
        denom = jnp.maximum(jnp.sum(valid, axis=-1), 1)
        seq_loss = jnp.sum(nll, axis=-1) / denom
        return seq_loss

    def sample_actions(
        self,
        rng: jax.Array,
        observation: _model.Observation,
        *,
        max_decoding_steps: int = 256,
        temperature: float = 0.0
    ) -> _model.Actions:
        """
        Autoregressively sample a sequence of actions (or action tokens) from the model given an observation.
        This uses the model as a prefix model (prefix = images + prompt tokens + optional point tokens),
        then generates additional tokens up to max_decoding_steps or until an EOS token is produced.
        """
        # Preprocess observation (no augmentation, just ensure correct shapes/masks)
        observation = _model.preprocess_observation(None, observation, train=False, image_keys=list(observation.images.keys()))
        # Embed inputs to get prefix token embeddings and masks
        prefix_tokens, prefix_mask, prefix_ar_mask = self.embed_inputs(observation)
        prefix_attn_mask = _pi0_fast.make_attn_mask(prefix_mask, prefix_ar_mask)
        # Align all prefix sequences to the right (required for caching in prefix)
        prefix_tokens, prefix_mask, prefix_attn_mask = _pi0_fast.left_to_right_align(prefix_tokens, prefix_mask, prefix_attn_mask)
        # â‘   â€”â€”  ä¸ SpatialLM ä¸€è‡´ï¼šprefill_len æ˜ç¡® cast ä¸º int32ï¼ˆåç»­ä¸ lax.iota ç­‰ä¿æŒç±»å‹åŒ¹é…ï¼‰
        prefill_size = prefix_tokens.shape[1]   # total sequence length after alignment (prefix padded to some length)
        prefill_len = jnp.sum(prefix_mask, axis=-1).astype(jnp.int32)   # actual prefix length per batch (number of valid tokens)
        prefix_start = prefill_size - prefill_len   # start index of actual prefix tokens after right-align (for each batch)
        # Prepare attention mask for prefix + decoding steps
        prefix_attn_mask = jnp.pad(prefix_attn_mask, ((0, 0), (0, 0), (0, max_decoding_steps)))
        prefix_positions = (jnp.cumsum(prefix_mask.astype(jnp.int32), axis=-1) - 1).astype(jnp.int32)  # positions of prefix tokens (0-indexed)
        # Run the LLM in decoding mode to fill KV cache with prefix
        prefix_logits, kv_cache, _ = self.PaliGemma.llm(
            embedded_prefix=prefix_tokens,
            mask=prefix_attn_mask,
            positions=prefix_positions,
            decode=True
        )
        # Start from the last logit of the prefix as the beginning for new generation
        last_logit = prefix_logits[:, -1:]   # [B, 1, V]
        # Placeholder for generated token outputs (initialize with zeros)
        output_tokens = jnp.zeros((last_logit.shape[0], max_decoding_steps), dtype=jnp.int32)

        # Now run autoregressive decoding for at most max_decoding_steps
        # Prepare attention mask for single-step decoding (prefix length + current step)
        # We will update the attention mask dynamically in the loop if needed

        # Use a while loop to generate tokens until done or max steps
        def cond_fn(state):
            _rng, _last, _cache, _step, _out = state
            # while_loop çš„æ¡ä»¶å¿…é¡»æ˜¯**æ ‡é‡ bool**ã€‚
            # è¿™é‡Œæˆ‘ä»¬è®¤ä¸ºâ€œæ‰€æœ‰æ ·æœ¬éƒ½å·²ç”Ÿæˆ EOSâ€æ‰æå‰åœæ­¢ï¼Œå› æ­¤ç”¨ jnp.all(...) â†’ æ ‡é‡ã€‚
            def _false_scalar(_):
                return jnp.array(False, dtype=bool)
            def _all_eos_scalar(_):
                # _out[:, _step - 1] å½¢çŠ¶ä¸º [B]ï¼Œjnp.all(...) è¿”å›æ ‡é‡ï¼ˆæ‰€æœ‰æ ·æœ¬å‡ä¸º EOSï¼‰
                # æ³¨æ„ï¼šstep==0 æ—¶è¿˜æ²¡æœ‰æœ‰æ•ˆ tokenï¼Œå› æ­¤èµ° _false_scalar åˆ†æ”¯ã€‚
                return jnp.all(_out[:, _step - 1] == _pi0_fast.PALIGEMMA_EOS_TOKEN)
            has_eos = jax.lax.cond(
                _step == 0,
                _false_scalar,
                _all_eos_scalar,
                operand=None,
            )
            return jnp.logical_and(_step < max_decoding_steps, jnp.logical_not(has_eos))

        def body_fn(state):
            rng_key, last_logits, cache, step, out_tokens = state
            rng_key, subkey = jax.random.split(rng_key)
            logits_step = last_logits.squeeze(1)
            token = jax.lax.cond(
                temperature > 1e-6,
                lambda key: jax.random.categorical(key, logits_step / temperature, axis=-1),
                lambda key: jnp.argmax(logits_step, axis=-1),
                operand=subkey,
            ).astype(jnp.int32)
            # åŸ put_along_last_axis æ„é€  O(NÂ²) oneâ€‘hotï¼›æ”¹ç”¨ scatter æ›´æ–°
            out_tokens = out_tokens.at[:, step].set(token)

            # Gemmaâ€‘fast & SpatialLMï¼šä½ç½® = å·²å¡« prefix token æ•° + å½“å‰ step
            # â‘¡  â€”â€”  positions ç»Ÿä¸€ int32ï¼Œå¯é¿å… multiâ€‘host sharding â€œmixed signednessâ€ æŠ¥è­¦
            # ä¸ SpatialLM/pi0_fast å¯¹é½ï¼ˆ0â€‘basedï¼‰ï¼šé¦–ä¸ªæ–° token ä½ç½® = prefill_len + 0
            positions = (prefill_len[:, None] + step).astype(jnp.int32)
            # Gemmaâ€‘fast æ—  token=kwargï¼šå…ˆåµŒå…¥ï¼Œå† decode ä¸€æ­¥
            token_emb = self.PaliGemma.llm(token[:, None], embed_only=True)
            # ä¸åŸ Pi0â€‘FAST ä¿æŒä¸€è‡´ï¼šæ˜¾å¼ä¼ å…¥ causalÂ maskï¼Œ
            # å±è”½å³å¯¹é½å‰ç¼€å·¦ä¾§ padding çš„ KVã€‚
            mask = jnp.logical_and(
                jnp.arange(prefill_size + max_decoding_steps, dtype=jnp.int32)[None, None, :]
                >= prefix_start[:, None, None],
                jnp.arange(prefill_size + max_decoding_steps, dtype=jnp.int32)[None, None, :]
                < (
                    jnp.broadcast_to(
                        prefill_size + step + 1,
                        (prefix_start.shape[0], 1, 1),
                    )
                ),
            )
            logits, cache = self.PaliGemma.llm(
                embedded_prefix=token_emb,
                kv_cache=cache,
                positions=positions,
                decode=True,
                mask=mask,  # â˜… æ–°å¢
            )
            return rng_key, logits, cache, step+1, out_tokens

        init_state = (rng, last_logit, kv_cache, jnp.array(0, jnp.int32), output_tokens)
        _, _, _, final_step, output_seq = jax.lax.while_loop(cond_fn, body_fn, init_state)

        # Return the output sequence of tokens as the model's predicted "actions"
        # (In practice, these tokens might represent discretized actions or a planned sequence encoded as text tokens)
        return output_seq[:, :final_step]   # [B, <=max_dec_steps]